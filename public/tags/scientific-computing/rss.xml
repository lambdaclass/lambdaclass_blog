<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
      <title>LambdaClass Blog - Scientific Computing</title>
      <link>https://blog.lambdaclass.com</link>
      <description>Deep technical insights on cryptography, distributed systems, zero-knowledge proofs, and cutting-edge software engineering from the LambdaClass team.</description>
      <generator>Zola</generator>
      <language>en</language>
      <atom:link href="https://blog.lambdaclass.com/tags/scientific-computing/rss.xml" rel="self" type="application/rss+xml"/>
      <lastBuildDate>Thu, 02 Sep 2021 00:00:00 +0000</lastBuildDate>
      <item>
          <title>Simulations are about to get way, way faster with JuliaSim</title>
          <pubDate>Thu, 02 Sep 2021 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://blog.lambdaclass.com/posts/simulations-are-about-to-get-way-way-faster-with-juliasim/</link>
          <guid>https://blog.lambdaclass.com/posts/simulations-are-about-to-get-way-way-faster-with-juliasim/</guid>
          <description xml:base="https://blog.lambdaclass.com/posts/simulations-are-about-to-get-way-way-faster-with-juliasim/">&lt;p&gt;Today we’re excited to bring you a first glance at the result of a major multi-year project by the Julia Computing team.&lt;&#x2F;p&gt;
&lt;p&gt;JuliaSim is a cloud-based simulation platform built on top of the Julia open source stack, including SciML and ModelingToolkit, which we explored in depth &lt;a href=&quot;&#x2F;scientific-machine-learning-with-julia-the-sciml-ecosystem&#x2F;&quot;&gt;here&lt;&#x2F;a&gt; and &lt;a href=&quot;&#x2F;modeling-complexity-with-symbolics-jl-and-modelingtoolkit-jl&#x2F;&quot;&gt;here&lt;&#x2F;a&gt;, respectively. These were just the base of JuliaSim, which aims to change the way the industry does modeling and simulation with powerful acceleration and integration within a complete ecosystem.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;juliacomputing.com&#x2F;products&#x2F;juliasim&#x2F;&quot;&gt;JuliaSim&lt;&#x2F;a&gt;’s first beta will be released in a few months. We interviewed Chris Rackauckas to learn more about the project.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h4 id=&quot;what-is-juliasim-how-does-it-compare-to-alternatives-like-modelica-dymola&quot;&gt;What is JuliaSim? How does it compare to alternatives like Modelica&#x2F;Dymola?&lt;&#x2F;h4&gt;
&lt;p&gt;JuliaSim is a cloud-based platform for accelerated modeling and simulation. Unlike tools like Dymola, it integrates with a large open source community, the Julia programming language and the SciML ecosystem, to enhance its environment with offerings like easy parallelism, automated generation of ML surrogate models, and much more. In &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=lNbU5jNp67s&quot;&gt;a recent talk at JuliaCon 2021&lt;&#x2F;a&gt; I highlight this community integration as one of its core aspects that gives JuliaSim a competitive advantage in terms of features and performance, since it allows us to contribute to and benefit from the work of many scientists and engineers from across the world.&lt;&#x2F;p&gt;
&lt;p&gt;While JuliaSim has acausal modeling as one of its core features, unlike Modelica-based tools that is just one of its domains. Accelerated simulation of PDEs with neural networks, integrating stochastic simulation into workflows, specific simulation environments for pharmacology and circuit modeling, and much more are all part of the JuliaSim product. We see the future as a place where composability will be necessary to achieve the next level of simulations.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;can-it-integrate-with-the-fmi-will-we-be-able-to-use-models-written-in-e-g-modelica-inside-juliasim&quot;&gt;Can it integrate with the FMI? Will we be able to use models written in, e.g. Modelica, inside JuliaSim?&lt;&#x2F;h4&gt;
&lt;p&gt;Yes, JuliaSim at its release will offer features for integrating with the FMI standard, allowing for FMI imports and FMI exports. This will allow for example the ability to build surrogates of models from Modelica or Simulink platforms, and allow for generating binaries that can integrate back into these platforms.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;a-key-aspect-of-modelica-is-its-standard-library-which-includes-many-of-the-most-common-components-for-modeling-will-there-be-a-similar-thing-in-juliasim&quot;&gt;A key aspect of Modelica is its standard library, which includes many of the most common components for modeling. Will there be a similar thing in JuliaSim?&lt;&#x2F;h4&gt;
&lt;p&gt;With JuliaSim we are building a standard library which includes similar domains to the Modelica Standard Library, but also includes many other domains related to the customers we have been working with. For example, with JuliaSim one will be able to easily search a database of hundreds of physiological and systems biological models for accelerating workflows in biomedical simulation and drug development. We plan to continually improve this model library and mold it to the needs of our customers.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-are-surrogate-models-what-makes-them-important-especially-beyond-academic-applications&quot;&gt;What are surrogate models? What makes them important, especially beyond academic applications?&lt;&#x2F;h4&gt;
&lt;p&gt;Surrogate models are an amortization of compute cost to improve simulation workflows. It gives you a way to say “do 100 simulations now, and all of my future simulations are 100x faster”. When you mix this with cloud resources you can get a major workflow update: pay for a bit of cloud compute to spawn a bunch of simulations in parallel, but now every time you click the simulate button you do not have to wait 30 minutes to check the result.&lt;&#x2F;p&gt;
&lt;p&gt;When I was in graduate school I noticed that there is a very nonlinear effect of code speed on productivity which I captured in a &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.stochasticlifestyle.com&#x2F;the-nonlinear-effect-of-code-speed-on-productivity&quot;&gt;blog post&lt;&#x2F;a&gt;. If you have to wait 30 minutes for a result, that means that instead you’ll start it before lunch or before a 1 hour meeting, so the true “time to see simulation results” gets amplified further. 2 hour simulations are something you will start in the morning and check at night. Thus a surrogate changing a long simulation to something that you can analyze in real-time is invaluable to decreasing labor costs because of how simulation time effects the day-to-day life of an engineer.&lt;&#x2F;p&gt;
&lt;p&gt;While in an academic sense we focus on issues like “training the surrogate costs 100 simulations, but we needed 10,000 simulations for to optimize the building design and thus we saved in the end”, I do not think this calculus is really the major change that surrogates will bring. Even if it takes 100 simulations to train a surrogate that you use 10 times, if you integrate this will cloud compute to do those all in parallel, then to the user you only have to sit through what is effectively 2 simulations. If that’s a two hour simulation time, you’ve now changed a workflow that takes a full day to something that you set to train in the morning and then after lunch you can interactively fiddle with parameters until your controls are correct. And then any time you revisit in the future, it’s ready to be fiddled with again. When you view surrogates in this light, I think you can see why we believe this will be a gamechanger for the everyday engineer.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;one-of-the-main-innovations-brought-by-juliasim-is-the-generation-of-fast-and-accurate-surrogate-models-that-can-speedup-simulations-as-much-as-500x-even-in-the-presence-of-stiff-models-how-is-this-achieved-what-s-a-ctesn&quot;&gt;One of the main innovations brought by JuliaSim is the generation of fast and accurate surrogate models that can speedup simulations as much as 500x, even in the presence of stiff models. How is this achieved? What’s a CTESN?&lt;&#x2F;h4&gt;
&lt;p&gt;A continuous-time echo state network (CTESN) is an implicitly trained machine learning framework for capturing the dynamics of stiff models. These are models with phase transitions, fast transient behavior, and are well-known to be numerically difficult. Across many domains we have shown the CTESN training procedure to be robust due to how it incorporates implicit features of stable differential equation solvers. All that we need to generate it is a chunk of simulations done beforehand, and what results is this really fast object that will predict the simulation behavior at new parameters.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;how-easy-is-it-to-compose-surrogate-models-with-normal-ones-in-juliasim-what-are-the-advantages-of-this-approach&quot;&gt;How easy is it to compose surrogate models with normal ones in JuliaSim? What are the advantages of this approach?&lt;&#x2F;h4&gt;
&lt;p&gt;The CTESN represents the surrogate of a differential equation model as a differential equation model. Because of this representation, it’s not different from the other physical components. As long as you train it to cover the right states and observables, it will slot right into where you had the larger model before.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;paramount-to-surrogatization-is-the-ability-to-check-the-accuracy-of-the-surrogate-model-and-its-performance-against-the-original-one-how-does-juliasim-tackle-this-are-these-metrics-appropriately-exposed-to-the-user&quot;&gt;Paramount to surrogatization is the ability to check the accuracy of the surrogate model and its performance against the original one. How does JuliaSim tackle this? Are these metrics appropriately exposed to the user?&lt;&#x2F;h4&gt;
&lt;p&gt;JuliaSim generates diagnostics of the surrogate training process to signal to the user important features like the projected maximum error over the timeseries over the user-defined parameter space. A lot of this is done through quasi-random sampling right now, though we are investigating more complex techniques to more quickly achieve good estimates.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;does-juliasim-run-on-top-of-juliahub-or-are-they-separate-things-is-the-pricing-model-expected-to-be-the-same&quot;&gt;Does JuliaSim run on top of &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;juliahub.com&#x2F;lp&#x2F;&quot;&gt;JuliaHub&lt;&#x2F;a&gt; or are they separate things? Is the pricing model expected to be the same?&lt;&#x2F;h4&gt;
&lt;p&gt;JuliaSim is JuliaHub-based platform. JuliaSim users receive a subscription to a set of proprietary packages, such as the standard library and the surrogatization tools, which grants access to their use on JuliaHub. The pricing model of JuliaSim is simply the subscription and pay-for-compute, so users only pay for what they use but have access to the full suite.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;will-there-be-a-gui-for-modeling-or-will-we-mostly-have-to-write-all-the-julia-code-explicitly&quot;&gt;Will there be a GUI for modeling or will we mostly have to write all the Julia code explicitly?&lt;&#x2F;h4&gt;
&lt;p&gt;There will be many GUIs! The first GUI that we are building is more pharmaceutical modeling focused given our early customer base and connections with Pumas-AI. This allows for quickly building chemical reaction network and systems pharmacology models, and representing models in a visual form for presentations and reporting. It also will serve as the basis for visual programming of compartmental models in pharmacokinetics. We also will have a GUI at launch which simplifies the FMU surrogatization process, allowing non-Julia users to quickly accelerate their FMUs by entering in parameter information and clicking “surrogatize”. We have other GUIs planned for the near future as well, such as GUIs for block diagrams and acausal modeling, along with 3D visualization tools.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;juliasim-is-launching-pretty-soon-what-can-we-expect-from-this-first-version-what-features-are-next&quot;&gt;JuliaSim is launching pretty soon; what can we expect from this first version? What features are next?&lt;&#x2F;h4&gt;
&lt;p&gt;JuliaSim’s first beta will be launching fairly soon. I wouldn’t call it the first version quite yet, though the beta will already be usable as we have been working with a group of customers to showcase the performance advantage for their specific applications. The first release will be a mix of GUIs, cloud parallel surrogatization, and standard libraries. And for the future we are aiming for a lot more. The full vision of JuliaSim is expressed in &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=lNbU5jNp67s&quot;&gt;the JuliaCon 2021 video&lt;&#x2F;a&gt; so refer to that for more details.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Scientific Machine Learning with Julia: the SciML ecosystem</title>
          <pubDate>Fri, 13 Nov 2020 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://blog.lambdaclass.com/posts/scientific-machine-learning-with-julia-the-sciml-ecosystem/</link>
          <guid>https://blog.lambdaclass.com/posts/scientific-machine-learning-with-julia-the-sciml-ecosystem/</guid>
          <description xml:base="https://blog.lambdaclass.com/posts/scientific-machine-learning-with-julia-the-sciml-ecosystem/">&lt;h4 id=&quot;interview-with-chris-rackauckas&quot;&gt;Interview with Chris Rackauckas&lt;&#x2F;h4&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-zBLCNU10DE1qv5PG4wdwbg.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;We live in a complex world. For those scientists who dare to immerse themselves in that complexity and generate a deeper understanding of it, it is very common to have to deal with differential equation models that are not possible to solve without the use of a computer.&lt;&#x2F;p&gt;
&lt;p&gt;A lot of time is usually be spent in coding the particular differential equation for each problem. Julia SciML works to create and maintain tools that improve this process— from the creation of a framework that allows to automate the pipeline to create and solve problem-specific differential equations with a high level syntax, to introducing machine learning methods to infer unknown components of the model, and many other functionalities.&lt;&#x2F;p&gt;
&lt;p&gt;We interviewed the creator of SciML, Chris Rackauckas, to get to know a little more about his work.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-bCCWEZqP_ORcTiLPPV13rw.png&quot; alt=&quot;&quot; &#x2F;&gt;Source: DifferentialEquations.jl documentation&lt;&#x2F;p&gt;
&lt;h4 id=&quot;please-tell-us-a-bit-about-yourself-what-is-your-background-what-is-your-current-position&quot;&gt;Please tell us a bit about yourself. What is your background? what is your current position?&lt;&#x2F;h4&gt;
&lt;p&gt;I am an applied mathematics instructor at MIT, the Director of Scientific Research at Pumas-AI, and a senior research analyst at the University of Maryland, School of Pharmacy. My background is numerical differential equations and systems biology, where my PhD was in new methods for efficient solving of stochastic differential equations to model the control of randomness in the developing zebrafish hindbrain.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-is-sciml-why-was-it-born-and-what-s-its-purpose&quot;&gt;What is SciML? Why was it born and what’s its purpose?&lt;&#x2F;h4&gt;
&lt;p&gt;Before the “SciML” organization, there was just DifferentialEquations.jl and JuliaDiffEq, but it grew beyond just a single project. There were methods for symbolically manipulating equations, sparse automatic differentiation, automated model discovery, neural PDE solvers, and even packages in Python and R for using these tools. So the name didn’t fit and we did a reorganization around the central principle: scientific machine learning. Scientific machine learning is a burgeoning field that mixes scientific computing, like differential equation modeling, with machine learning. That is the essence of the organization: many tools for scientific simulation with differential equation solvers, chemical reaction network tools and N-body simulators, but all of them can compose with machine learning.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-YtKzMw7VOvNbOCsOkXwU0A.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;scientific-computing-and-machine-learning-are-often-perceived-as-very-different-areas-what-would-you-say-are-the-strengths-and-weaknesses-of-each-one-and-how-does-sciml-take-advantage-of-them&quot;&gt;Scientific Computing and Machine Learning are often perceived as very different areas. What would you say are the strengths and weaknesses of each one and how does SciML take advantage of them?&lt;&#x2F;h4&gt;
&lt;p&gt;Scientific computing generally requires a lot of prior knowledge about the system. You need to be able to create a “mechanistic model”, which requires knowing the physical laws, the chemicals which react, or other way to mathematically encode each interaction of the system. If you know this, great! Then you have a very predictive model. You might know all of the chemicals which interact but not know the reaction rates, and then 12 data points can turn this into quite a predictive model. So these models are interpretable (since it’s all about the mechanism), data efficient, etc. They are great at extrapolating too: the theory of gravity gives pretty good predictions for what happens on Earth as it does for the solar system as it does for galaxies.&lt;&#x2F;p&gt;
&lt;p&gt;Data-driven modeling, like machine learning, takes a completely opposite approach of being “data first”. You have a non-mechanistic model, and you “train” the model based on the data. This requires a lot of data, but you can do this even when you have no idea what the mechanism is. What’s the mechanism for what movie someone will want to watch next on Netflix given the previous movies they’ve seen? Einstein didn’t have a theory for that! But with big data, you can generate such a model.&lt;&#x2F;p&gt;
&lt;p&gt;Scientific machine learning is about pairing together these two paradigms. Incorporating mechanism into machine learning makes it more interpretable, more data efficient, and better able to predict beyond the training data, all without requiring that you know all of the mechanisms. We’re using this in cases like pharmacometrics, where in the first clinical trial we may not know everything about how the drug works, but we can start with a pretty good guess by using mechanistic models derived for similar drugs, and use the incoming data to train models which transforms the prior model towards the data.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-ihyMT0ujkdDopf3M8eiXUw.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-are-neural-odes-when-is-it-appropiate-to-work-with-one-do-you-fear-that-accuracy-or-interpretability-is-lost-by-introducing-a-neural-network-as-part-of-the-equation-aren-t-there-other-learning-methodologies-suited-for-such-a-thing&quot;&gt;What are Neural ODEs? When is it appropiate to work with one? Do you fear that accuracy or interpretability is lost by introducing a Neural Network as part of the equation? Aren’t there other learning methodologies suited for such a thing?&lt;&#x2F;h4&gt;
&lt;p&gt;Neural Ordinary Differential Equations or Neural ODEs are ordinary differential equations defined by a neural network. Indeed the result is less interpretable than having a mechanistic physical model, but it allows for the model to be learned directly from data. The neural network makes it not just estimating parameters, but estimating functions. As a middle ground, we created the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2001.04385&quot;&gt;universal differential equation&lt;&#x2F;a&gt; which is a partially mechanistic model where the neural networks fill in areas of the model which are unknown or have a lot of uncertainty. In this sense, there is more of a continuum between the data-driven and mechanistic models.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;currently-there-exist-many-differential-equations-solvers-why-do-you-think-this-is-the-case-is-there-a-way-to-choose-the-best-one-for-each-situation&quot;&gt;Currently, there exist many differential equations solvers, why do you think this is the case? Is there a way to choose the best one for each situation?&lt;&#x2F;h4&gt;
&lt;p&gt;We created an automated algorithm chooser in order to mitigate this issue. If you do ‘solve(prob)’ (i.e. don’t specify a solver algorithm), it will choose one for you. Then you can give it hints to go down different branches. As time goes on I think we will keep refining that algorithm and pushing more people towards that.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-are-the-key-reasons-the-sciml-differential-equations-solver-is-so-fast-how-does-it-differ-from-others-how-influential-was-writing-it-in-julia&quot;&gt;What are the key reasons the SciML Differential Equations solver is so fast? How does it differ from others? How influential was writing it in Julia?&lt;&#x2F;h4&gt;
&lt;p&gt;Every differential equation solver specializes on some aspect of the differential equation, giving them different performance aspects. For example, BDF integrators, “the standard” for stiff equations, use values from past steps. This can speed things up if the equation is not too stiff, but if it’s too stiff then you cannot use a high order (known as the Dahlquist barrier) and it slows down. So it’s problem dependent as to how well it can mitigate numerical issues, which means for some problems it’s fast and in others it breaks down. Then, if you have discontinuities which are frequent, like dosing in pharmacometrics simulations, this also requires order reduction and thus makes this particular method slower. DifferentialEquations.jl has about 300 methods when you consider all of the tableaus across not just ODEs but also SDEs, DAEs, and DDEs, and it’s this collection that allows it to be efficient.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;regarding-the-importance-of-being-able-to-quantify-the-uncertainty-of-the-numerical-resolution-when-solving-differential-equations-how-does-sciml-address-this-problem&quot;&gt;Regarding the importance of being able to quantify the uncertainty of the numerical resolution when solving differential equations, how does SciML address this problem?&lt;&#x2F;h4&gt;
&lt;p&gt;DifferentialEquations.jl comes with a module DiffEqUncertainty.jl that gives sampling-based estimates of numerical uncertainty by causing jitter on the order of the error estimates calculated on each step. Normally these error estimates are only used for adapting dt, but this gives a way to get essentially a free estimate of what other possible paths look like. Andrew Stuart’s group at CalTech then has a full publication that describes that this method indeed matches the error distribution of the full solve. So if you run this a hundred times you’ll get a sense of what all of the possible trajectories could’ve been given the error tolerance that you allowed.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-are-multiscalearrays-in-what-ways-do-these-data-structures-help-us-in-simulating-complex-scientific-models&quot;&gt;What are MultiScaleArrays? In what ways do these data structures help us in simulating complex scientific models?&lt;&#x2F;h4&gt;
&lt;p&gt;The differential equation solvers, and actually all of the SciML ecosystem, work on abstract interfaces which allow for the concrete implementation of a type to be radically different from the standard implementation. MultiScaleArrays is a nice example of this where an entire multi-scale model is represented as both a graph structure and an array simultaneously. This lets the user write a model like “for every cell in the lung, do the chemical reactions of a lung cell” to define a model, but have the stiff high-performance ODE solver automatically know how to interact with this object. It’s not even an array: it’s an array of arrays of arrays etc., which acts like an array. In this form it’s very efficient to allows cells to divide and die, and the ODE solver will adapt the size of the solution vector automatically as this changes.&lt;&#x2F;p&gt;
&lt;p&gt;While this was made for the specific case of multi-scale biological modeling in mind, other users have since come up with other great examples. CuArrays are CUDA-accelerated arrays that live on the GPU that can be dropped in as a replacement to the standard array, or ComponentArrays.jl defines an array type similar to MultiScaleArrays which is backed by a real vector, so it’s faster for standard computations but slower for size changes. A lot of new features can thus be directly added and optimized in the ODE solver just by changing the input types!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-crRcFtHznAsYXDCb1uh4oQ.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;are-the-processes-of-solving-differential-equations-and-training-a-neural-networks-similar-how-do-you-put-together-both-frameworks&quot;&gt;Are the processes of solving differential equations and training a Neural Networks similar? How do you put together both frameworks?&lt;&#x2F;h4&gt;
&lt;p&gt;Training a neural network is solving an ODE defined by the gradient of the loss function until zero. Solving that ODE with Euler’s method is gradient descent. So you could use an ODE solver as the algorithm for training a neural ODE, and there is a use case that we’re looking into for that. Differential equations are more ubiquitous than I think most people realize.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;is-gpu-computing-integrated-in-the-sciml-ecosystem-how-important-is-having-this-feature-to-a-scientific-computing-framework-nowadays&quot;&gt;Is GPU computing integrated in the SciML ecosystem? How important is having this feature to a scientific computing framework nowadays?&lt;&#x2F;h4&gt;
&lt;p&gt;Yes, there’s two major ways. If you have “big kernels”, like PDE solving or neural networks integrated into models, you can do those calculations on the GPU. This is what’s known as “within-method parallelism”. One of the more recent techniques that we have is “between-method parallelism”, where we can automatically generate CUDA kernels from your model and parallelize that between trajectories of the solution. This uses some fancy code generation tricks thanks to tools like KernelAbstractions.jl, and allows “small problems” to have an effective way to use GPUs as well.&lt;&#x2F;p&gt;
&lt;p&gt;How important is it? Somewhat. There are problems which are extremely GPU-parallelizable, like neural ODEs and PDEs, and there are problems which are not, like lots of semi-mechanistic universal differential equation models. Whether a GPU is useful is very dependent on what and how you’re trying to model.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;in-which-cases-is-it-worth-to-add-a-bayesian-analysis-to-the-parameter-estimation-for-example-with-the-use-of-diffeqbayes-jl-what-are-its-advantages-over-more-classical-optimization-algorithms&quot;&gt;In which cases is it worth to add a Bayesian analysis to the parameter estimation, for example with the use of DiffEqBayes.jl? What are its advantages over more classical optimization algorithms?&lt;&#x2F;h4&gt;
&lt;p&gt;Bayesian analysis gives you a posterior distribution which has a sense of uncertainty quantification, i.e. it doesn’t just give you the “best parameter” but also a distribution which you can use to understand the error bars on your parameter estimate. In many cases this is a fundamentally interesting quantity. For example, in pharmacology we often want to know the probability that the drug concentration is in the safe zone. To evaluate this, we need a probabilistic fit of the model since only by including the uncertainty of our parameters can we get an accurate guess of the probabilities of the dynamics.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-c8-WwVO2Mlef4QqXP7SvSA.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;are-there-any-relevant-books-or-papers-you-would-like-to-recommend-for-digging-deeper-in-these-topics&quot;&gt;Are there any relevant books or papers you would like to recommend for digging deeper in these topics?&lt;&#x2F;h4&gt;
&lt;p&gt;Books schmooks. You’ll want to go directly to the sources. The only books I really recommend these days are Ernst Hairer’s “Solving Ordinary Differential Equations” I and II tomes: those are a work of art. Also Kloeden’s book on numerical methods for stochastic differential equations. Other than that, dive right into the scientific literature.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-is-next-for-sciml-are-you-currently-working-on-some-other-features-to-add-in-the-near-future&quot;&gt;What is next for SciML? Are you currently working on some other features to add in the near future?&lt;&#x2F;h4&gt;
&lt;p&gt;There’s tons we’re doing! I think a lot of what’s next is the integration of symbolic computing into all of our tools. ModelingToolkit.jl is the centerpiece of that push, and while I gave a talk at JuliaCon 2020 showcasing how it can be used as an automated code optimization tool (and gave a PyData 2020 talk on how you can GPU-accelerate ODE solves in R using it!), it’s so much more than that. It’s sometimes hard to numerically do things correctly, like ensuring positivity in an ODE solution can be difficult. But if you log transformed your model, then by definition your solution will always be positive. Right now this is up to the user, but what if we could automatically change the equations you wrote so that, not only are they more efficient, but they are also mathematically easier to solve and estimate? That’s the scope of ModelingToolkit, and if that interests you then you might want to stay tuned to that and its sister product NeuralSim which is about automated surrogate acceleration for the ModelingToolkit modeling language.&lt;&#x2F;p&gt;
</description>
      </item>
    </channel>
</rss>
