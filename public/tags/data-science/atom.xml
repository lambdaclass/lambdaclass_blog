<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title>LambdaClass Blog - Data Science</title>
    <subtitle>Deep technical insights on cryptography, distributed systems, zero-knowledge proofs, and cutting-edge software engineering from the LambdaClass team.</subtitle>
    <link rel="self" type="application/atom+xml" href="https://blog.lambdaclass.com/tags/data-science/atom.xml"/>
    <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2021-03-19T00:00:00+00:00</updated>
    <id>https://blog.lambdaclass.com/tags/data-science/atom.xml</id>
    <entry xml:lang="en">
        <title>We wrote a book! “Data Science in Julia for Hackers” beta is now live and free to read</title>
        <published>2021-03-19T00:00:00+00:00</published>
        <updated>2021-03-19T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/how-we-wrote-a-hands-on-bayesian-data-science-book-in-6-months/"/>
        <id>https://blog.lambdaclass.com/posts/how-we-wrote-a-hands-on-bayesian-data-science-book-in-6-months/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/how-we-wrote-a-hands-on-bayesian-data-science-book-in-6-months/">&lt;h4 id=&quot;learn-about-data-science-and-julia-while-solving-real-life-problems&quot;&gt;Learn about data science and Julia while solving real-life problems&lt;&#x2F;h4&gt;
&lt;p&gt;&lt;strong&gt;Read our book “Data Science in Julia for Hackers” at:&lt;&#x2F;strong&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;datasciencejuliahackers.com&#x2F;&quot;&gt;&lt;strong&gt;https:&#x2F;&#x2F;datasciencejuliahackers.com&#x2F;&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-t93INVDo-XNSm7iObeXODQ.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;We put together this post to share the release of our first book on data science methods, which focuses on solving real-life problems. This release is actually a beta version, as we are looking to receive constructive criticism and feedback, in order to improve the book until the first revised version is ready.&lt;&#x2F;p&gt;
&lt;p&gt;We come from different backgrounds. Federico Carrone is a developer with over 15 years of experience and founder of a startup that is running since 2014, who is currently studying towards a degree in Mathematics. Herman Obst is an Industrial Engineer who is just learning to program as is our Physicist, Mariano Nicolini. Martina Cantaro coordinated the writing process and our technical consultants, Manuel Puebla and Lucas Fernández Piana, are making sure our definitions are simple to understand yet accurate.&lt;&#x2F;p&gt;
&lt;p&gt;We do not come from academia, nor are we experts in statistics, which may make some people wonder whether we have enough authority to concern ourselves with such complex issues. But we have one thing in common: above all, we are doers. Collectively, we have experience in setting ourselves big goals and achieving them through, learning, hacking, tinkering and thinking. Data science is a toolkit that has enabled us to solve different real-life problems and we want to share what we have learned in the process.&lt;&#x2F;p&gt;
&lt;p&gt;Speaking of real-life problems, few disciplines have as much impact when it comes to solving them as data science. Currently, our society is constantly generating massive amounts of information encoding complex behaviors and relationships from a wide array of fields. And people are developing the tools to use that information to our benefit.&lt;&#x2F;p&gt;
&lt;p&gt;That was why we were so struck by the fact that almost all the books on data science and statistics had a very theoretical approach, focusing on understanding the mathematics of the algorithms and never talking about their applications to situations we might encounter in work or life in general.&lt;&#x2F;p&gt;
&lt;p&gt;Because of this (and because of our love for making and generating things) we decided to embark on the adventure of writing a book. A book whose first and foremost premise was to propose diverse and interesting problems, and solve them using the ingenuity and tools of data science. And theory does not play a minor role, not at all, but it is developed only to the extent that the resolution of the problem requires it. In this way, a real connection between theory and reality is achieved.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;what-we-want-you-to-learn&quot;&gt;What we want you to learn&lt;&#x2F;h3&gt;
&lt;p&gt;One of the ideas we are most interested in conveying is that of taking action. Nowadays there is a dominant way of thinking, widespread in the academic world, which maintains that before being able to carry any meaningful work we must first acquire a broad theoretical knowledge of the subject. We think this can be counterproductive, as it makes people afraid of taking risks and daring to immerse themselves in practice.&lt;&#x2F;p&gt;
&lt;p&gt;We decided to disprove this way of thinking by making a book about Bayesian statistics, machine learning and artificial intelligence, without (at first) knowing much about any of these fields.&lt;&#x2F;p&gt;
&lt;p&gt;That was our goal. We figured out the rest as we went along.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;what-we-learned&quot;&gt;What we learned&lt;&#x2F;h3&gt;
&lt;p&gt;With our goal always in mind, we started searching and solving a wide variety of problems that could be interesting to tackle using Bayesian inference, which at the beginning was the only topic we planned to talk about. That way we got used to the Bayesian mindset and the different probabilistic programming tools in Julia, our language of choice.&lt;&#x2F;p&gt;
&lt;p&gt;But as we profressed, we changed the focus of the book from something like “Bayesian methods from a practical perspective” to include data science topics in general, from time series prediction to the powerful Scientific Machine Learning ecosystem. Finally, although we wanted to focus on these -not so widespread- methods, we thought it pertinent to add a section on more classical methods, such as deep learning and machine learning — the latter currently in production.&lt;&#x2F;p&gt;
&lt;p&gt;As the dificulty of the scenarios we created began to increase (we often found that a problem was way more complicated than we initially thought), it became clear that we had to incorporate a little more solid knowledge about Bayesianism. That’s where reading &lt;em&gt;Bayesian Methods for Hacker&lt;&#x2F;em&gt; s and &lt;em&gt;Statistical Rethinking&lt;&#x2F;em&gt; gave us a much better understanding and tools to deal with the complexity.&lt;&#x2F;p&gt;
&lt;p&gt;Our writing process also got better over time. Although we already had some experience writing blog posts, writing a book was a brand new challenge for everyone, especially since we are not native English speakers.&lt;&#x2F;p&gt;
&lt;p&gt;At the beginning, our explanations of models and the theory behind them were somewhat lacking. Several pages were discarded, and the rest were re-written several times until we found them passable. It was a process that involved some deal of frustration, but as we iterated over them, the quality of the pages increased substantially. Finally, we found a comfort zone in terms of diagraming, coding and writing the chapters.&lt;&#x2F;p&gt;
&lt;p&gt;The road was winding and some keys to keep the progress up were to not let ourselves be overwhelmed by the enormous task, to divide the work, to go chapter by chapter and, above all, to always keep moving forward. One strategy we used was to complete the writing of the chapters until we felt they were 80% complete. That way, the progress curve always kept a good positive slope, since (by Pareto law) that last 20% would take 80% of the time to complete. Only when we had completed 80% of the book, we went back chapter by chapter to finish polishing it.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;where-you-can-read-it&quot;&gt;Where you can read it&lt;&#x2F;h3&gt;
&lt;p&gt;And that’s it! As of now, the book is up for everyone to read at:&lt;&#x2F;p&gt;
&lt;h4 id=&quot;https-datasciencejuliahackers-com&quot;&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;datasciencejuliahackers.com&#x2F;&quot;&gt;https:&#x2F;&#x2F;datasciencejuliahackers.com&#x2F;&lt;&#x2F;a&gt;&lt;&#x2F;h4&gt;
&lt;p&gt;We hope it will be useful to as many people as possible and we hope to receive lots of feedback and constructive criticism, so we can keep improving edition after edition.&lt;&#x2F;p&gt;
&lt;p&gt;Enjoy!&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Modeling complexity with Symbolics.jl and ModelingToolkit.jl</title>
        <published>2021-03-18T00:00:00+00:00</published>
        <updated>2021-03-18T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/modeling-complexity-with-symbolics-jl-and-modelingtoolkit-jl/"/>
        <id>https://blog.lambdaclass.com/posts/modeling-complexity-with-symbolics-jl-and-modelingtoolkit-jl/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/modeling-complexity-with-symbolics-jl-and-modelingtoolkit-jl/">&lt;h4 id=&quot;an-interview-with-chris-rackauckas&quot;&gt;An interview with Chris Rackauckas&lt;&#x2F;h4&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-sHzrVkhNvHxdiJ2IBmfVPA.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;As we often mentioned on Not a Monad Tutorial, the world is complex, and we increasingly understand where our tools fall short when trying to model this complexity.&lt;&#x2F;p&gt;
&lt;p&gt;We’ve previously interviewed Chris Rackauckas on &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;notamonadtutorial.com&#x2F;scientific-machine-learning-with-julia-the-sciml-ecosystem-b22802951c8a&quot;&gt;SciML&lt;&#x2F;a&gt;; this time he joins us to answer questions regarding new developments in the area of symbolic computation with Julia, its relation to numerical computing, causal vs acausal approaches, how these matters are represented in Symbolics.jl and ModelingToolkit.jl, and how these packages relate to the existing simulation tooling landscape.&lt;&#x2F;p&gt;
&lt;p&gt;These packages compose easily and thus allow modelling larger, more complex systems by reusing parts, as well as helping community efforts. Having these interoperable packages is key to building a modern simulation software stack which can address the aforementioned needs of complex modelling.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h4 id=&quot;what-is-symbolics-jl-what-are-the-motivations-behind-the-creation-of-the-system&quot;&gt;What is Symbolics.jl? What are the motivations behind the creation of the system?&lt;&#x2F;h4&gt;
&lt;p&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;JuliaSymbolics&#x2F;Symbolics.jl&quot;&gt;Symbolics.jl&lt;&#x2F;a&gt; is a Computer Algebra System (CAS) in the Julia programming language developed by the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;juliasymbolics.org&#x2F;&quot;&gt;JuliaSymbolics Organization&lt;&#x2F;a&gt;. Think symbolic computation: write down equations and ask the computer to come up with symbolic solutions. It’s a modern CAS, meaning it’s built on a widely used modern programming language (Julia), making use of modern tooling like pervasive parallelism, new algorithms like E-Graphs, integration with machine learning, and more.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-is-modelingtoolkit-jl-what-are-the-needs-it-addresses&quot;&gt;What is ModelingToolkit.jl? What are the needs it addresses?&lt;&#x2F;h4&gt;
&lt;p&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;SciML&#x2F;ModelingToolkit.jl&quot;&gt;ModelingToolkit.jl&lt;&#x2F;a&gt; is an equation-based acausal modeling system. It’s similar to systems like Modelica which allow for composing models to quickly generate realistic simulations. This lets you take pre-built models created by other scientists and build complete systems. For example, you can take a high fidelity model of an air conditioning, then make a model of a building, and stick the air conditioning into the building and ask what kind of energy efficiency you get. Then change the building to start designing what’s most efficient.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;how-does-acausal-modeling-relate-to-tools-like-simulink&quot;&gt;How does acausal modeling relate to tools like Simulink?&lt;&#x2F;h4&gt;
&lt;p&gt;Simulink is a causal modeling tool. You have to know “what causes what” in order to develop the simulation. This can be difficult in our complex world: the heat of the building is read by the thermostat which turns the AC on which then changes the heat of the building. Feedbacks and “algebraic loops” cause issues in causal modeling systems: users have to break the loops or change the model. For this reason &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1909.00484&quot;&gt;experts consider causal modeling as not suitable for complex simulations&lt;&#x2F;a&gt; as they do not compose well. This is the reason acausal tools like Modelica have seen a lot of adoption. Even MATLAB has an acausal tool now, SimScape. Given the advancements in these techniques, I see the next generation of engineers all using acausal tools, with ModelingToolkit.jl being one of the only fully-featured free and open-source acausal systems.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;why-is-symbolic-computation-needed-at-all-what-are-the-advantages-compared-to-numerical-computation-when-is-one-preferred-to-the-other&quot;&gt;Why is symbolic computation needed at all? What are the advantages compared to numerical computation? When is one preferred to the other?&lt;&#x2F;h4&gt;
&lt;p&gt;Are you sure you know enough mathematics to have written the mathematical model in the most numerically-stable form? Even if you know all of the tricks that you’re supposed to do, do you want to do it all by hand? I see the main use of symbolic computation in symbolic-numerics, i.e. using symbolic techniques to improve the models which are then used in numerical methods. For example, in a recent blog post titled &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.stochasticlifestyle.com&#x2F;generalizing-automatic-differentiation-to-automatic-sparsity-uncertainty-stability-and-parallelism&#x2F;&quot;&gt;Generalizing Automatic Differentiation to Automatic Sparsity, Uncertainty, Stability, and Parallelism&lt;&#x2F;a&gt;, I describe how a two-dimensional pendulum simulation without the small angle approximation requires a differential-algebraic equation. The intuitive model of “position moves by velocity, velocity moves by acceleration, and length is constant” is actually an unstable description of the full pendulum. You have to differentiate the “length is constant” equation twice, then substitute other relationships, and then you arrive at an “index-1” DAE which is easier to numerically solve. Even if you know enough of these details to do it, you don’t want to handle that! Symbolic-numeric computation is how we will get to a future where that is all automated.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;wolfram-mathematica-and-sympy-in-python-are-some-of-the-most-popular-choices-when-dealing-with-symbolic-manipulation-nowadays-what-are-the-advantages-symbolics-jl-offers-in-comparison-to-them&quot;&gt;Wolfram Mathematica and SymPy in Python are some of the most popular choices when dealing with symbolic manipulation nowadays. What are the advantages Symbolics.jl offers in comparison to them?&lt;&#x2F;h4&gt;
&lt;p&gt;Symbolics.jl is being built from the ground up for speed, being built from the ground up with parallelism, and last but not least, it’s being built up from a community of tools. There is so much good stuff out there that I think it would be unreasonable to silo one’s organization off and do everything from scratch. Julia has many great initiatives like &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.computeralgebra.de&#x2F;sfb&#x2F;&quot;&gt;OSCAR.jl&lt;&#x2F;a&gt; which are building fast implementations of the mathematical guts. We are using the fact that Julia is a high performance language to both develop high level interfaces and ensure that all of these tools can be used with minimal overhead, mental and computational. So while you might know nothing about Galois fields, there might be a fancy algorithm underneath the hood when you call factorize(x² + 2x + 1) that does it efficiently and scales to large systems.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;how-is-modelingtoolkit-jl-related-to-symbolics-jl-what-role-does-julia-s-composability-play-in-the-relationship-between-the-two-packages&quot;&gt;How is ModelingToolkit.jl related to Symbolics.jl? What role does Julia’s composability play in the relationship between the two packages?&lt;&#x2F;h4&gt;
&lt;p&gt;Acausal modeling requires symbolic transformations of equations. In that pendulum example, “differentiate the equation twice and substitute”, what kind of tool provides features like differentiation and high performance equation rewriting (i.e. substitution)? A CAS! So ModelingToolkit.jl let’s someone say “this is an ODE”, where it’s equations are described by Symbolics.jl expressions. There are then functions that do things like “transform this to index-1 form” and “analytically discover which equations are redundant and delete them”, and those transformations are written using the tools of Symbolics.jl. This means that as the CAS grows more powerful, so will ModelingToolkit.jl and its environment.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;how-does-modelingtoolkit-jl-compare-to-other-modeling-frameworks-such-as-modelica-and-simulink-how-easily-would-a-person-with-some-background-on-these-frameworks-adapt-to-modelingtoolkit-jl&quot;&gt;How does ModelingToolkit.jl compare to other modeling frameworks such as Modelica and Simulink? How easily would a person with some background on these frameworks adapt to ModelingToolkit.jl?&lt;&#x2F;h4&gt;
&lt;p&gt;ModelingToolkit.jl’s focus at this point has mainly been on flexibility and speed. In terms of flexibility, ModelingToolkit.jl is the only one which has a hackable compiler that allows composing transformations. All of the symbolic enhancements that are allowed in the Modelica and Simulink compilers are those that are built-in. While it sounds like that’s all that most users need, what that really does is stifle innovation. There are people working in these fields that need a common framework to build off of. Many of these researchers are now in Julia. So for example, could we add an analysis pass that automatically tells you whether you can distinguish between parameters with the data you have? Yes, anyone could extend the ModelingToolkit.jl system with a pass that does that, &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;alexeyovchinnikov&#x2F;SIAN-Julia&quot;&gt;and we’re already talking with authors of Julia libraries about doing this&lt;&#x2F;a&gt;. There is so much going on in this space that it’s hard to express, but expect tons of unique transformations to be allowed on your models. “Make a model that doesn’t solve in other systems solve here” is not just a dream.&lt;&#x2F;p&gt;
&lt;p&gt;And then there’s speed. We haven’t done complete and comprehensive benchmarking against all of the systems yet, but we have seen &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2103.05244&quot;&gt;some good performance against some Modelica compilers&lt;&#x2F;a&gt;, indicating we’re doing really well. One NASA user of ModelingToolkit.jl said &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;youtu.be&#x2F;tQpqsmwlfY0&quot;&gt;a 15 minute Simulink simulation took 50ms in ModelingToolkit.jl&lt;&#x2F;a&gt;. A user mentioned at the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;youtu.be&#x2F;FMVOUvWNlLE&quot;&gt;AAS&#x2F;AIAA Space Flight Mechanics meeting that every case against a Fortran package with a MATLAB interface, they saw at least an order of magnitude acceleration by moving to ModelingToolkit.jl&lt;&#x2F;a&gt;. In a very early version of ModelingToolkit.jl, we did a demo with Pfizer where we &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;juliacomputing.com&#x2F;case-studies&#x2F;pfizer&#x2F;&quot;&gt;demonstrated a 175x acceleration over their original C-based simulations&lt;&#x2F;a&gt;. Part of all of this is just due to the solvers, &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;benchmarks.sciml.ai&#x2F;html&#x2F;MultiLanguage&#x2F;wrapper_packages.html&quot;&gt;which benchmark really well in a cross-language way&lt;&#x2F;a&gt;. Another good chunk is due to the feature sets of the solvers, and ModelingToolkit.jl automatically enabling some of the best choices of combinations. This is explored a bit in a talk at JuliaCon 2020 titled &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=UNkXNZZ3hSw&quot;&gt;Auto-Optimization and Parallelism in DifferentialEquations.jl&lt;&#x2F;a&gt;, which was the video that announced the release of ModelingToolkit.jl as a new front end to the solvers for further improving speed.&lt;&#x2F;p&gt;
&lt;p&gt;That said, we have focused so far on the details. We want the biggest hardest models with the users who have the most demands. These other tools have put a lot more time into user interface, specifically graphical user interfaces (GUIs). Modelica and Simulink has a lot of tooling for drag-and-drop model building. Also, they have libraries of premade libraries. But, this will change very soon. Keep your eyes peeled for some announcements.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-are-the-main-challenges-to-solve-in-order-to-build-such-a-high-level-modeling-library&quot;&gt;What are the main challenges to solve in order to build such a high level modeling library?&lt;&#x2F;h4&gt;
&lt;p&gt;You want to make the modeling language be expressive enough so that every detail you can mathematically specialize on and optimize for is there, but you want to make it easy for users to actually use. Striking that balance is difficult. ModelingToolkit.jl has around 4 years in various prototype forms going through and breaking designs until we found one that could actually solve the problem to the level we hoped.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;how-is-julia-code-generated-from-symbolic-expressions&quot;&gt;How is Julia code generated from symbolic expressions?&lt;&#x2F;h4&gt;
&lt;p&gt;The symbolic expressions use the same exact pieces under different symantics. For example, square roots in the model are &lt;code&gt;sqrt&lt;&#x2F;code&gt; in Symbolics.jl and &lt;code&gt;sqrt&lt;&#x2F;code&gt; in Julia. This means all we have to do is take the symbolic expression and write it into a Julia function, and invoke the compiler. Invoking compilation on the fly as part of a symbolic language is an interesting challenge though, something that a tool like SymPy skips but which reduces speed by orders of magnitude. The specific details of this are pretty esoteric so I will spare you, but to make this all work we created a new hook into the Julia compiler called &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;SciML&#x2F;RuntimeGeneratedFunctions.jl&quot;&gt;RuntimeGeneratedFunctions&lt;&#x2F;a&gt; which allow for staged compilation that composes with garbage collection, making generated code safe.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-are-the-mechanisms-that-allow-easy-model-composition-with-modelingtoolkit-jl&quot;&gt;What are the mechanisms that allow easy model composition with ModelingToolkit.jl?&lt;&#x2F;h4&gt;
&lt;p&gt;It’s the acasual modeling. You can develop pieces in isolation and just declare relationships between the components. For example, build a model of a power generator, and a model of a computer chip. Now you want to connect these two completely different models? Physically, a wire would connect them and then Kirchoff’s laws would have to hold, i.e. the voltages would have to be equal at the connection points and the currents would sum to zero. So in ModelingToolkit.jl that’s what you’d do: you’d say “current from generator + current to chip = 0” and “voltage at generator = voltage at chip” and bingo you’re there. Now this might produce some redundant variables and equations, but it’s okay: the symbolic preprocessing system eliminates all of this and simplifies down to the most efficient problem to simulate. Then at the end, you can ask “give me the timeseries of the voltage at the chip” and it will give you it, regardless if it was actually in the simulation of not, because it has the information to reconstruct these values.&lt;&#x2F;p&gt;
&lt;p&gt;ModelingToolkit.jl goes one step further. There are &lt;code&gt;connect&lt;&#x2F;code&gt; statements which let you define a common behavior. For example, a &lt;code&gt;Pin&lt;&#x2F;code&gt; in an electrical circuit always has a voltage and a current, and those laws from above are how “connections” physically work. So at this higher level you can say “connect the pin of the generator to the pin of the circuit”, and it generates all of the physical relationships associated with that statement. There are many prebuilt systems which are coming very soon (likely to be completed before these responses are public!), so heat flow, enthalpy relationships, etc. are all simple &lt;code&gt;connect&lt;&#x2F;code&gt; statements. The connection mechanism is extendable too, so if you have a common meaning in say pharmacological models which differs, you can create a new variable type and make connections automatically enforce the laws you want. Connect the heart to the kidney means blood flow is conserved but oxygen is not. This makes it easy to specialize the systems to each of the specific scientific domains.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-are-the-advantages-of-symbolic-preprocessing-of-models&quot;&gt;What are the advantages of symbolic preprocessing of models?&lt;&#x2F;h4&gt;
&lt;p&gt;From the previous statement, note that simple modeling requires the ability to build things in isolation, and then just say “a=b”. Numerically simulating with “a=b” is rather difficult though, numerical methods really want to not solve equations exactly. But if the current at one side is 10^(-8) higher than the other, you lose conservation of current, and you can have the power of the system steadily rising until it spirals out of control and the simulation crashes. This is actually a very common behavior in causal modeling systems. But if you eliminate the variable “b” and replace it with “a” in every place where it shows up, and then if the user asks for “b” you give them “a”, now you’ve symbolically enforced equality and you will never have a numerical issue due to that effect. So not only does it make the set of equations you have to solve smaller (making the solving process faster), but it also makes the numerical solving a lot more stable and more likely to succeed.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;who-are-modelingtoolkit-jl-and-symbolics-jl-aimed-to-beyond-academia-do-you-consider-people-in-the-industry-might-find-them-useful&quot;&gt;Who are ModelingToolkit.jl and Symbolics.jl aimed to? Beyond academia, do you consider people in the industry might find them useful?&lt;&#x2F;h4&gt;
&lt;p&gt;Symbolics.jl is more academically focused. People doing symbolic computer algebra are everywhere, but I tend to see more in academia. Physicists, computational biologists, etc. Because Symbolics.jl allows for translating back and forth between Julia code and symbolic code automatically, we’re seeing computer scientists even adopt it as a nice and easy way to analyze code.&lt;&#x2F;p&gt;
&lt;p&gt;ModelingToolkit.jl on the other hand is more focused towards engineers and modelers. Mechanical engineers, robotics experts, building designers, synthetic biologists. These people are found commonly in both academia and industry. We’re getting a lot of praise from industry users of ModelingToolkit.jl already, so it’s likely to find a nice foothold there.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;how-many-people-are-involved-in-the-projects-what-are-their-backgrounds&quot;&gt;How many people are involved in the projects? What are their backgrounds?&lt;&#x2F;h4&gt;
&lt;p&gt;There are far too many involved, so I’m just going to give a shoutout to the top few. Yingbo Ma is a super star, still an undergrad but a major contributor to both SciML (the differential equation solvers and ModelingToolkit.jl) and JuliaSymbolics. Shashi Gowda is a PhD student at MIT who has been driving a lot of the internals of JuliaSymbolics. Then there have been many contributions by NASA folks, high schoolers, professors in math departments and biology departments, pandemic researchers, etc. It’s still very early on in the project but the community around it is already great.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-are-the-next-steps-for-each-project&quot;&gt;What are the next steps for each project?&lt;&#x2F;h4&gt;
&lt;p&gt;We’re going to have a major announcement very soon, so stay tuned.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Stumpy: unleashing the power of the matrix profile for time series analysis</title>
        <published>2020-11-02T00:00:00+00:00</published>
        <updated>2020-11-02T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/stumpy-unleashing-the-power-of-the-matrix-profile-for-time-series-analysis/"/>
        <id>https://blog.lambdaclass.com/posts/stumpy-unleashing-the-power-of-the-matrix-profile-for-time-series-analysis/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/stumpy-unleashing-the-power-of-the-matrix-profile-for-time-series-analysis/">&lt;h4 id=&quot;an-interview-with-stumpy-creator-sean-law&quot;&gt;An interview with Stumpy creator Sean Law&lt;&#x2F;h4&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-4Y5wJGqZM2AxKb7fmT9-og.png&quot; alt=&quot;&quot; &#x2F;&gt;Source: &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;stumpy.readthedocs.io&#x2F;en&#x2F;latest&#x2F;Tutorial_Time_Series_Chains.html&quot;&gt;Stumpy documentation&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;In the mid-20th century, the Information Age started. Every day an astonishing amount of data is created and analyzing it in an efficient way requires computational tools that combine novel and clever approaches that benefit from cutting edge technology.&lt;&#x2F;p&gt;
&lt;p&gt;Time series are a particular kind of data: the points measured are related by time, and analyzing them can often become quite difficult because time is not just like any other variable. More traditional methods like ARIMA or machine learning methods like LSTM can quickly become computationally inefficient as the amount of points increase, and sometimes they can be too elaborate for simple results such as finding overall patterns in the data, not to mention the complications arising when finding more complex patterns in the data is the final goal.&lt;&#x2F;p&gt;
&lt;p&gt;Stumpy is a library for analyzing time series, that tries to address the problems that appear when working with this kind of data. By design, Stumpy high performance, simplicity, and to employ general purpose approaches for extracting meaningful information. We interviewed the team to learn more about this promising project.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-NWV2vLKBciK49BAVfzvN4Q.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-is-stumpy-what-are-the-goals-of-the-project&quot;&gt;What is STUMPY? What are the goals of the project?&lt;&#x2F;h4&gt;
&lt;p&gt;Numerous classical methods exist for understanding and analyzing time series data, such as data visualization, summary statistics, ARIMA modeling, Markov modeling, anomaly detection, forecasting, machine learning, deep learning, etc. The list goes on. However, when a data practitioner is presented with new or unfamiliar time series data, many of the aforementioned approaches often fail to uncover any significant pattern, anomaly, or unique observation since it isn’t known, a priori, whether or not an interesting insight even exists. Of course, if a behavior is found to be conserved within your time series (though, this may not always be true), then there must have been a reason why it was conserved and teasing out those reasons or causes can often be very useful. Note that with time series analysis we are rarely interested in single point statistics (i.e., global max, global min, etc) and, instead, it is more valuable to discover interesting “subsequences” (i.e., a continuous run of values along your time series with a preset length). So, when starting with time series analysis, one should really be asking:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Do any conserved behaviors (i.e., repeating subsequences) exist in my time series data?&lt;&#x2F;li&gt;
&lt;li&gt;If there are conserved behaviors, what are they and where are they?&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;A naive but straightforward approach that can help answer these questions (covered in more detail &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;stumpy.readthedocs.io&#x2F;en&#x2F;latest&#x2F;Tutorial_The_Matrix_Profile.html&quot;&gt;here&lt;&#x2F;a&gt;) could involve comparing the Euclidean distance for every subsequence within the time series in a pairwise fashion in order to identify subsequences that are either highly conserved or exceptionally rare. This seems intuitive at first and it provides an exact solution to our problem but, as the size of the dataset increases (&amp;gt;10,000 data points), this brute force search can quickly become computationally intractable and reveals why approximate solutions (i.e., allowing for false positives and false negatives) or less interpretable solutions (above) have prevailed. Recently, &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.cs.ucr.edu&#x2F;~eamonn&#x2F;MatrixProfile.html&quot;&gt;independent research conducted at UC Riverside&lt;&#x2F;a&gt; has spawned a collection of brand new ideas and they have developed scalable algorithms that directly addresses this hard computational problem. However, the knowledge and capabilities that have been transferred to the scientific Python community has been limited.&lt;&#x2F;p&gt;
&lt;p&gt;And so, STUMPY was born. &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;TDAmeritrade&#x2F;stumpy&quot;&gt;STUMPY&lt;&#x2F;a&gt; is a powerful and scalable Python package that faithfully reproduces the aforementioned academic work and, at its core, efficiently computes something called a “matrix profile”, which can be used for a variety of time series data mining tasks. Essentially, a matrix profile is a vector that stores the Euclidean distance (and index location) between each subsequence within a time series and its nearest neighbor. And, with 100% code coverage and multi-CPU&#x2F;multi-GPU support out of the box, the goal of STUMPY is to provide a highly reliable and user-friendly interface for modern time series analysis that can quickly and easily scale up to accommodate your ever-growing data needs.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-kind-of-time-series-analysis-can-be-done-with-stumpy-in-what-fields-do-you-think-it-will-help-the-most&quot;&gt;What kind of time series analysis can be done with Stumpy? In what fields do you think it will help the most?&lt;&#x2F;h4&gt;
&lt;p&gt;As mentioned above, STUMPY is focused on efficiently computing a simple-to-interpret but highly useful data structure called the “matrix profile”. Earlier, Eamonn Keogh, one of the original academic researchers, claimed that “Given the matrix profile, most time series data mining problems are easy or trivial to solve in a few lines of code.” In fact, Keogh and his colleagues have since published over 20 papers demonstrating the many things that can be done once you’ve computed the matrix profile and, below, are a just few examples:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Motif discovery — identify conserved subsequences (related to pattern recognition)&lt;&#x2F;li&gt;
&lt;li&gt;Discord discovery — uncover subsequences that are poorly conserved (related to anomaly detection)&lt;&#x2F;li&gt;
&lt;li&gt;Time series chains — find related patterns that are evolving monotonically over time (related to forecasting)&lt;&#x2F;li&gt;
&lt;li&gt;Semantic segmentation — automatically determine regime changes within your time series data (related to change point detection)&lt;&#x2F;li&gt;
&lt;li&gt;Streaming data analysis&lt;&#x2F;li&gt;
&lt;li&gt;Multi-dimensional matrix profiles&lt;&#x2F;li&gt;
&lt;li&gt;Time series clustering&lt;&#x2F;li&gt;
&lt;li&gt;And more…&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;One of the benefits of computing matrix profiles with STUMPY is that it is 100% domain agnostic. This means that it is completely generalizable and can be applied in any field where you need to analyze continuous sequential data! In addition to the previously published examples, STUMPY has been applied in analyzing the stock market, bettering server uptime and resiliency, investigating call center conversation flow, understanding IoT sensor data, improving cryptocurrency model predictions, and stabilizing ion acceleration at CERN, just to name a few. Today, time series data is ubiquitous in both academia as well as industry and so we believe that STUMPY is a new tool that is extremely well positioned to help researchers and data scientists explore their data in a systematic and focused way and, hopefully, allow them to discover new insights with much less frustration and time spent. If you already have Python installed then you should be able to get started with STUMPY in less time than it takes for you to make a cup of coffee.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-are-the-benefits-of-computing-the-matrix-profile-in-the-context-of-analyzing-a-time-series-what-are-the-advantages-over-other-methods&quot;&gt;What are the benefits of computing the matrix profile in the context of analyzing a time series? What are the advantages over other methods?&lt;&#x2F;h4&gt;
&lt;p&gt;Matrix profiles are simple, intuitive, and interpretable. Basically, if you understand what Pythagorean theorem is then you’re all set! Whereas with other methods, if you step away from the analysis for six months and then come back to it, you often have to perform a lot of mental gymnastics in order to remember and understand what was going on. With a single line of STUMPY code, you can compute your matrix profile and &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;stumpy.readthedocs.io&#x2F;en&#x2F;latest&#x2F;Tutorial_STUMPY_Basics.html&quot;&gt;quickly identify motifs (conserved patterns) and discords (potential anomalies) by looking at the minima and maxima&lt;&#x2F;a&gt;, respectively. From there, a slew of rapid post-analyses can be performed using the matrix profile and the subsequent results can help you develop further hypotheses and questions about your data. Additionally, unlike other methods which may be riddled with false positives and false negatives, matrix profiles are exact and don’t require any “training” in order to find patterns. It just works right out-of-the-box!&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-is-the-general-criteria-when-choosing-a-window-size-is-there-some-indicator-to-look-up-when-analysing-a-time-series&quot;&gt;What is the general criteria when choosing a window size? Is there some indicator to look up when analysing a time series?&lt;&#x2F;h4&gt;
&lt;p&gt;That’s a good question. Usually, the window size (i.e., the length of your subsequence or sliding window) should be chosen to be large enough to encompass a potential pattern. This usually requires a little bit of domain knowledge but the academic researchers have found that matrix profiles are not so sensitive to the choice of the window size so long as it isn’t smaller than the subsequence pattern. So, being in the rough ballpark is usually enough. However, since matrix profiles are pretty fast and cheap to compute, your best bet is to simply try several different window sizes, perhaps, by repeatedly doubling your window size and observing where there may be conserved minima&#x2F;maxima across the set of matrix profiles. The academic researchers have also published a paper (which you can download &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.cs.ucr.edu&#x2F;~eamonn&#x2F;PAN_SKIMP%20%28Matrix%20Profile%20XX%29.pdf&quot;&gt;here&lt;&#x2F;a&gt;) detailing a similar approach called a “pan matrix profile” that can help narrow down the search space. So, look out for this new STUMPY feature in an upcoming release!&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-is-semantic-segmentation-in-the-context-of-time-series-what-were-the-problems-in-the-past-with-this-method-and-how-do-you-solve-them&quot;&gt;What is semantic segmentation in the context of time series? What were the problems in the past with this method and how do you solve them?&lt;&#x2F;h4&gt;
&lt;p&gt;In the context of time series, “semantic segmentation” is “the division of a time series into internally consistent areas&#x2F;regimes” or, sometimes, you can think of it as a “special type of clustering with the additional constraint that the elements in each cluster are contiguous in time”. Basically, if you have a time series where the values are repeating periodically within some range and then, in response to some external change or event, the time series shifts into another mostly periodic range so that you are left with two distinct “regimes”, then semantic segmentation may be useful for helping you identify the boundary in between the regimes. Now, methods like “change point detection” exist for detecting changes in various statistical properties of the time series (i.e., the mean or variance) but, fundamentally, we are interested in regimens which are defined by changes in the shapes of the time series subsequences, which can change without any obvious effect on the statistical properties. And this is where matrix profiles come into play. By simply using the information stored within your matrix profile, you can automatically identify and label these boundary regions in a systematic way. You can learn more in this illustrative &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;stumpy.readthedocs.io&#x2F;en&#x2F;latest&#x2F;Tutorial_Semantic_Segmentation.html&quot;&gt;STUMPY tutorial&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;how-does-the-sampling-rate-affect-the-analysis-of-a-time-series-how-often-are-important-patterns-hidden-because-of-a-bad-sampling-method&quot;&gt;How does the sampling rate affect the analysis of a time series? How often are important patterns hidden because of a bad sampling method?&lt;&#x2F;h4&gt;
&lt;p&gt;In general, sampling rate is quite important but it is often independent of the analysis method. If you have a conserved pattern that spans a full minute (i.e., it is a unique shape that is captured within 60 data points spaced one second apart) but you only collect a single aggregate data point once every hour, then it is impossible for any method to discover this pattern. Conversely, if you collect a data point once every microsecond then you might run out of storage space or lack the ability to analyze this large data set after 5 years. Unfortunately, in either case, having the best algorithms and the fastest hardware will not help you fix poor sampling. Or, as they say, “garbage in, garbage out”.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1--71VCPSQe2aIyw49RucHCQ.png&quot; alt=&quot;&quot; &#x2F;&gt;Source: &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;stumpy.readthedocs.io&#x2F;en&#x2F;latest&#x2F;Tutorial_Time_Series_Chains.html&quot;&gt;Stumpy documentation&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;stumped-is-the-distributed-version-of-stump-and-it-is-implemented-using-dask-why-have-you-chosen-dask-over-other-solutions-to-implement-stumped&quot;&gt;STUMPED is the distributed version of STUMP and it is implemented using Dask. Why have you chosen Dask over other solutions to implement STUMPED?&lt;&#x2F;h4&gt;
&lt;p&gt;As a research scientist, one of my pet peeves is software that is slow or that takes way too much time and effort to install. So, it was imperative for STUMPY to have minimal dependencies, be easy to install, and also be fast and scalable. Initially, when we prototyped STUMPY, everything was written using NumPy and SciPy and this worked well for time series that contained around 10K data points. However, we noticed that not all of the threads on our machine were being used (due to the GIL) and things started to take forever as we increased the length of our time series. At the time, Cython was a popular option for releasing the GIL but it seemed really hard to maintain from a packaging perspective and the coding style never felt “Pythonic”. In contrast, we had starting hearing a lot of great things about Numba’s ability to JIT-compile Python code into performant machine code and so, within two days, we were able to parallelize STUMPY using Numba and leverage all of the compute power available on our local server. For data scientists, this is great and usually sufficient for small to medium-sized data sets but, naturally, we starting thinking about distributed computing. Dask is a wonderful Python package that offers scalable analytics, can be easily distributed to over a thousand servers, and has a large user community. Additionally, we knew that Dask interoperated well with Numba and so, within five days, we were able to go from a single server to distributing our matrix profile computation across a 32 server Dask cluster. While other solutions currently exist for distributed computing, we really liked that Dask was lightweight, heavily battle-tested, and was supported by knowledgeable maintainers who had the right vision. While STUMPY does not leverage Dask’s “big data collections” (i.e., parallel arrays and dataframes), the robust dynamic task scheduling used by STUMPY is well beyond experimental.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;was-gpu-compatibility-challenging-to-integrate-in-the-project&quot;&gt;Was GPU compatibility challenging to integrate in the project?&lt;&#x2F;h4&gt;
&lt;p&gt;This is a great question! In our journey, we carefully assessed the landscape and seriously considered the idea of using PyCUDA, CuPy, TensorFlow, PyTorch, or even writing raw CUDA kernels and interfacing it with Cython. However, these technologies can either be too hard to install, too low level and verbose, too difficult to maintain (or for others to contribute to), or their APIs are simply too unstable. Ultimately, the best solution for adding GPU support was right underneath our noses and we didn’t even need to add any additional dependencies! Because, luckily for us, Numba is also able to JIT-compile Python code to target GPUs. Of course, it is important to point out that since the programming paradigm for GPUs is quite different from CPUs, STUMPY has to maintain separate Python modules that target the different hardware and we’ve had to develop new and unique ways to ensure proper and thorough testing of our software. However, the massive performance benefits gained from leveraging GPUs and not having to switch from Python to writing CUDA is well worth the tradeoffs. If anybody tries to convince you that “Python is slow” then I’d highly recommend trying Numba and Dask as they can easily help take your Python performance scaling to the next level. If you are interested in computing matrix profiles with STUMPY using GPUs then please check out this &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;colab.research.google.com&#x2F;drive&#x2F;1FIbHQoD6mJInkhinoMehBDj2E1i7i2j7&quot;&gt;Google Colab notebook&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;considering-you-have-chosen-numba-for-optimizing-and-parallelizing-computation-have-you-thought-about-using-julia-in-the-future-which-has-built-in-features-for-this-tasks&quot;&gt;Considering you have chosen Numba for optimizing and parallelizing computation, have you thought about using Julia in the future, which has built-in features for this tasks?&lt;&#x2F;h4&gt;
&lt;p&gt;Julia has certainly grown over the years but its adoption has been slow and so we’ve yet to consider it as a viable option. However, given the amount of effort that we’ve put in to keeping our code base easy to read and digest, it shouldn’t be difficult to port STUMPY over to other languages and we’d certainly be open to sharing and collaborating in the future.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;how-do-you-justify-the-comparison-between-the-benchmark-using-256-cpus-stumped-256-against-the-one-using-16-gpus-gpu-stump-dgx2-especially-economically-speaking&quot;&gt;How do you justify the comparison between the benchmark using 256-CPUs (STUMPED.256) against the one using 16 GPUs (GPU-STUMP.DGX2), especially economically speaking?&lt;&#x2F;h4&gt;
&lt;p&gt;The STUMPY README provides rough &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;stumpy.readthedocs.io&#x2F;en&#x2F;latest&#x2F;#performance&quot;&gt;performance benchmarks&lt;&#x2F;a&gt; but the point isn’t to debate whether GPUs are “faster” or “better suited” for computing matrix profiles than CPUs. If you have access to one or more GPUs, then you should definitely use them! However, if you don’t have access to top-of-the-line GPUs or national super computing clusters, STUMPY can still be useful. Benchmarks are always biased and outdated but our goal is to be transparent and to give people a clearer sense of how long their computation might take (depending on the size of their data) and what hardware resources they may need in order to realistically complete their analysis. Otherwise, the user should be able to make an informed decision as to whether or not STUMPY is suitable for their situation. For all intents and purposes, STUMPY is more than “fast enough” and, more importantly, it faithfully reproduces the academic work and users can feel confident that STUMPY can perform equally as well on better hardware and with larger data set! Thanks to Moore’s law, you don’t have to take our word for it. Give STUMPY a try and let us know what you think!&lt;&#x2F;p&gt;
&lt;h4 id=&quot;in-the-paper-presenting-the-stomp-algorithms-an-implementation-in-a-seismologic-dataset-is-shown-working-with-a-really-huge-amount-of-data-and-analysing-it-within-days-how-near-are-we-from-real-time-anomaly-detection-systems-that-analyse-datasets-as-large-at-that-scale&quot;&gt;In the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.cs.ucr.edu&#x2F;~eamonn&#x2F;STOMP_GPU_final_submission_camera_ready.pdf&quot;&gt;paper&lt;&#x2F;a&gt; presenting the STOMP algorithms, an implementation in a seismologic dataset is shown, working with a really huge amount of data and analysing it within days. How near are we from real-time anomaly detection systems that analyse datasets as large at that scale?&lt;&#x2F;h4&gt;
&lt;p&gt;To answer this question, one first needs to clearly define what is meant by “real-time”. Typically, this involves a situation where large amounts of data is being streamed in continuously and at a reasonably high frequency rate. Additionally, when discussing real-time analysis, it is important to identify how much data needs to be collected before the analysis can begin (i.e., is it one data point or do you need to collect 10 days worth of data before you can start) and it is also worth considering whether this is a sliding window analysis (i.e., where the oldest data point is removed as a new data point arrives). I can’t speak directly to the primary research but, in the 100 million data point seismology example, the dataset was actually recorded at 20 Hz and collected over 58 days but the the matrix profile was computed in just over 12 days. In that particular case, the speed of analysis (12 days) was actually faster than the speed of data collection (58 days) and, naturally, if you could initiate your analysis with less data then the matrix profile computation would require substantially less time as well. Of course, this feels more like a batch analysis than a streaming analysis but hopefully the point that we’re trying to make is clear. In fact, the academic researchers have published additional work on how to incrementally update your matrix profile on-the-fly as additional data points are streamed in. This streaming-friendly capability is currently available in STUMPY and more detail can be found in &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;stumpy.readthedocs.io&#x2F;en&#x2F;latest&#x2F;Tutorial_Matrix_Profiles_For_Streaming_Data.html&quot;&gt;this STUMPY tutorial&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;how-do-you-think-stumpy-will-evolve-do-you-have-in-mind-new-features-to-implement-in-the-near-future&quot;&gt;How do you think STUMPY will evolve? Do you have in mind new features to implement in the near future?&lt;&#x2F;h4&gt;
&lt;p&gt;One of the co-founders of Explosion, Ines Montani, gave a &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;speakerdeck.com&#x2F;inesmontani&#x2F;let-them-write-code-keynote-pycon-india-2019&quot;&gt;wonderful talk at PyCon India 2019&lt;&#x2F;a&gt; titled “Let Them Write Code” where she identified that ‘Good tools help people do their work. You don’t have to do their work for them. Worst developer experiences: tools that want to be “fully integrated solution”’, which I think embodies our approach to developing STUMPY. We have purposely limited the scope of STUMPY and stayed laser-focused on making our code base rock solid, performant and well tested, and super user-friendly. While it may be tempting to over-simplify time series analysis and offer additional things like data cleaning or custom visualization tools all in one package, we want to enable all of our users to really think through their analysis approach rather than relying on a package to make false assumptions about their data, which is more than likely to be wrong anyways. To that extent, STUMPY has already achieved its goal in providing an efficient way for users to compute matrix profiles and that is scalable on a wide variety of hardware. Additionally, there has been a lot of interest in &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;stumpy.readthedocs.io&#x2F;en&#x2F;latest&#x2F;api.html&quot;&gt;computing matrix profiles with non-normalized Euclidean distances&lt;&#x2F;a&gt; (as opposed to z-normalized Euclidean distances) and so we’ve added a suite of new features that addresses these needs and you can check out our &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;TDAmeritrade&#x2F;stumpy&#x2F;issues&quot;&gt;current backlog of feature enhancements on our public Github page&lt;&#x2F;a&gt;. There is still a lot of work that needs to be done to socialize the matrix profile approach, to educate others through public talks and tutorials that use real-world examples, and to continue building and fostering a transparent and supportive community. Of course, this will take time and is easier said than done but we’re making progress everyday.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;are-there-any-books-you-recommend-reading-on-the-topic&quot;&gt;Are there any books you recommend reading on the topic?&lt;&#x2F;h4&gt;
&lt;p&gt;Unfortunately, there aren’t any books on the topic yet but, for starters, readers may be interested in exploring the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;stumpy.readthedocs.io&#x2F;en&#x2F;latest&#x2F;tutorials.html&quot;&gt;STUMPY tutorials&lt;&#x2F;a&gt; or watching this &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=xLbPP5xNIJs&quot;&gt;STUMPY video&lt;&#x2F;a&gt; (hosted by the Stitch Fix Algorithms team) as they provide a balanced mixture of background information, relevant context, and technical detail to help you develop the right intuition. Additionally, I strongly recommend skimming the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.cs.ucr.edu&#x2F;~eamonn&#x2F;MatrixProfile.html&quot;&gt;plethora of articles published by Eamonn Keogh’s group&lt;&#x2F;a&gt;. They’re actually a pleasure to read and I continually learn more each time I re-read these foundational papers.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;where-can-readers-find-you-and-where-can-they-learn-more-about-stumpy&quot;&gt;Where can readers find you and where can they learn more about STUMPY?&lt;&#x2F;h4&gt;
&lt;p&gt;I blog occasionally &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;seanlaw.github.io&#x2F;&quot;&gt;on my personal website&lt;&#x2F;a&gt; but you can follow me on Twitter @seanmylaw and you can stay up-to-date on the development of STUMPY @stumpy_dev. Additionally, please post all of your STUMPY questions to our &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;TDAmeritrade&#x2F;stumpy&#x2F;issues&quot;&gt;Github issues page&lt;&#x2F;a&gt; as this will help ensure that all user questions are recorded and searchable by others. Also, we’re always looking for new contributors and, especially if you are a tech minority, we’d love to work together with you. And don’t forget to &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;stumpy.readthedocs.io&#x2F;en&#x2F;latest&#x2F;&quot;&gt;share STUMPY&lt;&#x2F;a&gt; with all of your friends and colleagues and let us know how you are using STUMPY!&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Julia GPU</title>
        <published>2020-10-20T00:00:00+00:00</published>
        <updated>2020-10-20T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/julia-gpu/"/>
        <id>https://blog.lambdaclass.com/posts/julia-gpu/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/julia-gpu/">&lt;h3 id=&quot;how-the-julia-language-is-making-it-easy-for-programmers-to-use-gpu-capabilities-with-juliagpu&quot;&gt;How the Julia language is making it easy for programmers to use GPU capabilities with JuliaGPU&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-KJX3T1Y9T1Cj0aV3m-A22w.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;We are living in a time where more and more data is being created every day as well as new techniques and complex algorithms that try to extract the most out of it. As such, CPU capabilities are approaching a bottleneck in their computing power. GPU computing opened its way into a new paradigm for high-performance and parallel computation a long time ago, but it was not until recently that it become massively used for data science.&lt;br &#x2F;&gt;
In this interview, &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;maleadt&quot;&gt;Tim Besard&lt;&#x2F;a&gt;, one of the main contributors to the JuliaGPU project, digs into some of the details about GPU computing and the features that make Julia a language suited for such tasks, not only from a performance perspective but also from a user one.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h4 id=&quot;please-tell-us-a-bit-about-yourself-what-is-your-background-what-is-your-current-position&quot;&gt;Please tell us a bit about yourself. What is your background? what is your current position?&lt;&#x2F;h4&gt;
&lt;p&gt;I’ve always been interested in systems programming, and after obtaining my CS degree I got the opportunity to start a PhD at Ghent University, Belgium, right when Julia was first released around 2012. The language seemed intriguing, and since I wanted to gain some experience with LLVM, I decided to port some image processing research code from MATLAB and C++ to Julia. The goal was to match performance of the C++ version, but some of its kernels were implemented in CUDA C… So obviously Julia needed a GPU back-end!&lt;&#x2F;p&gt;
&lt;p&gt;That was easier said than done, of course, and much of my PhD was about implementing that back-end and (re)structuring the existing Julia compiler to facilitate these additional back-ends. Nowadays I’m at Julia Computing, where I still work on everything GPU-related.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-is-juliagpu-what-is-the-goal-of-the-project&quot;&gt;What is JuliaGPU? What is the goal of the project?&lt;&#x2F;h4&gt;
&lt;p&gt;JuliaGPU is the name we use to group GPU-related resources in Julia: There’s a &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;JuliaGPU&quot;&gt;GitHub organization&lt;&#x2F;a&gt; where most packages are hosted, a &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;juliagpu.org&#x2F;&quot;&gt;website&lt;&#x2F;a&gt; to point the way for new users, we have &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;JuliaGPU&#x2F;gitlab-ci&quot;&gt;CI infrastructure&lt;&#x2F;a&gt; for JuliaGPU projects, there’s a Slack channel and Discourse category, etc.&lt;&#x2F;p&gt;
&lt;p&gt;The goal of all this is to make it easier to use GPUs for all kinds of users. Current technologies often impose significant barriers to entry: CUDA is fairly tricky to install, C and C++ are not familiar to many users, etc. With the software we develop as part of the JuliaGPU organization, we aim to make it easy to use GPUs, without hindering the ability to optimize or use low-level features that the hardware has to offer.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-is-gpu-computing-how-important-is-it-nowadays&quot;&gt;What is GPU computing? How important is it nowadays?&lt;&#x2F;h4&gt;
&lt;p&gt;GPU computing means using the GPU, a device originally designed for graphics processing, to perform general-purpose computations. It has grown more important now that CPU performance is not improving as steadily as it used to. Instead, specialized devices like GPUs or FPGAs are increasingly used to improve the performance of certain computations. In the case of GPUs, the architecture is a great fit to perform highly-parallel applications. Machine learning networks are a good example of such parallel applications, and their popularity is one of the reasons GPUs have become so important.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;do-you-think-julia-is-an-appropriate-language-to-efficiently-use-gpu-capabilities-why&quot;&gt;Do you think Julia is an appropriate language to efficiently use GPU capabilities? Why?&lt;&#x2F;h4&gt;
&lt;p&gt;Julia’s main advantage is that the language was designed to be compiled. Even though the syntax is high-level, the generated machine code is&lt;br &#x2F;&gt;
compact and has great performance characteristics (for more details, see &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;janvitek.org&#x2F;pubs&#x2F;oopsla18b.pdf&quot;&gt;this paper&lt;&#x2F;a&gt;). This is crucial for GPU execution, where we are required to run native binaries and cannot easily (or efficiently) interpret code as is often required by other language’s semantics.&lt;&#x2F;p&gt;
&lt;p&gt;Because we’re able to directly compile Julia for GPUs, we can use almost all of the language’s features to build powerful abstractions. For example, you can define your own types, use those in GPU arrays, compose that with existing abstractions like lazy “Transpose” wrappers, access those on the GPU while benefiting from automatic bounds-checking (if needed), etc.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;from-a-python-programmer-perspective-how-does-cuda-jl-compare-to-pycuda-are-their-functionalities-equivalent&quot;&gt;From a Python programmer perspective, how does CUDA.jl compare to PyCUDA? Are their functionalities equivalent?&lt;&#x2F;h4&gt;
&lt;p&gt;PyCUDA gives the programmer access to the CUDA APIs, with high-level Python functions that are much easier to use. CUDA.jl provides the same, but in Julia. The &lt;code&gt;hello world&lt;&#x2F;code&gt; from PyCUDA’s home page looks almost identical in Julia:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;using CUDA&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;function multiply_them(dest, a, b)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; i = threadIdx().x&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; dest[i] = a[i] * b[i]&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; return&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;end&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;a = CuArray(randn(Float32, 400))&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;b = CuArray(randn(Float32, 400))&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;dest = similar(a)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;@cuda threads=400 multiply_them(dest, a, b)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;println(dest-a.*b)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;There’s one very big difference: “multiply_them” here is a function written in Julia, whereas PyCUDA uses a kernel written in CUDA C. The reason is straightforward: Python is not simple to compile. Of course, projects like Numba prove that it is very much possible to do so, but in the end those are separate compilers that try to match the reference Python compilers as closely as possible. With CUDA.jl, we integrate with that reference compiler, so it’s much easier to guarantee consistent semantics and follow suit when the language changes (for more details,&lt;br &#x2F;&gt;
refer to &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1712.03112&quot;&gt;this paper&lt;&#x2F;a&gt;).&lt;&#x2F;p&gt;
&lt;h4 id=&quot;are-the-packages-in-the-juliagpu-organization-targeted-to-experienced-programmers-only&quot;&gt;Are the packages in the JuliaGPU organization targeted to experienced programmers only?&lt;&#x2F;h4&gt;
&lt;p&gt;Not at all. CUDA.jl targets different kinds of (GPU) programmers. If you are confident writing your own kernels, you can do so, while using all of the low-level features CUDA GPUs have to offer. But if you are new to the world of GPU programming, you can use high-level array operations that use existing kernels in CUDA.jl. For example, the above element-wise multiplication could just as well be written as:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;using CUDA&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;a = CuArray(randn(Float32, 400))&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;b = CuArray(randn(Float32, 400))&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;dest = a .* b&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;&lt;h4 id=&quot;is-it-necessary-to-know-how-to-code-in-cuda-jl-to-take-full-advantage-of-gpu-computing-in-julia&quot;&gt;Is it necessary to know how to code in CUDA.jl to take full advantage of GPU computing in Julia?&lt;&#x2F;h4&gt;
&lt;p&gt;Not for most users. Julia has a powerful language of generic array operations (“map”, “reduce”, “broadcast”, “accumulate”, etc) which can be applied to all kinds of arrays, including GPU arrays. That means you can often re-use your codebase developed for the CPU with CUDA.jl (&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;abs&#x2F;pii&#x2F;S0965997818310123&quot;&gt;this paper&lt;&#x2F;a&gt; shows some powerful examples). Doing so often requires minimal changes: changing the array type, making sure you use array operations instead of for loops, etc.&lt;&#x2F;p&gt;
&lt;p&gt;It’s possible you need to go beyond this style of programming, e.g., because your application doesn’t map cleanly onto array operations, to use specific GPU features, etc. In that case, some basic knowledge about CUDA and the GPU programming model is sufficient to write kernels in CUDA.jl.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;how-is-the-experience-of-coding-a-kernel-in-cuda-jl-in-comparison-to-cuda-c-and-how-transferable-is-the-knowledge-to-one-another&quot;&gt;How is the experience of coding a kernel in CUDA.jl in comparison to CUDA C and how transferable is the knowledge to one another?&lt;&#x2F;h4&gt;
&lt;p&gt;It’s very similar, and that’s by design: We try to keep the kernel abstractions in CUDA.jl close to their CUDA C counterparts such that the programming environment is familiar to existing GPU programmers. Of course, by using a high-level source language there’s many quality-of-life improvements. You can allocated shared memory, for example, statically and dynamically as in CUDA C, but instead of a raw pointers we use an N-dimensional array object you can easily index. An example from the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;developer.nvidia.com&#x2F;blog&#x2F;using-shared-memory-cuda-cc&#x2F;&quot;&gt;NVIDIA developer blog&lt;&#x2F;a&gt;:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;__global__ void staticReverse(int *d, int n)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;{&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; __shared__ int s[64];&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; int t = threadIdx.x;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; int tr = n-t-1;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; s[t] = d[t];&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; __syncthreads();&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; d[t] = s[tr];&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;}&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The CUDA.jl equivalent of this kernel looks very familiar, but uses array objects instead of raw pointers:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;function staticReverse(d)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; s = @cuStaticSharedMem(Int, 64)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; t = threadIdx().x&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; tr = length(d)-t+1&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; s[t] = d[t]&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; sync_threads()&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; d[t] = s[tr]&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; return&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;end&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Using array objects has many advantages, e.g. multi-dimensional is greatly simplified and we can just do “d[i,j]”. But it’s also safer, because these accesses are bounds checked:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;julia&amp;gt; a = CuArray(1:64)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;64-element CuArray{Int64,1}:&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 1&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 2&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 3&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; ⋮&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 62&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 63&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 64&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;julia&amp;gt; @cuda threads=65 staticReverse(a)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;ERROR: a exception was thrown during kernel execution.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;Stacktrace:&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; [1] throw_boundserror at abstractarray.jl:541&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Bounds checking isn’t free, of course, and once we’re certain our code is correct we can add an “@inbounds” annotation to our kernel and get the high-performance code we expect:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;julia&amp;gt; @device_code_ptx @cuda threads=64 staticReverse(a)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;.visible .entry staticReverse(.param .align 8 .b8 d[16]) {&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; .reg .b32 %r&amp;lt;2&amp;gt;;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; .reg .b64 %rd&amp;lt;15&amp;gt;;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; .shared .align 32 .b8 s[512];&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;mov.b64 %rd1, d;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; ld.param.u64 %rd2, [%rd1];&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; ld.param.u64 %rd3, [%rd1+8];&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; mov.u32 %r1, %tid.x;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; cvt.u64.u32 %rd4, %r1;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; mul.wide.u32 %rd5, %r1, 8;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; add.s64 %rd6, %rd5, -8;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; add.s64 %rd7, %rd3, %rd6;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; ld.global.u64 %rd8, [%rd7+8];&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; mov.u64 %rd9, s;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; add.s64 %rd10, %rd9, %rd6;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; st.shared.u64 [%rd10+8], %rd8;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; bar.sync 0;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; sub.s64 %rd11, %rd2, %rd4;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; shl.b64 %rd12, %rd11, 3;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; add.s64 %rd13, %rd9, %rd12;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; ld.shared.u64 %rd14, [%rd13+-8];&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; st.global.u64 [%rd7+8], %rd14;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; ret;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;}&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;julia&amp;gt; a&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;64-element CuArray{Int64,1}:&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 64&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 63&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 62&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; ⋮&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 3&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 2&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 1&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Tools like “@device_code_ptx” make it easy for an experienced developer to inspect generated code and ensure the compiler does what he wants.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;why-does-having-a-compiler-have-such-an-impact-in-libraries-like-cuda-jl-how-was-the-process-of-integrating-it-to-the-julia-compiler&quot;&gt;Why does having a compiler have such an impact in libraries like CUDA.jl? (How was the process of integrating it to the Julia compiler?)&lt;&#x2F;h4&gt;
&lt;p&gt;Because we have a compiler at our disposal, we can rely on higher-order functions and other generic abstractions that specialize based on the arguments that users provide. That greatly simplifies our library, but also gives the user very powerful tools. As an example, we have carefully implemented a &lt;code&gt;mapreduce&lt;&#x2F;code&gt; function that uses shared memory, warp intrinsics, etc to perform a high-performance reduction. The implementation is generic though, and will automatically re-specialize (even at run time) based on the arguments to the function:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;julia&amp;gt; mapreduce(identity, +, CuArray([1,2,3]))&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;6&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;julia&amp;gt; mapreduce(sin, *, CuArray([1.1,2.2,3.3]))&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;-0.11366175839582586&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;With this powerful &lt;code&gt;mapreduce&lt;&#x2F;code&gt; abstraction, implemented by a experienced GPU programmer, other developers can create derived abstractions without such experience. For example, let’s implement a &lt;code&gt;count&lt;&#x2F;code&gt; function that evaluates for how many items a predicate holds true:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;count(predicate, array) = mapreduce(predicate, +, array)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;julia&amp;gt; a = CUDA.rand(Int8, 4)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;4-element CuArray{Int8,1}:&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 51&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 3&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 70&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 100&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;julia&amp;gt; count(iseven, a)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;2&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Even though our &lt;code&gt;mapreduce&lt;&#x2F;code&gt; implementation has not been specifically implemented for the &lt;code&gt;Int8&lt;&#x2F;code&gt; type or the &lt;code&gt;iseven&lt;&#x2F;code&gt; predicate, the Julia compiler automatically specializes the implementation, resulting in kernel optimized for this specific invocation.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-were-the-biggest-challenges-when-developing-packages-for-juliagpu-particularly-writing-a-low-level-package-such-as-cuda-jl-in-a-high-level-programming-language-such-as-julia&quot;&gt;What were the biggest challenges when developing packages for JuliaGPU, particularly writing a low level package such as CUDA.jl in a high level programming language such as Julia?&lt;&#x2F;h4&gt;
&lt;p&gt;Much of the initial work focused on developing tools that make it possible to write low-level code in Julia. For example, we developed the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;maleadt&#x2F;LLVM.jl&quot;&gt;LLVM.jl&lt;&#x2F;a&gt; package that gives us access to the LLVM APIs. Recently, our focus has shifted towards generalizing this functionality so that other GPU back-ends, like &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;JuliaGPU&#x2F;AMDGPU.jl&quot;&gt;AMDGPU.jl&lt;&#x2F;a&gt; or &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;JuliaGPU&#x2F;oneAPI.jl&quot;&gt;oneAPI.jl&lt;&#x2F;a&gt; can benefit from developments to CUDA.jl. Vendor-neutral array operations, for examples, are now implemented in &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;JuliaGPU&#x2F;GPUArrays.jl&quot;&gt;GPUArrays.jl&lt;&#x2F;a&gt; whereas shared compiler functionality now lives in &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;JuliaGPU&#x2F;GPUCompiler.jl&quot;&gt;GPUCompiler.jl&lt;&#x2F;a&gt;. That should make it possible to work on several GPU back-ends, even though most of them are maintained by only a single developer.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;regarding-the-latest-release-announced-in-the-juliagpu-blog-about-multi-device-programming-what-are-the-difficulties-that-this-new-functionality-solves-is-this-relevant-in-the-industry-where-big-computational-resources-are-needed&quot;&gt;Regarding the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;juliagpu.org&#x2F;2020-07-18-cuda_1.3&#x2F;&quot;&gt;latest release&lt;&#x2F;a&gt; announced in the JuliaGPU blog about multi-device programming, what are the difficulties that this new functionality solves? Is this relevant in the industry where big computational resources are needed?&lt;&#x2F;h4&gt;
&lt;p&gt;In industry or large research labs, MPI is often used to distribute work across multiple nodes or GPUs. Julia’s MPI.jl supports that use case, and integrates with CUDA.jl where necessary. The multi-device functionality added to CUDA 1.3 additionally makes it possible to use multiple GPUs within a single process. It maps nicely on Julia’s task-based concurrency, and makes it easy to distribute work within a single node:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;Threads.@threads for dev in devices()&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; device!(dev)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; # do some work here&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;end&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;&lt;h4 id=&quot;what-are-the-plans-for-the-near-future&quot;&gt;&lt;strong&gt;What are the plans for the near future?&lt;&#x2F;strong&gt;&lt;&#x2F;h4&gt;
&lt;p&gt;There aren’t any specific roadmaps, but one upcoming major feature is proper support for reduced-precision inputs, like 16-bits floating point. We already support Float16 arrays where CUBLAS or CUDNN does, but the next version of Julia will make it possible to write kernels that operate on these values.&lt;&#x2F;p&gt;
&lt;p&gt;Other than that, features come as they do :-) Be sure to subscribe to the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;juliagpu.org&#x2F;post&#x2F;&quot;&gt;JuliaGPU blog&lt;&#x2F;a&gt; where we publish a short post for every major release of Julia’s GPU back-ends.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;You can find Tim at @&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;maleadt&quot;&gt;maleadt&lt;&#x2F;a&gt; on Twitter!&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>For the first time, enjoy all the talks of BuzzConf 2020 online and free of charge!</title>
        <published>2020-07-26T00:00:00+00:00</published>
        <updated>2020-07-26T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/for-the-first-time-enjoy-all-the-talks-of-buzzconf-2020-online-and-free-of-charge/"/>
        <id>https://blog.lambdaclass.com/posts/for-the-first-time-enjoy-all-the-talks-of-buzzconf-2020-online-and-free-of-charge/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/for-the-first-time-enjoy-all-the-talks-of-buzzconf-2020-online-and-free-of-charge/">&lt;h3 id=&quot;come-see-buzzconf-2020-a-software-and-data-science-conference-open-and-online-for-one-and-for-all&quot;&gt;Come see BuzzConf 2020, a software and data science conference, open and online for one and for all!&lt;&#x2F;h3&gt;
&lt;p&gt;The third edition of BuzzConf will be held freely online via Zoom and Youtube live. We’re very proud of our speaker lineup, which covers a wide range of topics that expand the frontiers of our technical knowledge.&lt;&#x2F;p&gt;
&lt;p&gt;We will dive into the topics of functional programming, Julia, Python, data science, machine learning, observability, operating systems and more! We believe Functional Programming and Data Science are two of the most interesting topics in the field which will open many opportunities in the near future, and we want to bring the latest developments in these areas to the global community.&lt;&#x2F;p&gt;
&lt;p&gt;This conference is the result of a combined effort of private and public sectors from Argentina, which aspires to help the development of our country’s technical capabilities while spreading and sharing knowledge with the world.&lt;&#x2F;p&gt;
&lt;p&gt;We thank the generosity of the speakers who agreed to donate their time and we hope you enjoy their talks as much as we will.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-LzNJkTEcILfT_6U8t2baDg.jpeg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;mon-july-27-2pm-pdt-6pm-gmt-3-9pm-utc&quot;&gt;Mon, July 27–2pm PDT &#x2F; 6pm GMT-3 &#x2F; 9pm UTC&lt;&#x2F;h3&gt;
&lt;h3 id=&quot;charity-majors-what-got-you-here-won-t-get-you-there-how-your-team-can-become-a-high-performing-team-by-embracing-observability&quot;&gt;Charity Majors — “What got you here won’t get you there: How your team can become a high-performing team by embracing observability”&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;em&gt;To Be Announced&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Join us on Zoom:&lt;&#x2F;em&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;zoom.us&#x2F;j&#x2F;92898927496&quot;&gt;&lt;em&gt;https:&#x2F;&#x2F;zoom.us&#x2F;j&#x2F;92898927496&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Join us on YouTube:&lt;&#x2F;em&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;youtu.be&#x2F;QK6zEFdvXYw&quot;&gt;&lt;em&gt;https:&#x2F;&#x2F;youtu.be&#x2F;QK6zEFdvXYw&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;0-fTWA2R7HUM90oPA7.jpeg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;mon-july-27-3pm-pdt-7pm-gmt-3-10pm-utc&quot;&gt;Mon, July 27–3pm PDT &#x2F; 7pm GMT-3 &#x2F; 10pm UTC&lt;&#x2F;h3&gt;
&lt;h3 id=&quot;maria-vanina-martinez-symbolic-reasoning-to-model-sentiment-and-knowledge-diffusion-in-social-networks&quot;&gt;María Vanina Martinez: “Symbolic Reasoning to model Sentiment and Knowledge Diffusion in Social Networks”&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;em&gt;Social media platforms, taken in conjunction, can be seen as complex networks; in this context, understanding how agents react to sentiments expressed by their connections is of great interest. We show how Network Knowledge Bases help represent the integration of multiple social networks, and explore how information flow can be handled via belief revision operators for local (agent-specific) knowledge bases. We report on preliminary experiments on Twitter data showing that different agent types react differently to the same information — this is a first step toward developing symbolic tools to predict how agents behave asinformation flows in their social environment.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Join us on Zoom:&lt;&#x2F;em&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;zoom.us&#x2F;j&#x2F;92898927496&quot;&gt;&lt;em&gt;https:&#x2F;&#x2F;zoom.us&#x2F;j&#x2F;92898927496&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Join us on YouTube:&lt;&#x2F;em&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;youtu.be&#x2F;QK6zEFdvXYw&quot;&gt;&lt;em&gt;https:&#x2F;&#x2F;youtu.be&#x2F;QK6zEFdvXYw&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;0-Urum4vQ0RP0TZub3.jpeg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;tue-july-28-2pm-pdt-6pm-gmt-3-9pm-utc&quot;&gt;Tue, July 28–2pm PDT &#x2F; 6pm GMT-3 &#x2F; 9pm UTC&lt;&#x2F;h3&gt;
&lt;h3 id=&quot;will-kurt-the-limits-of-probability&quot;&gt;Will Kurt: “The Limits of Probability”&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;em&gt;Probability is an increasingly ubiquitous part of our daily lives, especially as developers, researchers and data scientists. It is easy to mistakenly think this powerful tool is all we need to understand our world. This talk will show how our current environment of global pandemic, political unrest and economic uncertainty forces us to face the limits of probability as a tool for reasoning and understanding. This talk will cover both practical examples of the limitations of probability as well as dive into the philosophical roots of these limitations to show that it cannot be our only means to engage with our world.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Join us on Zoom:&lt;&#x2F;em&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;zoom.us&#x2F;j&#x2F;97859783809&quot;&gt;&lt;em&gt;https:&#x2F;&#x2F;zoom.us&#x2F;j&#x2F;97859783809&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Join us on YouTube:&lt;&#x2F;em&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;youtu.be&#x2F;N75ebGWz2o4&quot;&gt;&lt;em&gt;https:&#x2F;&#x2F;youtu.be&#x2F;N75ebGWz2o4&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;0-a3kX6m-ky8tQK27S.jpeg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;tue-july-28-3pm-pdt-7pm-gmt-3-10pm-utc&quot;&gt;Tue, July 28–3pm PDT &#x2F; 7pm GMT-3 &#x2F; 10pm UTC&lt;&#x2F;h3&gt;
&lt;h3 id=&quot;lightning-talks&quot;&gt;Lightning Talks&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;strong&gt;Juan Pablo Lorenzo:&lt;&#x2F;strong&gt; “Delete your code: in search of a minimalist approach to software development”&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Gajendra Deshpande:&lt;&#x2F;strong&gt; “Computation Techniques for Encrypted Data using Python”&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Join us on Zoom:&lt;&#x2F;em&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;zoom.us&#x2F;j&#x2F;97859783809&quot;&gt;&lt;em&gt;https:&#x2F;&#x2F;zoom.us&#x2F;j&#x2F;97859783809&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Join us on YouTube:&lt;&#x2F;em&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;youtu.be&#x2F;N75ebGWz2o4&quot;&gt;&lt;em&gt;https:&#x2F;&#x2F;youtu.be&#x2F;N75ebGWz2o4&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;wed-july-29-2pm-pdt-6pm-gmt-3-9pm-utc&quot;&gt;Wed, July 29–2pm PDT &#x2F; 6pm GMT-3 &#x2F; 9pm UTC&lt;&#x2F;h3&gt;
&lt;h3 id=&quot;aditya-siram-what-fp-can-learn-from-static-introspection&quot;&gt;Aditya Siram: “What FP Can Learn From Static Introspection”&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;em&gt;What if compile time and type level programming in functional programming languages were easy, something you reach for without even thinking about it? What if you could debug type errors with a simple compile time print statement? Write highly flexible systems by being able to introspect into types at compile time? Pre-calculate large portions of your programs for great efficiency? Typed functional programming is a great and fun way to write resilient software, and as type systems have become more and more expressive in recent years, we are able to program sophisticated and useful properties at the type level for even better compile time safety. Just one problem: It is very difficult, requires advanced knowledge of the type system, the syntax is convoluted, the error messages are impenetrable, and it is nearly impossible to debug. This talk will dive into why we should steal static introspection from languages like Nim, and D, state-of-the-art imperative programming languages which can solve all these issues, make type systems much more approachable without losing any expressive power, and offer new design possibilities for functional programs.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Join us on Zoom:&lt;&#x2F;em&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;zoom.us&#x2F;j&#x2F;95139644343&quot;&gt;&lt;em&gt;https:&#x2F;&#x2F;zoom.us&#x2F;j&#x2F;95139644343&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Join us on YouTube:&lt;&#x2F;em&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;youtu.be&#x2F;yGq0KnkqOgI&quot;&gt;&lt;em&gt;https:&#x2F;&#x2F;youtu.be&#x2F;yGq0KnkqOgI&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;0-Koxyxq-wrBx9iGfe.jpeg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;wed-july-29-3pm-pdt-7pm-gmt-3-10pm-utc&quot;&gt;Wed, July 29–3pm PDT &#x2F; 7pm GMT-3 &#x2F; 10pm UTC&lt;&#x2F;h3&gt;
&lt;h3 id=&quot;sergio-chouhy-deeploying-deep-q-learning-with-pytorch&quot;&gt;Sergio Chouhy: “Deeploying Deep Q Learning with Pytorch”&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;em&gt;Many things are being said about Deep Reinforcement Learning, but sometimes it is really hard to know where to start. In this talk, I will tell you all about the basis of this algorithms and show you how to deploy Deep Q Learning from scratch using Pytorch. I will be also talking about industrial applications for this technology.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Join us on Zoom:&lt;&#x2F;em&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;zoom.us&#x2F;j&#x2F;95139644343&quot;&gt;&lt;em&gt;https:&#x2F;&#x2F;zoom.us&#x2F;j&#x2F;95139644343&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Join us on YouTube:&lt;&#x2F;em&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;youtu.be&#x2F;yGq0KnkqOgI&quot;&gt;&lt;em&gt;https:&#x2F;&#x2F;youtu.be&#x2F;yGq0KnkqOgI&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;0-82lbeMCqONPXiKq1.jpeg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;thu-july-30-2pm-pdt-6pm-gmt-3-9pm-utc&quot;&gt;Thu, July 30–2pm PDT &#x2F; 6pm GMT-3 &#x2F; 9pm UTC&lt;&#x2F;h3&gt;
&lt;h3 id=&quot;viral-b-shah-julia-a-language-for-ai-and-much-more&quot;&gt;Viral B. Shah: “Julia — A language for AI and much more”&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;em&gt;The Julia language is now used by over half a million programmers worldwide. Created to solve the two language problem, Julia is demonstrating performance gains of 50x-100x for many data science tasks such as data loading, data processing, graph processing, machine learning and scaling. Robust support for modern deep learning and the ability to do differentiable programming in an intuitive way is quickly leading to Julia becoming the language of choice for AI workloads. My talk will discuss the origin story of Julia, the formation of the Julia community, and all the amazing things happening in the world of Julia.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Join us on Zoom:&lt;&#x2F;em&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;zoom.us&#x2F;j&#x2F;94906592252&quot;&gt;&lt;em&gt;https:&#x2F;&#x2F;zoom.us&#x2F;j&#x2F;94906592252&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Join us on YouTube:&lt;&#x2F;em&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;youtu.be&#x2F;fbKHLdoG7wA&quot;&gt;&lt;em&gt;https:&#x2F;&#x2F;youtu.be&#x2F;fbKHLdoG7wA&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;0--gyZtKfGpWBIxRoz.jpeg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;thu-july-30-3pm-pdt-7pm-gmt-3-10pm-utc&quot;&gt;Thu, July 30–3pm PDT &#x2F; 7pm GMT-3 &#x2F; 10pm UTC&lt;&#x2F;h3&gt;
&lt;h3 id=&quot;chris-rackauckas-sciml-how-language-is-changing-scientific-research&quot;&gt;Chris Rackauckas: “SciML: How Language is Changing Scientific Research”&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;em&gt;Scientific machine learning is a burgeoning field and its taking off in Julia. Why? The purpose of this talk is to dive into that question: how has language accelerated the development of Julia’s SciML ecosystem? The core is composibility through multiple dispatch. We will showcase how this feature is not only what makes standard Julia code as fast as C or Fortran, but also allows Julia to eschew the traditional idea of “machine learning frameworks” and instead have machine learning directly work on the standard functions and libraries of the whole Julia programming language. This language-wide differentiable programming then builds a foundation where existing climate models, helicopter simulations, and efficiency simulators for battery-powered airplanes can be instantly composed with new tools for machine learning, and we will demonstrate how this has changed the way that researchers in Julia do science.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Join us on Zoom:&lt;&#x2F;em&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;zoom.us&#x2F;j&#x2F;94906592252&quot;&gt;&lt;em&gt;https:&#x2F;&#x2F;zoom.us&#x2F;j&#x2F;94906592252&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Join us on YouTube:&lt;&#x2F;em&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;youtu.be&#x2F;fbKHLdoG7wA&quot;&gt;&lt;em&gt;https:&#x2F;&#x2F;youtu.be&#x2F;fbKHLdoG7wA&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;0-2EbV5-0r03R6aPYH.jpeg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;fri-july-31-2pm-pdt-6pm-gmt-3-9pm-utc&quot;&gt;Fri, July 31–2pm PDT &#x2F; 6pm GMT-3 &#x2F; 9pm UTC&lt;&#x2F;h3&gt;
&lt;h3 id=&quot;pablo-fernandez-machine-learning-in-the-real-world&quot;&gt;Pablo Fernandez: “Machine Learning in The Real World”&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;em&gt;A tour of the last 3 years of my career where I’ve productionized 3 different machine learning projects on kind-of-a-big-company (Despegar). Some of the challenges faced, not only technical but also from a product standpoint, some of the pedagogical work needed to convince others of letting important decisions be made by a machine. Hopefully insights that help you bring your own models to production.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Join us on Zoom:&lt;&#x2F;em&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;zoom.us&#x2F;j&#x2F;92628004626&quot;&gt;&lt;em&gt;https:&#x2F;&#x2F;zoom.us&#x2F;j&#x2F;92628004626&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Join us on YouTube:&lt;&#x2F;em&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;youtu.be&#x2F;t-ebpSHyBEE&quot;&gt;&lt;em&gt;https:&#x2F;&#x2F;youtu.be&#x2F;t-ebpSHyBEE&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;0-7y4gqQ8d8_6veW_j.jpeg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;fri-july-31-3pm-pdt-7pm-gmt-3-10pm-utc&quot;&gt;Fri, July 31–3pm PDT &#x2F; 7pm GMT-3 &#x2F; 10pm UTC&lt;&#x2F;h3&gt;
&lt;h3 id=&quot;peter-alvaro-what-not-where-why-a-blue-sky-os&quot;&gt;Peter Alvaro: “What not where: why a blue sky OS?”&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;em&gt;A world of distributed, persistent memory is on its way. Our programming models traditionally operate on short-lived data representations tied to ephemeral contexts such as processes or computers. In the limit, however, data lifetime is infinite compared to these transient actors. We discuss the implications for programming models raised by a world of large and potentially persistent distributed memories, including the need for explicit, context-free, invariant data references. We present a novel operating system that uses wisdom from both storage and distributed systems to center the programming model around data as the primary citizen, and reflect on the transformative potential of this change for infrastructure and applications of the future.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Join us on Zoom:&lt;&#x2F;em&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;zoom.us&#x2F;j&#x2F;92628004626&quot;&gt;&lt;em&gt;https:&#x2F;&#x2F;zoom.us&#x2F;j&#x2F;92628004626&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Join us on YouTube:&lt;&#x2F;em&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;youtu.be&#x2F;t-ebpSHyBEE&quot;&gt;&lt;em&gt;https:&#x2F;&#x2F;youtu.be&#x2F;t-ebpSHyBEE&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;0-MOD81ymGRUNUrv7m.jpeg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;We hope to see you there! There will be time for Q&amp;amp;A with the speakers. &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.eventbrite.com.ar&#x2F;e&#x2F;buzzconf-2020-tickets-111836742708&quot;&gt;Register now&lt;&#x2F;a&gt;!&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Soss: Probabilistic Programming with Julia</title>
        <published>2020-05-19T00:00:00+00:00</published>
        <updated>2020-05-19T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/soss-probabilistic-programming-with-julia/"/>
        <id>https://blog.lambdaclass.com/posts/soss-probabilistic-programming-with-julia/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/soss-probabilistic-programming-with-julia/">&lt;h4 id=&quot;an-interview-with-its-creator-chad-scherrer&quot;&gt;An interview with its creator, Chad Scherrer&lt;&#x2F;h4&gt;
&lt;p&gt;By: Javier Rodríguez Chatruc and Federico Carrone&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-m6924vcooeuQEu7FiBOI5A.png&quot; alt=&quot;&quot; &#x2F;&gt;Credit: Chad Scherrer&lt;&#x2F;p&gt;
&lt;p&gt;Probabilistic programming is at this point an established field both for research and industry applications, but like everything else (especially in the tech industry), it is undergoing constant evolution. This is where &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;julialang.org&#x2F;&quot;&gt;Julia&lt;&#x2F;a&gt; comes in — designed for high performance in the world of data science, it seems to be the perfect fit for probabilistic programming.&lt;&#x2F;p&gt;
&lt;p&gt;To learn more about this world we contacted &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;chadscherrer&quot;&gt;Chad Scherrer&lt;&#x2F;a&gt;, the creator of &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;cscherrer&#x2F;Soss.jl&quot;&gt;Soss&lt;&#x2F;a&gt;, a probabilistic programming library written entirely in Julia. With a very clean syntax resembling math notation, Soss seems to bridge the gap between the more academic side of data science and the more technical&#x2F;developer one, while also providing speed and &lt;em&gt;first-class&lt;&#x2F;em&gt; models.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h4 id=&quot;please-tell-us-a-bit-about-yourself-what-is-your-background-what-is-your-current-position&quot;&gt;Please tell us a bit about yourself. What is your background? what is your current position?&lt;&#x2F;h4&gt;
&lt;p&gt;Starting out, I thought I would end up focusing on algebraic topology. So I did coursework along these lines for a few years before switching to stats. My thesis is on a special case of multivariate normal distributions with a group symmetry, so algebra still plays a big part.&lt;&#x2F;p&gt;
&lt;p&gt;After graduating, I worked at Pacific Northwest National Laboratory, mostly doing computational statistics. I learned some Python, then R. The high-level coding was nice, but I was frustrated by how awkward it was to make it fast.&lt;&#x2F;p&gt;
&lt;p&gt;One day I came across this “Great Computer Language Shootout”, where Ocaml was really dominating. So I used that for a few years. Then multicore hardware started really picking up, but at the time the Ocaml team said they wouldn’t really be doing anything with SMP (symmetric multiprocessing). So I started looking around again, and found Haskell.&lt;&#x2F;p&gt;
&lt;p&gt;Along the way, I had collaborated with the high-performance computing group doing &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1206.6409.pdf&quot;&gt;parallel&lt;&#x2F;a&gt; &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1212.4174v1.pdf&quot;&gt;machine learning&lt;&#x2F;a&gt; using C&#x2F;OpenMP. And I started getting interested in probabilistic programming. I wanted to make something like &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;mcmc-jags.sourceforge.net&#x2F;&quot;&gt;JAGS&lt;&#x2F;a&gt;, but using Haskell and allowing more high-level expressiveness. So I collaborated with Galois to develop &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;cscherrer.github.io&#x2F;pdf&#x2F;Scherrer%20-%202012%20-%20Passage%20A%20Parallel%20Sampler%20Generator%20for%20Hierarchical%20Bayesian%20Modeling.pdf&quot;&gt;Passage&lt;&#x2F;a&gt;, which works in terms of a now-standard probability monad, and produces C&#x2F;OpenMP code for parallel Gibbs sampling.&lt;&#x2F;p&gt;
&lt;p&gt;Based on the Passage work, Galois started getting involved with &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.darpa.mil&#x2F;program&#x2F;probabilistic-programming-for-advancing-machine-Learning&quot;&gt;&lt;em&gt;Probabilistic Programming for Advancing Machine Learning (PPAML)&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;, but they needed someone to serve as technical lead. So I moved to Portland and did that for a few years. Galois is a (mostly) Haskell shop, so I was able to dig deeper into both Haskell and probabilistic programming.&lt;&#x2F;p&gt;
&lt;p&gt;Still wanting to extend some of the ideas from Passage, I moved to Seattle and spent a couple of years at &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.thisismetis.com&#x2F;&quot;&gt;Metis&lt;&#x2F;a&gt; teaching data science. In my free time, I got more up to speed on &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;julialang.org&#x2F;&quot;&gt;Julia&lt;&#x2F;a&gt;, and started work on what would become &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;cscherrer&#x2F;Soss.jl&quot;&gt;Soss&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;These days, I work as a Senior Research Scientist at &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.relational.ai&#x2F;&quot;&gt;RelationalAI&lt;&#x2F;a&gt;. Most machine learning pipelines treat database queries and model training as entirely independent, so to go between them requires throwing away all of the structure and just joining everything.&lt;&#x2F;p&gt;
&lt;p&gt;As it turns out, that throws away some big opportunities for optimization. So our system has an expressive language for reasoning about relational structure, and works in terms that make these optimizations natural for machine learning and probabilistic programming.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-is-probabilistic-programming-how-does-it-differ-from-other-forms-of-programming&quot;&gt;What is probabilistic programming? How does it differ from other forms of programming?&lt;&#x2F;h4&gt;
&lt;p&gt;When people talk about &lt;em&gt;Probabilistic Programming Languages&lt;&#x2F;em&gt; (PPLs), they usually mean a system for building and reasoning about Bayesian models. Maybe the simplest way to think about this is as a way of reasoning about simulations. Say you have a simulation that you can run to make a simulated “world”. Every part of the simulation has some randomness. This includes the things you can actually observe, but also the underlying choices the simulator made for things that affect those observations. But those are random too, so they might depend on &lt;em&gt;other&lt;&#x2F;em&gt; random choices.&lt;&#x2F;p&gt;
&lt;p&gt;Ok, so choices made along the way will affect the distribution of things downstream. But we can also use this to reason the other way! We observe some data, and ask “what choices along the way could have led to this?”&lt;&#x2F;p&gt;
&lt;p&gt;In the simplest case, say we have a simulation for biased coin flips where we pick a random probability of heads, say &lt;code&gt;p ~ Uniform(0,1)&lt;&#x2F;code&gt;, and simulate 20 flips. Then we observe 15 heads and 5 tails. We can’t say for certain what &lt;code&gt;p&lt;&#x2F;code&gt; was, but we can find a distribution that’s updated based on the observed data.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;how-did-you-get-into-julia-why-choose-julia-over-python-or-r&quot;&gt;How did you get into Julia? Why choose Julia over Python or R?&lt;&#x2F;h4&gt;
&lt;p&gt;I want to be able to express ideas at a high level of abstraction without sacrificing performance. I’ve used Python and R quite a bit, for the things I wanted to do I always felt constrained because getting performance always means pushing things to another language. Then there are concerns with the cost of crossing that language barrier, both in a human and computational sense.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-is-soss-how-did-it-come-about-and-what-was-the-motivation-behind-it&quot;&gt;What is Soss? How did it come about and what was the motivation behind it?&lt;&#x2F;h4&gt;
&lt;p&gt;Soss is a Julia-based PPL that represents the right-hand side of each assignment (&lt;code&gt;=&lt;&#x2F;code&gt;) and sample (&lt;code&gt;~&lt;&#x2F;code&gt;) as an AST. The nice thing about this is, it gives ultimate flexibility in what a model can do. For example, we have inference methods that take a &lt;code&gt;Model&lt;&#x2F;code&gt; and return an &lt;code&gt;AST&lt;&#x2F;code&gt; that generates code at run-time, but we also have model transformation functions that return another model. Models are first-class, and can be used inside other models, etc.&lt;&#x2F;p&gt;
&lt;p&gt;There are some other things too, for example we have an interface to SymPy so you can easily get to a symbolic representation of the log-density. Simplifications here can lead to faster code, so we also have a way to generate SSA Julia code from this. There’s still plenty more speed to be had, but I’ve seen 100x-1000x speedup with this vs a direct implementation.&lt;&#x2F;p&gt;
&lt;p&gt;I’ve wanted to build Soss for a long time, it was just a matter of finding a language with metaprogramming support that could handle the syntax I wanted, while also having the speed and a good numerically-oriented ecosystem.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;how-does-the-probabilistic-programming-ecosystem-in-julia-compare-to-the-ones-in-python-r-in-particular-how-does-soss-compare-to-pymc3&quot;&gt;How does the probabilistic programming ecosystem in Julia compare to the ones in Python&#x2F;R? In particular, how does Soss compare to PyMC3?&lt;&#x2F;h4&gt;
&lt;p&gt;To get speed, both Python and R have to call to other languages. I’ve spent a lot of time using PyMC3, and I really like it. But it still requires keeping in your head which lines of code are talking to Python, vs which are talking to Theano. There’s a language barrier to play across, and losing track of it tends to break things.&lt;&#x2F;p&gt;
&lt;p&gt;When you write a Soss model, it’s all Julia. You can use Julia functions freely. Even if you want to do Soss development (please do!), it’s still all Julia.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;on-that-note-who-is-the-end-user-for-the-library-is-it-mostly-just-used-in-academic-settings-or-are-there-industry-uses-as-well&quot;&gt;On that note, who is the end user for the library, is it mostly just used in academic settings or are there industry uses as well?&lt;&#x2F;h4&gt;
&lt;p&gt;It’s certainly intended for both. One thing I like about the AST approach is that generated code can be as fast as you can make it.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-were-the-biggest-challenges-in-developing-probabilistic-programming-for-a-new-language&quot;&gt;What were the biggest challenges in developing probabilistic programming for a new language?&lt;&#x2F;h4&gt;
&lt;p&gt;There’s always some overhead in learning a new programming language. Julia has a very Python-like syntax, so learning the basics was very fast. But metaprogramming requires different ways of thinking about things, so that took a lot of spinning up.&lt;&#x2F;p&gt;
&lt;p&gt;Macros weren’t enough, we had to use Julia’s &lt;code&gt;@generated&lt;&#x2F;code&gt; functions, which let you do staged programming. Even with this, the types weren’t quite working out, so I was using &lt;code&gt;eval&lt;&#x2F;code&gt; all over the place, which does evaluation in global scope and can cause some problems.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;thautwarm.github.io&#x2F;Site-32&#x2F;index.html&quot;&gt;Taine Zhao&lt;&#x2F;a&gt; got us out of the rut with some great Julia packages like &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;thautwarm&#x2F;GeneralizedGenerated.jl&quot;&gt;GeneralizedGenerated.jl&lt;&#x2F;a&gt;. Generated functions compile new code for each new type they’re evaluated on, so she realized the model’s type could contain a representation of the entire model. It’s a clever solution, and helped a lot of other parts of the design to fall into place.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;there-seems-to-be-an-explosion-in-probabilistic-programming-on-julia-with-other-libraries-like-turing-or-gen-how-does-soss-compare-to-them&quot;&gt;There seems to be an explosion in probabilistic programming on Julia with other libraries like Turing or Gen, how does Soss compare to them?&lt;&#x2F;h4&gt;
&lt;p&gt;I’d say the syntax is closer to Turing, but the semantics are closer to Gen.&lt;&#x2F;p&gt;
&lt;p&gt;The Gen team independently came up with the same approach we’re using of representing a model as a function. In most PPLs, the model includes some indication of which data will later be observed. But leaving this out until inference time makes it much easier to compose models in different ways.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;any-books-you-recommend-reading-on-the-topic-besides-the-classics-statistical-rethinking-and-bayesian-methods-for-hackers&quot;&gt;Any books you recommend reading on the topic, besides the classics Statistical Rethinking and Bayesian Methods for Hackers?&lt;&#x2F;h4&gt;
&lt;p&gt;Both of these are great. If you’re interested in a particular system, most of the well-funded ones have a nice collection of examples and tutorials; walking through those usually helps.&lt;&#x2F;p&gt;
&lt;p&gt;If you want a broader and deeper view, I’d suggest digging into Bayesian analysis directly. One of my favorites is David MacKay’s &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;www.inference.org.uk&#x2F;mackay&#x2F;itila&#x2F;&quot;&gt;Information Theory, Inference, and Learning Algorithms&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-s-next-for-soss&quot;&gt;What’s next for Soss?&lt;&#x2F;h4&gt;
&lt;p&gt;There’s always more to do. Currently we’re starting work to make the documentation better. I think we need lots more examples, tutorials, and comparisons to other systems.&lt;&#x2F;p&gt;
&lt;p&gt;If you have any questions about Soss, the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;discourse.julialang.org&#x2F;&quot;&gt;Julia Discourse&lt;&#x2F;a&gt; or &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;julialang.zulipchat.com&quot;&gt;Zulip&lt;&#x2F;a&gt; are both great. And of course, there’s always GitHub issues for &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;cscherrer&#x2F;Soss.jl&quot;&gt;the Soss repo&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>A brief introduction to the beauty of Information Theory</title>
        <published>2020-05-06T00:00:00+00:00</published>
        <updated>2020-05-06T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/a-brief-introduction-to-the-beauty-of-information-theory/"/>
        <id>https://blog.lambdaclass.com/posts/a-brief-introduction-to-the-beauty-of-information-theory/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/a-brief-introduction-to-the-beauty-of-information-theory/">&lt;h4 id=&quot;or-how-to-be-a-hardcore-guess-who-gamer&quot;&gt;Or how to be a hardcore Guess Who gamer&lt;&#x2F;h4&gt;
&lt;p&gt;&lt;em&gt;Authors: Juan Pablo Amoroso, Javier Rodríguez Chatruc, Camilo Plata, and Federico Carrone.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;The fundamental problem of communication is that of reproducing at one point either exactly or approximately a message selected at another point.&lt;br &#x2F;&gt;
— Claude Shannon, 1948&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;Imagine you were tasked with designing a comunications system between a space station and a ground control headquarters back in Earth. The system would transmit and receive messages encoded in binary, that is, as a sequence of 1s and 0s. As the message travels, there may be interferences from other radio signals, so that what is picked up in ground control is not exactly the same as the original message. Under these circumstances, is it possible to devise a scheme that allows reliable comunication?&lt;&#x2F;p&gt;
&lt;p&gt;A simple workaround would be to add redundancy: send each bit a number of times, let’s say 5:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;11111&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;00000&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;…&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If ground control receives the message &lt;em&gt;11101&lt;&#x2F;em&gt; , they could be fairly certain that what was truly sent was &lt;em&gt;11111&lt;&#x2F;em&gt;. Although this simple system would work (up to a point), we can see that it is very wasteful: we have to send 4 extra bits for every bit in the original message. The &lt;em&gt;transmission rate&lt;&#x2F;em&gt; is therefore only 20%. Can we do any better?&lt;&#x2F;p&gt;
&lt;p&gt;There seems to be a dilemma here: if we want accuracy, we must lower the rate of transmission.&lt;&#x2F;p&gt;
&lt;p&gt;This is the problem Claude Shannon tackled in his 1948 paper &lt;em&gt;A Mathematical Theory of Communication&lt;&#x2F;em&gt;. In it, he proved that there is a limit for the rate of information that can be reliably transmitted over a noisy channel (the &lt;em&gt;Shannon limit&lt;&#x2F;em&gt;). However, below this limit we can transmit information with an increasingly small error. This important result tells us that there &lt;em&gt;exists&lt;&#x2F;em&gt; a code that allows arbitrary accuracy over a given comunication channel, but it does not tell us how to build it.&lt;&#x2F;p&gt;
&lt;p&gt;More precisely, let’s say a channel has a probability &lt;em&gt;p&lt;&#x2F;em&gt; of transmitting a bit correctly, and a corresponding probability of 1 —  &lt;em&gt;p&lt;&#x2F;em&gt; of sending the wrong bit, Shannon proved that the optimum rate of transmission is:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-kCNAUFlhWJv1kUzKatqINA.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-TgCse1znfuWYULYwXeo4Aw.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The plot is symmetrical around &lt;em&gt;p = 0.5&lt;&#x2F;em&gt; , with maxima at &lt;em&gt;p = 0&lt;&#x2F;em&gt; and &lt;em&gt;p = 1&lt;&#x2F;em&gt;. The case of &lt;em&gt;p = 0&lt;&#x2F;em&gt; is interesting, the channel has perfect noise: it flips all the bits in the original message. But if we know that, then the message is trivially deciphered, we just flip them back.&lt;&#x2F;p&gt;
&lt;p&gt;The formula is commonly stated in terms of &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Entropy_%28information_theory%29&quot;&gt;information entropy&lt;&#x2F;a&gt;, a measure Shannon devised that can be interpreted as the level of ‘uncertainty’ or ‘surprise’ associated with the channel.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-fCyO-nZidJEiOqwqDGWJ3g.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-s0z3MUCTtJvh_AsvxGg72g.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;We can see that the entropy has a maximum at 1 when &lt;em&gt;p&lt;&#x2F;em&gt; = ½, and minima at 0 for &lt;em&gt;p =&lt;&#x2F;em&gt; 0 and &lt;em&gt;p =&lt;&#x2F;em&gt; 1.&lt;&#x2F;p&gt;
&lt;p&gt;More generally, given a random message &lt;em&gt;M&lt;&#x2F;em&gt; that can take &lt;em&gt;n&lt;&#x2F;em&gt; different values with probability &lt;em&gt;pᵢ&lt;&#x2F;em&gt; for &lt;em&gt;i =&lt;&#x2F;em&gt; 1,…,&lt;em&gt;n&lt;&#x2F;em&gt; , we define the entropy of the message as:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-ezweLprVK1INseQwDCN2yg.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;guess-who-example&quot;&gt;Guess Who example&lt;&#x2F;h4&gt;
&lt;p&gt;Let’s take a different approach. Suppose you are playing &lt;em&gt;Guess Who&lt;&#x2F;em&gt; , the game where you ask yes&#x2F;no questions about the appearance of your opponent’s character in order to single him or her out among a set of characters. You ask yourself: what order should I ask the questions in to maximise the probability of winning? Intutively, you try to ask first about features most of the characters have.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-TkW9quvg52IBgM06fM-7IA.jpeg&quot; alt=&quot;&quot; &#x2F;&gt;Hardcore Guess Who gamers apply Information Theory for optimal results&lt;&#x2F;p&gt;
&lt;p&gt;Moreover, an optimal question is one that divides the population evenly, that is, one that regardless of the answer (&lt;em&gt;yes&lt;&#x2F;em&gt; or &lt;em&gt;no&lt;&#x2F;em&gt;) discards half the characters. In any other case, you are not gaining the optimal amount of information with each question.&lt;&#x2F;p&gt;
&lt;p&gt;But what if you can’t divide the characters evenly by their characteristics? To answer the question, first we recall the concept of entropy defined above. We can think of a question as a variable &lt;em&gt;X&lt;&#x2F;em&gt; that splits the population into groups &lt;em&gt;xᵢ&lt;&#x2F;em&gt; with probabilities &lt;em&gt;pᵢ&lt;&#x2F;em&gt;. For example, think of a question about the eye color of the character (the questions in the game are technically only &lt;em&gt;yes&lt;&#x2F;em&gt; or &lt;em&gt;no&lt;&#x2F;em&gt; but this can be generalized). With this in mind, the entropy of a question becomes:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-KZq1CO03SyEnsH0qLamzRQ.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The intuition here is that with each possible answer, we gain an amount of information  &lt;em&gt;— log&lt;&#x2F;em&gt; &lt;em&gt;p&lt;&#x2F;em&gt;(&lt;em&gt;x&lt;&#x2F;em&gt; ᵢ), meaning that if we receive an answer with a very low probability (i.e. we ask if the character has a feature that is shared by very few people, and the answer is yes), the amount of information we gained is higher than an answer with more probability.&lt;&#x2F;p&gt;
&lt;p&gt;On the other hand, entropy is related to uncertainty. For example, if we flip a coin, the uncertainty in the outcome is higher with a &lt;em&gt;p&lt;&#x2F;em&gt; = 0.5 than with any other value of &lt;em&gt;p&lt;&#x2F;em&gt;. And in our case, more uncertainty is better. Why? If we choose a question with an uneven distribution in the population, lets say 0.7 and 0.3, the odds are that our character is among the 70%, discarding with the &lt;em&gt;no&lt;&#x2F;em&gt; answer only the remaining 30%, but with a more even division (and therefore more uncertain), we always tend to discard 50% of the population, leading to an advantage in the long run. This means that the best questions to ask are those that maximize the entropy, i.e, the ones with the higher uncertainty.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;decision-trees&quot;&gt;Decision Trees&lt;&#x2F;h4&gt;
&lt;p&gt;One common use of entropy is in decision trees, where one uses a set of features (features that split the data into disjoint sets) to construct a flowchart for a classification problem. Here, a common question is: which order should we “apply” the features in to get the best splits? A possible solution is to recursively always use the feature that maximizes the &lt;em&gt;information gain&lt;&#x2F;em&gt;. If we’re working with a dataset &lt;em&gt;S&lt;&#x2F;em&gt; and our feature is called &lt;em&gt;X&lt;&#x2F;em&gt; , the information gained on &lt;em&gt;S&lt;&#x2F;em&gt; by &lt;em&gt;X&lt;&#x2F;em&gt; , &lt;em&gt;I&lt;&#x2F;em&gt;(&lt;em&gt;S&lt;&#x2F;em&gt; ,&lt;em&gt;X&lt;&#x2F;em&gt;), is calculated as:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-tIzlfBpMihRvpfZICpWZJA.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;where &lt;em&gt;H&lt;&#x2F;em&gt;(&lt;em&gt;S&lt;&#x2F;em&gt; |&lt;em&gt;X&lt;&#x2F;em&gt;) is the conditional entropy of &lt;em&gt;S&lt;&#x2F;em&gt; given &lt;em&gt;X&lt;&#x2F;em&gt;. Intuitively, this is just the reduction in the entropy of the dataset &lt;em&gt;S&lt;&#x2F;em&gt; if we know &lt;em&gt;X&lt;&#x2F;em&gt;. Thus, it makes sense to choose the features &lt;em&gt;X&lt;&#x2F;em&gt; that maximize this value, as they will be the ones that reduce uncertainty the most, effectively obtaining the best splits.&lt;&#x2F;p&gt;
&lt;p&gt;Algorithms that consider the information gain at each node to choose the next feature are called &lt;em&gt;greedy&lt;&#x2F;em&gt; algorithms. Such algorithms do not take into account the overall information gain and may lead in some cases to suboptimal queries, but they are well-behaved and have a straightforward approach.&lt;&#x2F;p&gt;
&lt;p&gt;As an example, consider the picture below, where a decision tree method was used on the famous Iris flower dataset and two features were selected, the petal width, first with 0.8 cm as a threshold and then 1.75 cm. Setting aside how these specific features are selected, why use the ≤ 0.8 first? With the information gain calculation we described, we can provide an answer. We will call the feature that separates petal width on 0.8 cm &lt;em&gt;X&lt;&#x2F;em&gt; and the other one &lt;em&gt;Y&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-dEesB-YyIVG81qhIDn_T_w.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Applying &lt;em&gt;X&lt;&#x2F;em&gt; first splits the 150 data points (usually one would split between training and test sets, here for simplicity we use the entire set) into two sets: one containing the entire &lt;em&gt;setosa&lt;&#x2F;em&gt; class (50 points, corresponding to ≤ 0.8 cm) and nothing else, and the other containing the rest. In that case the calculations yield:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-2dDOZS_8PGYonq3RZYoyAg.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;On the other hand, applying &lt;em&gt;Y&lt;&#x2F;em&gt; first gives us one set with 50 &lt;em&gt;setosa&lt;&#x2F;em&gt; , 49 &lt;em&gt;versicolor&lt;&#x2F;em&gt; and 5 &lt;em&gt;virginica&lt;&#x2F;em&gt; (≤ 1.75 cm) and another with no &lt;em&gt;setosa&lt;&#x2F;em&gt; , 1 &lt;em&gt;versicolor&lt;&#x2F;em&gt; and 45 &lt;em&gt;virginica&lt;&#x2F;em&gt;. This leaves us with:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-VCQsujq_mEufMZi1X4DGdw.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Thus the information gain from &lt;em&gt;X&lt;&#x2F;em&gt; (petal width being under or over 0.8 cm) is greater than the one from &lt;em&gt;Y&lt;&#x2F;em&gt; , and we should use it first. This makes sense intuitively, as &lt;em&gt;X&lt;&#x2F;em&gt; completely separates the &lt;em&gt;setosa&lt;&#x2F;em&gt; class from the other two, whereas using &lt;em&gt;Y&lt;&#x2F;em&gt; first gives a more entangled split.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h4&gt;
&lt;p&gt;It is hard to overstate the importance of Shannon’s work: the Theory of Information has found &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.britannica.com&#x2F;science&#x2F;information-theory&#x2F;Applications-of-information-theory&quot;&gt;many applications&lt;&#x2F;a&gt; in fields as diverse as statistical inference and machine learning, natural language processing, genetics, data compression, coding theory, and cryptography. With over 120,000 citations, few papers can boast a similar impact. In the words of information theorist Anthony Ephremides:&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;It was like an earthquake and the aftershocks haven’t finished yet!&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Weld: accelerating numpy, scikit and pandas as much as 100x with Rust and LLVM</title>
        <published>2019-09-21T00:00:00+00:00</published>
        <updated>2019-09-21T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/weld-accelerating-numpy-scikit-and-pandas-as-much-as-100x-with-rust-and-llvm/"/>
        <id>https://blog.lambdaclass.com/posts/weld-accelerating-numpy-scikit-and-pandas-as-much-as-100x-with-rust-and-llvm/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/weld-accelerating-numpy-scikit-and-pandas-as-much-as-100x-with-rust-and-llvm/">&lt;h3 id=&quot;interview-with-weld-s-main-contributor-accelerating-numpy-scikit-and-pandas-as-much-as-100x-with-rust-and-llvm&quot;&gt;Interview with Weld’s main contributor: accelerating numpy, scikit and pandas as much as 100x with Rust and LLVM&lt;&#x2F;h3&gt;
&lt;p&gt;After working for weeks with Python’s and R’s data science stack I started to ask my self if there could be a common intermediate representation, similar to CUDA, that could be used by many languages. There should be something better than reimplementing and optimizing the same methods in each language. In addition to that, having a common runtime that could optimize the whole program instead of each function separately would be better. After a few days of researching and testing different projects I found &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.weld.rs&#x2F;&quot;&gt;Weld&lt;&#x2F;a&gt; (you can also read its &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;cs.stanford.edu&#x2F;~matei&#x2F;papers&#x2F;2017&#x2F;cidr_weld.pdf&quot;&gt;paper&lt;&#x2F;a&gt;). To my surprise, one of the creators of Weld is &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;matei_zaharia&quot;&gt;Matei Zaharia&lt;&#x2F;a&gt;, who also is the creator of Spark.&lt;&#x2F;p&gt;
&lt;p&gt;That is how I contacted and interviewed &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;shoumik.xyz&#x2F;&quot;&gt;Shoumik Palkar&lt;&#x2F;a&gt;, the main contributor of Weld. Shoumik is a Ph.D. student in the Computer Science department at Stanford University, that is advised by Matei Zaharia.&lt;&#x2F;p&gt;
&lt;p&gt;Weld is far from being production ready but it is promising. If you are interested in the future of data science and in Rust, you will like this interview.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-hqC6KtF-l1RN8uDg99rmow.png&quot; alt=&quot;&quot; &#x2F;&gt;Not a Monad Tutorial new logo!&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;&lt;strong&gt;What was the motivation to develop weld and what problem’s does it solve?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The motivation behind Weld is to provide bare-metal performance for applications that rely on existing high-level APIs such as NumPy and Pandas. The main problem it solves is enabling cross-function and cross-library optimizations that other libraries today don’t provide. In particular, many commonly used libraries provide state-of-the-art implementations for algorithms on a per-function basis (e.g., a fast join algorithm implemented in C in Pandas, or a fast matrix multiply in NumPy), but do not provide any facility for enabling optimization across these functions (e.g., preventing unnecessary scans of memory when performing a matrix multiply followed by an aggregation). Weld provides a common runtime that enables libraries to express computations in a common IR; that IR can then be optimized using a compiler optimizer, and can then be JIT’d to parallel native machine code with optimizations such as loop fusion, vectorization, etc. Weld’s IR is natively parallel, so programs expressed in it can always be trivially parallelized.&lt;&#x2F;p&gt;
&lt;p&gt;We also have a new project called split annotations which will integrate with Weld that’s meant to lower the barrier for enabling these optimizations in existing libraries.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Optimizing numpy, pandas and scikit wouldn’t be easier? How faster it is?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Weld provides optimizations across functions in these libraries, whereas optimizing these libraries would only make individual function calls faster. In fact, many of these data libraries are already highly optimized on a per-function basis, but deliver performance below the limits of modern hardware because they do not exploit parallelism or do not make efficient use of the memory hierarchy. For example, many NumPy ndarray functions are already implemented in C, but calling each function requires scanning over each input in entirety. If these arrays do not fit in the CPU caches, most of the execution time can go into loading data from main memory rather than performing computations. Weld can look across individual function calls and perform optimizations such as loop fusion that will keep data in the CPU caches or registers. These kinds of optimizations can improve performance by over an order of magnitude on multi-core systems, because they enable better scaling.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-eheS9p1hxxEPH8Fqo3As8A.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;strong&gt;Prototype integrations of Weld with Spark (top left), NumPy (top right), and TensorFlow (bottom left) show up to 30x improvements over the native framework implementations, with no changes to users’ application code. Cross library optimizations between Pandas and NumPy (bottom right) can improve performance by up to two orders of magnitude.&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What is Baloo?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Baloo is a library that implements a subset of the Pandas API using Weld. It was developed by Radu Jica, who was a Master’s student in CWI in Amsterdam. The goal of Baloo is to provide the kinds of optimizations described above in Pandas to improve its single-threaded performance, reduce memory usage, and to enable parallelism.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Does Weld&#x2F;Baloo support out-of-core operations (say, like Dask) to handle data that does not fit in memory?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Weld and Baloo currently do not support out-of-core operations, though we’d love open source contributions on this kind of work!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Why did you choose Rust and LLVM to implement weld? Was Rust your first choice?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;We chose Rust because:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;It has a very minimal runtime (essentially just bounds checks on arrays) and is easy to embed into other languages such as Java and Python&lt;&#x2F;li&gt;
&lt;li&gt;It contains functional programming paradigms such as pattern matching that make writing code such as pattern matching compiler optimizations easier&lt;&#x2F;li&gt;
&lt;li&gt;It has a great community and high quality packages (called “crates” in Rust) that made developing our system easier.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;We chose LLVM because its an open source compiler framework that has wide use and support; we generate LLVM directly instead of C&#x2F;C++ so we don’t need to rely on the existence of a C compiler, and because it improves compilation times (we don’t need to parse C&#x2F;C++ code).&lt;&#x2F;p&gt;
&lt;p&gt;Rust was not the first language in which Weld was implemented; the first implementation was in Scala, which was chosen because of its algebraic data types and powerful pattern matching. This made writing the optimizer, which is the core part of the compiler, very easy. Our original optimizer was based on the design of Catalyst, which is Spark SQL’s extensible optimizer. We moved away from Scala because it was too difficult to embed a JVM-based language into other runtimes and languages.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;If Weld targets CPU and GPUS how does it compare to projects like RAPIDS that implements python data science libraries but for the GPU?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The main way Weld differs from systems such as RAPIDS is that it focuses on optimizing applications across individually written kernels by JIT compiling code rather than providing optimized implementations of individual functions. For example, Weld’s GPU backend would JIT-compile a single CUDA kernel optimized for the end-to-end application on the fly rather than calling existing individual kernels. In addition, Weld’s IR is meant to be hardware independent, allowing it to target GPUs as well as CPUs or custom hardware such as vector accelerators. Of course, Weld overlaps significantly and is influenced by many other projects in the same space, including RAPIDS. Runtimes such as Bohrium (a lazily evaluated NumPy) and Numba (a Python library that enables JIT compilation of numerical code) both share Weld’s high level goals, while optimizers systems such as Spark SQL have directly impacted Weld’s optimizer design.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Does weld have other applications outside data science library optimizations?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;One of the most exciting aspects of Weld’s IR is that it supports data parallelism natively. This means that loops expressed in the Weld IR are always safe to parallelize. This makes Weld an attractive IR for targeting new kinds of hardware. For example, collaborators at NEC have demonstrated that they can use Weld to run Python workloads on a custom high-memory-bandwidth vector accelerator just by adding a new backend to the existing Weld IR. The IR can also be used to implement the physical execution layer in a database, and we plan to add features that will make it possible to compile a subset of Python to Weld code as well.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Are the libraries ready to be used on real-life projects? If not, when can we expect them to be ready?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Many of the examples and benchmarks we’ve tested these libraries on are taken from real workloads, so we’d love it if users tried out the current versions for their own applications, provided feedback, and (best of all) submitted open source patches. That said, we don’t expect everything to work out of the box on real-life applications just yet. Our next few releases over the following couple months are focusing exclusively on usability and robustness of the Python libraries; our goal is to make the libraries good enough for inclusion in real-life projects, and to seamlessly fall back to the non-Weld versions of the libraries in places where support is yet to be added.&lt;&#x2F;p&gt;
&lt;p&gt;As I mentioned on the first answer, one path toward making this easier comes in the form of a related project called split annotations (&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;weld-project&#x2F;split-annotations&quot;&gt;code&lt;&#x2F;a&gt; and &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;shoumik.xyz&#x2F;static&#x2F;papers&#x2F;mozart-sosp19final.pdf&quot;&gt;academic paper&lt;&#x2F;a&gt;). Split annotations are a system that allow annotating existing code to define how to split, pipeline, and parallelize it. They provide the optimization that we found was most impactful in Weld (keeping chunks of data in the CPU caches between function calls rather than scanning over the entire dataset), but they are significantly easier to integrate than Weld because they reuse existing library code rather than relying on a compiler IR. This also makes them easier to maintain and debug, which in turn improves their robustness. Libraries without full Weld support can fall back to split annotations when Weld is not supported, which will allow us to incrementally add Weld support based on feedback from users while still enabling some new optimizations.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Interview with Dask’s creator: Scale your Python from one computer to a thousand</title>
        <published>2019-09-03T00:00:00+00:00</published>
        <updated>2019-09-03T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/interview-with-dasks-creator-scale-your-python-from-one-computer-to-a-thousand/"/>
        <id>https://blog.lambdaclass.com/posts/interview-with-dasks-creator-scale-your-python-from-one-computer-to-a-thousand/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/interview-with-dasks-creator-scale-your-python-from-one-computer-to-a-thousand/">&lt;p&gt;My love for building distributed systems with Erlang, databases and fetching huge volumes of data still lives on. But nowadays I want to have better theoretical and practical tools to understand the data. That is why I have been seriously studying probability, statistics and getting better at Python, numpy, pandas, scikit-learn, scipy and R. If you have read my earlier interviews you are probably aware of this.&lt;&#x2F;p&gt;
&lt;p&gt;That is why I decided to interview Dask’s creator Matthew Rocklin. Dask is a great bridge between the two areas that we specialize at my company &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;lambdaclass.com&#x2F;&quot;&gt;LambdaClass&lt;&#x2F;a&gt;: distributed systems and data science. Dask is a great tool to parallelize python libraries. When you have some spare time I highly recommend that you check its code. Meanwhile I leave you with Matthew’s answers.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;&lt;strong&gt;What is Dask? Why did you create it?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Dask is a Python library designed to parallelize other common Python libraries, like NumPy, Pandas, Scikit-Learn and others. It helps people use Python on either a single multi-core machine, or a large distributed cluster.&lt;&#x2F;p&gt;
&lt;p&gt;People tend to use it either as a “Big Pandas” or “Big NumPy”, or as a lower level library to build their own parallel systems.&lt;&#x2F;p&gt;
&lt;p&gt;Originally we created Dask to parallelize Numpy and Pandas. We quickly found that the internals of Dask were useful for many more things, so we quickly pivoted to exposing the internals as a generic parallel system.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Dask dataframes are a full replacement of pandas dataframes?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;No, the Pandas API is &lt;strong&gt;huge&lt;&#x2F;strong&gt; , so a full replacement is nearly impossible.&lt;&#x2F;p&gt;
&lt;p&gt;That being said, Dask Dataframe does implement the vast majority of popularly used Pandas functionality. Common staples like elementwise, reductions, groupbys, joins, rolling, timeseries, and more operations are all there. Additionally, because Dask dataframes are just a bunch of Pandas dataframes spread around a cluster it’s often pretty easy to convert custom code from Pandas to Dask easily.&lt;&#x2F;p&gt;
&lt;p&gt;It’s also worth noting that Dask != Dask Dataframes. Dataframes only account&lt;br &#x2F;&gt;
for about a third of Dask use out there. Dask goes way beyond just&lt;br &#x2F;&gt;
parallelizing Pandas.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Is there any downside of using Dask dataframes instead of pandas dataframes?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Oh definitely. If Pandas is solving your problem today, please don’t switch to Dask.&lt;&#x2F;p&gt;
&lt;p&gt;As with any distributed system, Dask adds a lot of complexity like network&lt;br &#x2F;&gt;
overheads, function serialization, and longer tracebacks in errors. We do a&lt;br &#x2F;&gt;
lot of work to keep our overhead small, both by keeping Dask lightweight and&lt;br &#x2F;&gt;
taking care of Python usability, but still, if you don’t need to switch, then&lt;br &#x2F;&gt;
don’t.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;How is it different form other distributed computation solutions (eg Hadoop MapReduce, Spark, Storm, Luigi, Airflow)?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Dask is a bit lower level and more generic than those systems, and so can be used to build up similar solutions using existing Python libraries.&lt;&#x2F;p&gt;
&lt;p&gt;For example:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;When we combine Dask with Pandas we get &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;docs.dask.org&#x2F;en&#x2F;latest&#x2F;dataframe.html&quot;&gt;Dask Dataframes&lt;&#x2F;a&gt;, which are comparable with Spark DataFrames&lt;&#x2F;li&gt;
&lt;li&gt;When we combine Dask with Scikit-Learn we get &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;ml.dask.org&quot;&gt;Dask-ML&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;When we combine Dask with Python’s &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;docs.dask.org&#x2F;en&#x2F;latest&#x2F;futures.html&quot;&gt;futures or async&#x2F;await&lt;&#x2F;a&gt; APIs we get a real-time framework, somewhat similar to Storm&lt;&#x2F;li&gt;
&lt;li&gt;When we combine Dask with &lt;em&gt;cron&lt;&#x2F;em&gt; like logic, we get an ETL framework like Airflow or Luigi. In fact, some of the Airflow developers split off and made &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.prefect.io&#x2F;&quot;&gt;Prefect&lt;&#x2F;a&gt; a successor to Airflow which delegates the execution and data movement to Dask&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Additionally, Dask can be combined with other libraries to get novel systems&lt;br &#x2F;&gt;
that aren’t in your list. For example:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;When we combine Dask with Numpy we get a scalable multi-dimensional &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;docs.dask.org&#x2F;en&#x2F;latest&#x2F;array.html&quot;&gt;Dask Arrays&lt;&#x2F;a&gt;.&lt;&#x2F;li&gt;
&lt;li&gt;When we combine Dask with GPU-accelerated Pandas or Numpy like libraries like &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;rapids.ai&quot;&gt;RAPIDS&lt;&#x2F;a&gt; we get distributed GPU-accelerated dataframes and arrays.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Internally, Dask has the scalability of a system like MapReduce or Spark, with&lt;br &#x2F;&gt;
the flexibility of a system like Luigi or Airflow. This combination is nice both when you’re building new systems, and means that Dask gets used in a ton of novel work.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;How does data locality affect the performance of Dask? Does it assume all data is local to workers?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;By data locality you might mean two things (both of which Dask handles well):&lt;&#x2F;p&gt;
&lt;p&gt;1. Where does the data live in some storage system, like S3 or HDFS?&lt;&#x2F;p&gt;
&lt;p&gt;Dask is more than happy to query a data-local storage system like HDFS,&lt;br &#x2F;&gt;
find out where all the data lives, and target computations appropriately.&lt;&#x2F;p&gt;
&lt;p&gt;However, this kind of workload is becoming increasingly rare. More often&lt;br &#x2F;&gt;
people are using storage systems that prefer global accessibility over data&lt;br &#x2F;&gt;
locality, so this matters less and less these days in practice.&lt;&#x2F;p&gt;
&lt;p&gt;2. Once data is in memory, can Dask avoid moving it around?&lt;&#x2F;p&gt;
&lt;p&gt;Dask thinks a lot about where to run computations, and avoiding needless&lt;br &#x2F;&gt;
data communication is a big part of this decision. Sometimes we do need to&lt;br &#x2F;&gt;
move data around, but yes, Dask certainly avoids this when possible.&lt;&#x2F;p&gt;
&lt;p&gt;Moreover, because Dask gets used with a &lt;strong&gt;wide&lt;&#x2F;strong&gt; variety of workloads, our&lt;br &#x2F;&gt;
scheduling heuristics have had to evolve quite a bit over the years. It’s very&lt;br &#x2F;&gt;
rare for us to find problems today on which Dask’s data locality heuristics&lt;br &#x2F;&gt;
don’t respond optimally.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What is the biggest Dask cluster you have seen in production?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;One thousand Windows machines.&lt;&#x2F;p&gt;
&lt;p&gt;Dask gets used on some of the world’s largest super-computers (I was&lt;br &#x2F;&gt;
logged into &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.olcf.ornl.gov&#x2F;summit&quot;&gt;Summit&lt;&#x2F;a&gt;, the worlds largest super computer, just a few hours ago), and is deployed routinely on all major clouds.&lt;&#x2F;p&gt;
&lt;p&gt;However, Dask also scales down nicely. You can also just &lt;em&gt;import dask&lt;&#x2F;em&gt; and run it on a thread pool in a single python process or Jupyter notebook. As we like to say, &lt;em&gt;“The median cluster size is one”&lt;&#x2F;em&gt;. Dask is pure-Python, and super-lightweight if it needs to be. You can just &lt;code&gt;pip install dask&lt;&#x2F;code&gt; and it ships with the popular Anaconda distribution, which is deployed on millions of machines around the world.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;The Dask scheduler and Dask worker architecture, implementation and protocol was inspired by any other project?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The central scheduler + distributed worker architecture is pretty common today. It’s a pragmatic choice for systems that want to scale between 1–1000 nodes.&lt;&#x2F;p&gt;
&lt;p&gt;So sure, Dask was inspired by other projects. All of them :). Notably, Dask tries hard not to reinvent too much. We rely a ton on other infrastructure within the Python ecosystem. We use Tornado and asyncio for concurrency and peer-to-peer networking, Numpy, Pandas, and Scikit-learn for computation, and other Python APIs like concurrent.futures and joblib for user APIs.&lt;&#x2F;p&gt;
&lt;p&gt;Dask is really just a smashing together of Python’s networking stack with its&lt;br &#x2F;&gt;
data science stack. Most of the work was already done by the time we got here.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Which do are for you the most interesting frameworks, tools or libraries implemented on top of Dask and why?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I’ll list a few interesting frameworks, but there are a ton out there these days:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;xarray.pydata.org&quot;&gt;Xarray&lt;&#x2F;a&gt; is a library commonly used to study Earth system data, like the climate, meteorology, oceanography, satellite imagery, and more. It’s really gratifying to see people use Dask to finally be able to analyze these huge climate science simulations, and help us better understand the planet.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;prefect.io&quot;&gt;Prefect&lt;&#x2F;a&gt; provides a bunch of niceties on top of Dask for common Data Engineering or ETL workloads, similar to Airflow&#x2F;Luigi. We got these feature requests constantly when we were starting out but declared them out of scope. It was great to have another project come by, take that feature set, and implement it way better than we ever could.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;epistasislab.github.io&#x2F;tpot&quot;&gt;TPot&lt;&#x2F;a&gt; is a library for automatic machine learning. You give it a dataset, and it tries out a bunch of models and pre-processors to find a good model. TPot existed well before Dask, and it has really gnarly parallelism internally, which makes it hard for non-experts to accelerate. Fortunately the TPot and Dask developers were able to get this going in a weekend, and now you can scale out this search with Dask on whatever parallel hardware you have.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;rapids.ai&quot;&gt;RAPIDS&lt;&#x2F;a&gt; is a GPU-accelerated data science stack by NVIDIA. They were building out their own fast GPU implementation of Pandas and Numpy and wanted something to solve the multi-node problem for them. Dask was able to step in, handle all of the distributed communication, scheduling, and load balancing, and then step aside while NVIDIA’s fast GPU algorithms took over. (disclaimer, this is my current employer).&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;Could you please tell us about the work you are doing at NVIDIA to offload Dask computations to the GPU?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Yeah, RAPIDS is really exciting. It turns out that GPUs are good for things other than graphics and deep learning. They’re surprisingly effective at accelerating more traditional computing in data science (and actual science). Operations like dataframe joins, CSV parsing, FFTs, text processing, and more can often be accelerated 10x-200x. Historically you had to know C and CUDA to use these libraries though, which made them accessible only to somewhat experience software developers.&lt;&#x2F;p&gt;
&lt;p&gt;The RAPIDS project within NVIDIA is wrapping up all of these algorithms in Python, and exposing APIs to data science users that look like drop-in replacements for Numpy&#x2F;Pandas&#x2F;Scikit-Learn.&lt;&#x2F;p&gt;
&lt;p&gt;They use Dask to provide multi-GPU parallelism (some people have many GPUs in a single machine) and multi-node parallelism across a cluster. Dask’s&lt;br &#x2F;&gt;
flexibility, and the fact that it’s pretty unopinionated about what you run as&lt;br &#x2F;&gt;
computation make it the perfect fit. It’s also one of the only task schedulers&lt;br &#x2F;&gt;
out there that run in a non-JVM language, which helps if you use natively&lt;br &#x2F;&gt;
compiled code, like CUDA.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Do you have any book, MOOC or resource that you would recommend to those of us that want to learn more about the implementation of schedulers, concurrency models and distributed systems?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Ha! Sadly no.&lt;&#x2F;p&gt;
&lt;p&gt;Centrally managed distributed schedulers are, unfortunately, not a common topic of research these days. From an academic&#x2F;intellectual level it’s a fairly&lt;br &#x2F;&gt;
simple problem. Most of the difficult parts are in the details of engineering,&lt;br &#x2F;&gt;
which are unfortunately not that interesting to anyone who isn’t building a&lt;br &#x2F;&gt;
distributed scheduler.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Interview with Osvaldo Martin about Bayesian Analysis with Python</title>
        <published>2019-02-11T00:00:00+00:00</published>
        <updated>2019-02-11T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/interview-with-osvaldo-martin-about-bayesian-analysis-with-python/"/>
        <id>https://blog.lambdaclass.com/posts/interview-with-osvaldo-martin-about-bayesian-analysis-with-python/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/interview-with-osvaldo-martin-about-bayesian-analysis-with-python/">&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-NpQf9G3ZdnMXLT-QT3sErQ.jpeg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Like our &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;notamonadtutorial.com&#x2F;inteview-with-thomas-wiecki-about-probabilistic-programming-and-pymc-66a12b6f3f2e&quot;&gt;previous interviewee&lt;&#x2F;a&gt; &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;aloctavodia&quot;&gt;Osvaldo Martin&lt;&#x2F;a&gt; is one of the developers of PyMC3 and ArviZ. He is a researcher specialized in Bayesian statistics and data science. He will be speaking at our &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;lambdaclass&#x2F;buzzconf&quot;&gt;BuzzConf&lt;&#x2F;a&gt; this year. I hope you like this interview as much as we did!&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h4 id=&quot;can-you-tell-us-how-data-analysis-has-improved-over-the-years&quot;&gt;Can you tell us how data analysis has improved over the years?&lt;&#x2F;h4&gt;
&lt;p&gt;This is not a simple question to answer, specially if we take into account that we have been doing data analysis from ancient times. The analysis of astronomical data has a long tradition it even predates (modern) science. For most of our history it was motivated by the many different religious liturgies we have invented over the centuries and the more &lt;em&gt;grounded&lt;&#x2F;em&gt; need of improving and controlling the food production. Fast-forwarding thousand of years one can argue that the data-driven studies of astronomers like Tycho Brahe had a decisive impact on setting up the scientific revolution. Astronomy and astrology were not fully separated by that time, but Brahe, based on his observations and experience already thought that astrologists were just charlatans and he maintains that the planets and stars have null influence over the human affairs. If that’s not a Data Scientist, who is?&lt;&#x2F;p&gt;
&lt;p&gt;So the “big thing” we are living now is not that we suddenly realize data is important, we have already known that for centuries, the difference is that now we have tons of available data from scientific disciplines like Biology and Astronomy, just to name two, and from daily interactions with streaming platforms, social networks, cell phones, and sensors all around us. Computers have made this possible by increasing our capacity to storage, process and transmits information by several order of magnitude, and perhaps equally important computers has also changed the way we ask questions and provide answers. There is a whole array of new methods to analyze and generate data, that are impractical without computers. Indeed, the modern practice and development of Bayesian methods have been profoundly influenced by the computers and computational methods up to the point that modern Bayesian statistics IS computational statistics. The only reason we are talking now about probabilistic programming, Machine Learning and Data Science is because we have cheap and fast computers.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;can-you-tell-us-in-brief-how-pymc3-and-arviz-help-with-bayesian-analysis&quot;&gt;Can you tell us in brief how PyMC3 and ArviZ help with Bayesian Analysis?&lt;&#x2F;h4&gt;
&lt;p&gt;PyMC3 is a probabilistic programming language offering two main components: a very clear syntax to define probabilistic models and a powerful set of methods to solve those models, mainly Markov Chain Monte Carlo and Variational Inference. Ideally the methods to solve probabilistic models should be Universal in the sense that they should be able to solve any valid probabilistic model. Unfortunately, even when current methods are very powerful they do not always work as we like, some models are still very difficult or slow to solve. Thus an important step in Bayesian Analysis is to check that inference was done properly. And this is one the motivations for creating ArviZ, a Python package for exploratory analysis of Bayesian models. ArviZ Includes functions for posterior analysis, sample diagnostics, model checking, and comparison. ArviZ works hand-in-hand with PyMC3, and other probabilistic programming language, like PyStan, emcee, Pyro, etc. Where the aim of the probabilistic programming languages is to make it easy to build and solve Bayesian models, the aim of the ArviZ library is to make it easy to process and analyze the results from the Bayesian models.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;can-you-explain-some-of-the-main-concepts-of-bayesian-analysis&quot;&gt;Can you explain some of the main concepts of Bayesian Analysis?&lt;&#x2F;h4&gt;
&lt;p&gt;Bayesian analysis can be summarized in just two concepts. Use probability distributions to represents the uncertainty in your model parameters. Then use Bayes theorem to update those probabilities given the data you have. All the rest derives from these two main concepts. Other concepts that are important to the practice of Bayesian Analysis are shared with other modeling approaches, like evaluating if models make sense by comparing their output against the data and the available domain-knowledge.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;why-do-you-like-working-with-data&quot;&gt;Why do you like working with data?&lt;&#x2F;h4&gt;
&lt;p&gt;I am not sure I “like” working with data, working with data is hard, data collection, data wrangling, cleaning and processing is generally time consuming. Data &lt;em&gt;per se&lt;&#x2F;em&gt; is not important what really matters is understanding phenomena, solving problems and designing better tools to solve problems. What happens is that data is essential to all these tasks. To answer any question in a scientific way you will need data at some point, for some problems you can progress a lot with just theory, but eventually you will need some data. The only scientific discipline that can avoid using data is pure mathematics. And for that reason many people do not think that mathematics is a scientific discipline, or if so they classify it as a logical science and not a factual one.&lt;&#x2F;p&gt;
&lt;p&gt;Everyone is talking about the data deluge and thus is easy to miss that data is produced by someone and that producing data is not always easy or cheap. Even when we have access to pre-existing data it may need further processing or it may not be suitable to answer our questions and thus we may need to generate data from scratch. In general, answering specific questions requires generating specific data under specific conditions. Just a few years ago many computational biologists and bioinformaticians believed that by extracting biological information from scientific journals and databases we will be able to build very reliable models of the cell. It turns out that while this is a good idea, is not that easy as its sounds and not applicable to every question. Papers are behind paywalls, written in formats not that easy to analyze programatically, experiments are performed under so many different conditions that integrating the information coherently is closer to a bad breakup than a romantic dinner, some experimental results are too noisy or the experimental design is flawed, observations can be contradictory, information in databases need to be further curated, etc.&lt;&#x2F;p&gt;
&lt;p&gt;To many people Data Science have put “data” in the spotlight, but science has always been data-driven. Charles Darwin was responsible from one of the most elegant scientific theories, and one of the most misrepresented ones. He spent years and years collecting data, not for the sake of having data but to try to make sense of the diversity and complexity of living organisms. Nowadays evolutionary biologists still spend a lot of time producing and gathering data from carefully designed observations, experiments and simulations in order to refine evolutionary ideas.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-are-the-advantages-and-disadvantages-of-using-python-over-other-languages-for-data-analysis&quot;&gt;What are the advantages and disadvantages of using Python over other languages for data analysis?&lt;&#x2F;h4&gt;
&lt;p&gt;One of the reasons I use Python is that it is a general purpose language, and while I spend a lot of time on data-analysis related stuff I also use Python to solve other types of problems. I learned to program during my PhD without formal training but with the help of great books like Think Python by Allen Downey and A Primer on Scientific Programming with Python by Hans Petter Langtangen, and also helped in many different ways by a large, welcoming and enthusiastic Python community.&lt;&#x2F;p&gt;
&lt;p&gt;At the time of my PhD most of my “coding” was about automating boring stuff and gluing specific scientific packages in order to perform molecular simulations and very very simple data-analysis problems. I used to do that using a collections of poorly documented (and probably poorly written) bash scripts. With the time this approach turns to be too restrictive, so I tried to learn Fortran and C, but I found them overcomplicated for most of the tasks I wanted to solve at the moment, and only very useful for a subsets of them… until I find Python! As someone said Python is not the best programming language for almost any task but is good enough for most of them as I would discover with the pass of time and with every new project that involved Python. One super tedious task for me at that moment was updating plots. I used a software with a GUI (and open source clone of a reeeeeally expensive proprietary scientific plotting software). Updating plots after re-running a simulation or noticing a mistake or getting feedback from my advisors or peers was a lot of work. Somehow, I did not remember the exact moment I found matplotlib, that was a deal-breaker for me and one of the reasons to learn even more Python.&lt;&#x2F;p&gt;
&lt;p&gt;Another epiphany was when I re-wrote a small piece of software a colleague kindly passed to me. Like me, my colleague was a non-computer-scientist. This code was a collection of bash scripts and a Fortran main program. I started with the bash scripts, instead of running several bash scripts I unified all of them into a collection of coherent Python functions. This already make my workflow easier and I was already super-happy, then I decide to change the Fortran code, at first this was mainly an exercise to challenge myself to learn more NumPy and Scipy. After many attempts to get this right (I never truly learned Fortran) I got a working Python version of the code, this code was not only much more shorter, easier to read and more modular, but to my surprise it was also 10x faster! Most of the speed-up come by replacing a lot of Fortran code with a SciPy call and a couple of NumPy array operations. And this was an important lesson to me. Do not re-invent the wheel, there are many specialized, well-tested, efficient routines out there, use them! Because while Python is &lt;em&gt;slow&lt;&#x2F;em&gt; not being proficient programmer in a &lt;em&gt;fast&lt;&#x2F;em&gt; language like Fortran or C can be even slower!&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-aspects-of-doing-bayesian-analysis-with-python-do-you-feel-are-tricky-to-get-past&quot;&gt;What aspects of doing Bayesian Analysis with Python do you feel are tricky to get past?&lt;&#x2F;h4&gt;
&lt;p&gt;For newcomers getting a fully functional Python environment can sometimes be tricky. Anaconda (a scientific Python distribution) and conda (a package manager) have helped a lot to get things installed properly, specially for Windows users.&lt;&#x2F;p&gt;
&lt;p&gt;When I show PyMC3 code to people most of them seem surprised by how much you can do with a few lines of codes. I even get responses like “that’s not programming” which I totally agree is just using a programming language to give instructions to a computer and get things done ;-) The challenge when using PyMC3 is then not so much on the programming-side but on the mental-modeling side, at first most people has problems figuring out how to express they problems in terms of a probabilistic model. This is a matter of practice and the creative part of the job. In the book I tried to show many examples of different models to help ease this transition to thinking probabilistically. This is something that needs practice, knowing that most pop-songs are built from the same chord progression of 3 to 4 chords that’s not automatically makes you a pop-star.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;your-take-on-the-data-analysis-environment-with-regards-to-innovations-in-it-the-knowledge-and-skills-gap-and-software-development-how-do-you-think-the-tech-landscape-is-changing&quot;&gt;Your take on the data analysis environment with regards to innovations in it, the knowledge and skills gap, and software development. How do you think the tech landscape is changing?&lt;&#x2F;h4&gt;
&lt;p&gt;My impression is that we now have something that was completely unimagined just a couple of decades ago: the popularization of very powerful computer methods. One of the side effects of the computer revolution is that any person with a modest understanding of a programming language like Python now has access to a plethora of powerful computational methods for data analysis, simulations, and other complex tasks. I am totally in favor of this, is one of my motivation to work on Open Source Software projects and to give free courses at the University. But I also recognize that this should be an invitation to us, as a community, to be extra careful about these methods not only to be able to apply them correctly from a technical point of view and to avoid making false claims but also from an ethical and democratic perspective. Otherwise we face the risk of giving too much control over important decisions to an increasingly reduced group of rich and powerful people and corporations, something that I am afraid is already happening and with disastrous consequences for those of us that not are part of the super-rich club. To turn this popularization of methods into a true democratization we need not only to make the methods accessible we also need to make other resources widely available. If the majority of the data generating processes, the data itself and the most powerful hardware is controlled by a small group then, we are not aiming for a true democracy we are just spending a lot of resources into training a high skilled work-force to serve the interest of a few and that is just a technocratic version of an oligarchy.&lt;&#x2F;p&gt;
</content>
        
    </entry>
</feed>
