<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title>LambdaClass Blog - Programming Languages</title>
    <subtitle>Deep technical insights on cryptography, distributed systems, zero-knowledge proofs, and cutting-edge software engineering from the LambdaClass team.</subtitle>
    <link rel="self" type="application/atom+xml" href="https://blog.lambdaclass.com/tags/programming-languages/atom.xml"/>
    <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2023-12-24T00:00:00+00:00</updated>
    <id>https://blog.lambdaclass.com/tags/programming-languages/atom.xml</id>
    <entry xml:lang="en">
        <title>Interview with Fernando Borretti about Austral - a systems programming language with linear types</title>
        <published>2023-12-24T00:00:00+00:00</published>
        <updated>2023-12-24T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/austral/"/>
        <id>https://blog.lambdaclass.com/posts/austral/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/austral/">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;&#x2F;h2&gt;
&lt;p&gt;It has been many moons since we interviewed a language creator, and are very excited to present a few questions to and share the answers from Fernando Borretti, the creator of the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;austral-lang.org&#x2F;&quot;&gt;Austral&lt;&#x2F;a&gt; (&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;austral&#x2F;austral&quot;&gt;Github&lt;&#x2F;a&gt;) language. As it says on the tin:&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;“&lt;strong&gt;Austral&lt;&#x2F;strong&gt;  is a new systems programming language. It uses linear types to provide memory safety and &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Capability-based_security&quot;&gt;capability-secure code&lt;&#x2F;a&gt;, and is designed to be simple enough to be understood by a single person, with a focus on readability, maintainability, and modularity.”&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;Just as Pascal introduced modules, and Lisp garbage collection, to a generation of programmers; Rust introduced using the type system to enforce rules on resource usage &lt;em&gt;into the mainstream&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;It has sparked a very interesting and ongoing discussion about memory usage, resource handling, and linear type systems which are inspiring many other languages. We ourselves at Lambda hope to present our own take on this in the future.&lt;&#x2F;p&gt;
&lt;p&gt;Without further ado, here is the interview.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Why did you create Austral? Doesn’t Rust solve the same type of problems?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I think it was Manuel Simoni who said: the most important thing about a programming language is how it makes you feel.&lt;&#x2F;p&gt;
&lt;p&gt;And to many people that sounds like a joke but I take it very seriously. Programming language design is an affective thing. I stopped working with Python because it made me feel like I was always standing atop a house of cards in a strong wind. It made me feel anxious. JavaScript is a lot like that.&lt;&#x2F;p&gt;
&lt;p&gt;There’s something akin to the extended phenotype in biology for programming languages: beyond the core language and the standard library you have the “extended language”, the tooling, the ecosystem, the community, the culture. And all of those things come together and define your experience of the language. Some languages like OCaml have a lot of technical merit, but the tooling is horrible and the community has no interest in improving, and so you persist in using it for its technical beauty and then inevitably burn out. And the further away from the core language you go, the less control there is (it’s hard to socially engineer an entire language community) but there’s a lot of things the language creators have control over, like setting the tone of the community, expectations around documentation, the quality of the tooling.&lt;&#x2F;p&gt;
&lt;p&gt;I wanted a language (and an extended language) that I would feel happy using. I wanted a small, simple language. Simple in the sense of Kolmogorov complexity: it fits in your head and there’s not reams and reams of edge cases you need to understand it. I wanted a slow-moving, conservative language, in the spirit of Common Lisp, where code bitrots very very slowly and you can confidently write code today knowing it will compile and run in thirty or more years. And I want to build an extended language to support that: high quality tooling and high quality docs to set the tone and create a community where people value quality, taste, and craftsmanship.&lt;&#x2F;p&gt;
&lt;p&gt;Re: Rust, I like Rust a lot. I work with it professionally. The tooling is a joy to use (after years of being tormented by pip and dune and pretty much everything else). And it’s infinitely better designed than most other languages you can find. I will even defend async.&lt;&#x2F;p&gt;
&lt;p&gt;But Rust is a very pragmatic language, and the problem with pragmatism is that it never ends*. Pragmatism has no natural stopping point. Rust is already pretty complex and I expect it will continue to grow as people demand more from the language. And the thing about programming languages is you can’t really take features off. And this isn’t necessarily wrong: I don’t think Rust would be as successful if it didn’t have a thousand little ergonomic features, and certainly if it didn’t have async there’d be a lot less of an impetus to adopt it for building servers.&lt;&#x2F;p&gt;
&lt;p&gt;There’s two ways to build a general-purpose language: one is to make it so that it is not specialized to any one thing, and that’s the Austral approach; and one is to make it specialized to every one thing. And things tend to evolve towards the latter, because large companies – the ones whose employees sit on the boards of programming language foundations, and the ones who pay people to work on the compilers and tooling and such – have very specific needs, and they’re always lobbying to have the language solve their specific problem. So languages grow and accumulate all these features because Google needs to reduce global latency by 0.02%.&lt;&#x2F;p&gt;
&lt;p&gt;*Philip K. Dick originally said this of introspection, and he was right.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Which languages inspired you the most?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Rust gets a lot of credit because it’s the only industrial language to have anything like linear types.&lt;&#x2F;p&gt;
&lt;p&gt;Cyclone, which also inspired Rust, was a research language, a better dialect of C, didn’t take off but they published a few papers about it. There were very interesting ideas about region-based memory management there.&lt;&#x2F;p&gt;
&lt;p&gt;Haskell for type classes done right. Haskell 98 type classes in particular are a jewel of good design. Standard ML for its module system. Ada for the syntax, module system, and ideas about security.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What is a linear type system, why is it useful? What type of software do you think that can be improved by using a linear type system?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I’ve written a bit about this in different places:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;borretti.me&#x2F;article&#x2F;type-systems-memory-safety&quot;&gt;https:&#x2F;&#x2F;borretti.me&#x2F;article&#x2F;type-systems-memory-safety&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;borretti.me&#x2F;article&#x2F;how-australs-linear-type-checker-works&quot;&gt;https:&#x2F;&#x2F;borretti.me&#x2F;article&#x2F;how-australs-linear-type-checker-works&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;borretti.me&#x2F;article&#x2F;introducing-austral&quot;&gt;https:&#x2F;&#x2F;borretti.me&#x2F;article&#x2F;introducing-austral&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;austral-lang.org&#x2F;linear-types&quot;&gt;https:&#x2F;&#x2F;austral-lang.org&#x2F;linear-types&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Part of me wants to consolidate these into one “definitive” explanation, but another part thinks it’s valuable to have different approaches to the same idea. So I have a number of different elevator pitches:&lt;&#x2F;p&gt;
&lt;p&gt;One way to think about it is linear types let you enforce protocols at compile time. There’s two kinds of values in programming: plain data and protocol handles. The latter are things like sockets, file objects, database handles, IPC channels. In languages with manual memory management they include heap-allocated objects.&lt;&#x2F;p&gt;
&lt;p&gt;These have to conform to a particular protocol, with the right state transitions. No double-free (you can’t free memory twice) and no use-after-free. Linear types allow you to enforce this at compile time. This is the main benefit: you get manual memory management with high performance and without safety footguns.&lt;&#x2F;p&gt;
&lt;p&gt;But you can also make your own protocols for your own types and enforce higher-level API contracts than what a normal type system allows.&lt;&#x2F;p&gt;
&lt;p&gt;Another way to think about it is that linear types make values work like real-world objects. In reality things can only ever be in one place. They move, but can’t be copied. In computers, copying is the primitive operation. Values can be aliased because pointers are unrestricted.&lt;&#x2F;p&gt;
&lt;p&gt;It turns out a lot of the problems with mutation are really problems with aliasing. And when you restrict pointer aliasing through linear types, you get referential transparency with pervasive mutation. You get code that is easy to reason about and very high performance.&lt;&#x2F;p&gt;
&lt;p&gt;As for what kinds of software could be improved: mainly, anything that manually-manages memory or uses external resources that need to respect protocols. That’s the main improvement. But when you start to think about designing APIs with linear types from the ground up, it becomes a lot more general, because a whole lot of APIs can be improved by using linear types to enforce high-level contracts and protocols.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What are the disadvantages of using a linear type system? Do you think that developer experience or the learning curve are necessarily impacted?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;There are two main disadvantages:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    1. Explicitness and verbosity: you have to call destructors by hand, and a lot more things require destruction (e.g. any string).&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    2. Linear types are incompatible with traditional exception handling techniques: &amp;lt;https:&#x2F;&#x2F;borretti.me&#x2F;article&#x2F;linear-types-exceptions&amp;gt;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;strong&gt;Your post explaining the linearity checker details the implementation. Some modern languages are exploring implementing their type systems as rule sets in logic inference engines e.g. Datalog. Do you have thoughts on this trend?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I don’t know enough logic programming to implement the type checker in it. There’s this Racket tool called Redex which I’m aware of but haven’t played with, it basically lets you write typing judgments in Gentzen notation (like PLT papers) but have those judgements type-checked. Which is a vast improvement over writing the type system in LaTeX.&lt;&#x2F;p&gt;
&lt;p&gt;Another thing is that the type system is not too complicated. The goal is to be simple in the C. A. R. Hoare sense of “simple enough that there are obviously no bugs”.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Incremental compilation is also a hot topic today. In your post explaining the design of the Austral compiler you mention that for simplicity it does batch compilation. Have you considered incremental compilation an interesting feature or do you see it as an implementation detail?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Incremental and separate compilation are a must have in a production compiler but I think you can live without them in the early days, particularly because there’s just not that much code written in the language in the first place. You could take the entire ecosystem, 10x it in volume, and still not suffer from slow compile times.&lt;&#x2F;p&gt;
&lt;p&gt;I think this is an area where there’s room for improvement relative to other languages like Rust, because in Austral the module is the compilation unit, while in Rust the crate is the compilation unit. In Rust, all the modules that make up a crate are loaded at once, and only then compiled, so you can have e.g. circular dependencies between modules within a crate. The problem is build times are the main complaint people have about Rust, and people have to turn to bad solutions like manually splitting codebases into multiple crates.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;In your introduction to Austral, you mention that type inference is an anti-feature. Can you expand on what led you to this decision?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I feel that type inference is a science experiment that broke its cage and escaped the lab, to the detriment of many people. As in, it should have remained an academic curiosity.&lt;&#x2F;p&gt;
&lt;p&gt;The fundamental problem is that type inference doesn’t know whether the input you give it is correct or a mistake, but it will use it as a constraint in inference anyways. I had this problem in OCaml constantly: I’d make a mistake where in Java I’d get an error message saying “you made a mistake”, while in OCaml the compiler would make a best-effort inference, propagating my mistake upwards and sideways and every which way, and then I’d get an incomprehensible type error, sometimes many tens or hundreds of lines removed from the place where I made the actual mistake.Sometimes the only solution to such errors is to start adding type annotations (to function signatures, to variables) to constrain the inference process, and this can take a long time. And then you find the error and it was the most trivial thing, and in a less bigbrained language it would not have happened in the first place.&lt;&#x2F;p&gt;
&lt;p&gt;The next problem is languages that infer too much. Again, in OCaml (and unlike Rust) you can leave the parameters to a function unannotated. You save microseconds of typing, and for the rest of the lifetime of that codebase you will spend multiple minutes trying to figure out what the type of something is. And you can say, well, simply annotate all your function signatures. But that’s why languages have to have hard rules: if something is optional, people will take the shortcut and not do it all the time.&lt;&#x2F;p&gt;
&lt;p&gt;So type inference in ML family languages is a failed idea because you end up annotating the types anyways: you have to annotate the types of functions for documentation, and you frequently end up annotating the types of local variables for both readability and to constrain the type inference engine and make the errors easier. It’s just this really frustrating, circuitous way of doing what in Java you’d be forced to do in the first place. And I see people using VS Code with an LSP set up to display the types of the variables over the code and think, well, why not just have them written? Then you can read the code outside your dev environment, like in a GitHub diff for example.&lt;&#x2F;p&gt;
&lt;p&gt;I’ve found that type inference is only useful in a very narrow set of circumstances where type information doesn’t flow strictly downwards and annotations would be cumbersome. The best example of this is the &lt;code&gt;Option&lt;&#x2F;code&gt; type. If you have this in Rust:&lt;&#x2F;p&gt;
&lt;p&gt;enum Option&lt;T&gt; {&lt;br &#x2F;&gt;
Some(T),&lt;br &#x2F;&gt;
None,&lt;br &#x2F;&gt;
}&lt;&#x2F;p&gt;
&lt;p&gt;Then in the &lt;code&gt;Some&lt;&#x2F;code&gt; constructor, there’s no need for inference, because type information flows downwards: &lt;code&gt;Some: T -&amp;gt; Option&amp;lt;T&amp;gt;&lt;&#x2F;code&gt;. But without type inference the &lt;code&gt;None&lt;&#x2F;code&gt; constructor is harder: it doesn’t take a value, so in a language without type inference, you have to tell the compiler which type should be used in place of &lt;code&gt;T&lt;&#x2F;code&gt;. But a general type inference engine is such a complex piece of machinery for such a narrow use case.&lt;&#x2F;p&gt;
&lt;p&gt;And then there’s the performance cost. The more advanced the type system, the more expensive inference becomes . There’s also the fact that type inference wastes a lot of academic effort. Academic papers on PLT will introduce a new type system, and then spend pages and pages describing the type reconstruction algorithm. And I’m like, this is the least interesting part of it! Let me annotate things manually and show me what this thing can do to solve real problems!&lt;&#x2F;p&gt;
&lt;p&gt;So in Austral type information flows in one direction only, and variables and everything require annotations everywhere. The cost is you spend unobservable extra milliseconds writing. The gain is the code is instantly more readable and you never again have to deal with weird inference bugs.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Macros are also mentioned as an anti-feature but in your writings you mention Lisp. Do you consider there are valid use cases in general or in Austral for metaprogramming, and for which kinds of metaprogramming?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I used to write Common Lisp a lot. And macros work decently well in CL*. One of the things that attracted me to Lisp is that every programmer is a language designer. I used to think that was a very good thing: you can implement language features in a few seconds that Java programmers have been begging for in mailing lists for years. But then I saw what people do with macros and changed my mind.&lt;&#x2F;p&gt;
&lt;p&gt;This is part of a general pattern that when I was younger I wanted expressive power, and I was attracted to Common Lisp because in Common Lisp you can wave your magic wand and change the world. But after 10y of cleaning up people’s horrible code I realize what I want are fewer nightmares. Macros make everyone a language designer, and that, I realize, is a very bad thing because most people should not be anywhere near language design. Macros might work in a language that is only used by like, insane PL geniuses who also have great communication skills and write lots of docs, but “this feature can only be used by discerning geniuses with great taste” is not sustainable in the real world.&lt;&#x2F;p&gt;
&lt;p&gt;What do people use macro systems (and related things like Java-style annotations) for? Largely to build nightmares: codebases shot through with magic, where every type has like seven different annotations involving serialization, RPC, SQL mappings and the like. The code you see on the page is not what’s running: it’s an input to a vast, ill-defined, ad-hoc programming language made up of third-party macros that transforms the code in unpredictable ways. Errors become impossible to trace because nobody can tell you concretely what control flow looks like. Changes to the codebase become unpredictable.&lt;&#x2F;p&gt;
&lt;p&gt;So macros are kind of a bait and switch. The bait is, “it would be nice to have to have a shorthand way to write this common code”. The switch is you end up with a codebase nobody can understand.&lt;&#x2F;p&gt;
&lt;p&gt;And the solution is build-time code generation. It’s a lot like macros, but you can inspect the generated code, commit it to version control, debug it, and it is cleanly separate from the rest of the code you write.&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    * I wrote about why here: &amp;lt;https:&#x2F;&#x2F;borretti.me&#x2F;article&#x2F;why-lisp-syntax-works&amp;gt;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;strong&gt;The capability-based security description sounds strikingly similar to OpenBSD’s  &lt;code&gt;pledge&lt;&#x2F;code&gt;. Did you take inspiration from them?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This is one area where I wish I’d kept something like a lab notebook while iterating on the language design. It would be invaluable to be able to go back and see what I was aware of and when, which papers I read and such. I think I was aware of pledge and how it works at the time. I really like the pledge API. Linux and FreeBSD capabilities are hellishly complicated when compared to the bare-bones simplicity of pledge. Austral’s capability security is similar to pledge in that in both systems, you start with infinite capabilities, and you can then surrender those capabilities, irreversibly, one at a time. But Austral’s system is more granular because it doesn’t rely on a hardcoded list of syscalls, but, rather, you get pledge() at the value level, you can pledge individual files and other objects.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What is the most difficult part of designing a programming a new programming language like Austral?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I should say building a community, getting people interested, but honestly the most frustrating thing has been writing the compiler.&lt;&#x2F;p&gt;
&lt;p&gt;There’s this tension between, on the one hand, you want the simplest, most MVP, most prototype bootstrapping compiler so you can get to the stage where you can write real running programs and actually start playing with the language. That tells you a lot about ergonomics, about possible soundness issues. Because when things are vague and ill-defined they’re always great, it’s only when you concretize things (by implementing them) that you start to notice the flaws and the tradeoffs.&lt;&#x2F;p&gt;
&lt;p&gt;But if the compiler is too MVP you will have bugs you can’t easily figure out, because the error reporting is very poor for example. Compilers are really uniquely hellish to test and debug.&lt;&#x2F;p&gt;
&lt;p&gt;So you’re always changing course between “build a simple MVP compiler so I can quickly iterate on it” and “build something with production-grade diagnostics and error reporting”.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Are you planning on building a community or userbase? How do you think you can generate momentum to attract Rust or C programmers to develop with Austral?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I have a little Discord. I want to do more work to have something more substantial especially around the standard library and build tooling before spending much more effort on marketing. I think a lot of programmers are very tired of language churn and framework churn and library churn, and the idea of a small, simple, conservative, slow-moving language is appealing. Here’s a thing you can learn in an afternoon, and the code you write will compile and run thirty years from now, and you won’t have to jump ship in horror in a decade.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Do you think you can reuse existing tooling from other languages (like gdb, or rust-analyzer)? What is the state of the standard library and how do you see it evolving?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The current compiler spits out C. I don’t want that to become a trait of the language (“Austral compiles to C”), since it’s just an implementation detail of the compiler. So gdb and valgrind should be usable.&lt;&#x2F;p&gt;
&lt;p&gt;rust-analyzer, I doubt it. It’s a huge thing and is essentially the most complex parts of a compiler frontend specifically for Rust.&lt;&#x2F;p&gt;
&lt;p&gt;I think it would be a good idea to write the production compiler with a view towards making it usable also as an LSP.&lt;&#x2F;p&gt;
&lt;p&gt;The standard library is very minimal: simple containers and typeclasses. I see myself making small additions to it. A lot of people hate dependencies but I’m a big believer in lots of small libraries actually, so I like the idea of the standard library being just code that is either “eternal” (e.g. a resizable array type) or pervasive (e.g. date and time) or binding some platform-specific thing (e.g. file I&#x2F;O).&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Is interoperability with other languages (e.g. FFI) part of the roadmap? How would it interact with linear types and capabilities?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Interoperability with C is already there. That’s the most useful one because the C calling convention is basically the lingua franca of every language.&lt;&#x2F;p&gt;
&lt;p&gt;Some languages advertise e.g. automatic interoperability with C++. That is vastly more effort and I think it’s entirely misguided. e.g. the Clasp compiler for Common Lisp was built essentially so the author could access C++ libraries that use templates and such from Common Lisp. It’s a tremendous amount of effort when you can simply write a light extern C wrapper around the C++ code you need (in Common Lisp you can even automate much of this). So I’m not too worried about C++ interop. In the future we’ll just have an LLM port the entire C++ codebase over no problem.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What are your future plans for Austral? Do you plan to grow the language and add new features like concurrency primitives?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Standard library, build system and package manager, better docs. That’s the first thing.&lt;&#x2F;p&gt;
&lt;p&gt;I’m procrastinating on concurrency models because I don’t know enough about them, and I don’t want to prematurely specialize the language to an approach that might not pan out. Go has green threads and goroutines and that hasn’t worked out for them, the design gives up a lot of performance. OCaml has green threads now and that seems to be working out for them so far. I think Rust-style async is very unfairly maligned, but it also has practical problems in that, because of the way it interacts with lifetimes, everyone ends up putting all of their shared resources under reference-counted pointers. And so in theory the perf ceiling is very high but in practice people will leave a lot of performance on the table to get code that can be feasibly written and refactored.&lt;&#x2F;p&gt;
&lt;p&gt;So I’m happy to sit back and let the world define itself for me, and when there’s a clear and compelling right thing to do, I’ll implement it in Austral in the simplest, most orthogonal way possible.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;If you enjoy interviews to programming language creators, you might also enjoy these previous ones:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    * Dec 8, 2014 [https:&#x2F;&#x2F;blog.lambdaclass.com&#x2F;indie-languages-interview-pixie-and-timothy-baldridge&#x2F;](&#x2F;indie-languages-interview-pixie-and-timothy-baldridge&#x2F;)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    * Aug 26, 2015 [https:&#x2F;&#x2F;blog.lambdaclass.com&#x2F;interview-with-brian-mckenna-about-roy-purescript-haskell-idris-and-dependent-types&#x2F;](&#x2F;interview-with-brian-mckenna-about-roy-purescript-haskell-idris-and-dependent-types&#x2F;)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    * Aug 28, 2015 [https:&#x2F;&#x2F;blog.lambdaclass.com&#x2F;interview-with-nenad-rakocevic-about-red-a-rebol-inspired-programming-language&#x2F;](&#x2F;interview-with-nenad-rakocevic-about-red-a-rebol-inspired-programming-language&#x2F;)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    * Nov 27, 2015 [https:&#x2F;&#x2F;blog.lambdaclass.com&#x2F;efene-an-erlang-vm-language-that-embraces-the-python-zen&#x2F;](&#x2F;efene-an-erlang-vm-language-that-embraces-the-python-zen&#x2F;)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    * Dec 28, 2015 [https:&#x2F;&#x2F;blog.lambdaclass.com&#x2F;interview-with-jesper-louis-andersen-about-erlang-haskell-ocaml-go-idris-the-jvm-software-and&#x2F;](&#x2F;interview-with-jesper-louis-andersen-about-erlang-haskell-ocaml-go-idris-the-jvm-software-and&#x2F;) Dec 29, 2015 [https:&#x2F;&#x2F;blog.lambdaclass.com&#x2F;interview-with-jesper-louis-andersen-about-erlang-haskell-ocaml-go-idris-the-jvm-software-and-60901251608c356716f2f92e&#x2F;](&#x2F;interview-with-jesper-louis-andersen-about-erlang-haskell-ocaml-go-idris-the-jvm-software-and-60901251608c356716f2f92e&#x2F;)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    * Feb 29, 2016 [https:&#x2F;&#x2F;blog.lambdaclass.com&#x2F;interview-with-robert-virding-creator-lisp-flavored-erlang-an-alien-technology-masterpiece&#x2F;](&#x2F;interview-with-robert-virding-creator-lisp-flavored-erlang-an-alien-technology-masterpiece&#x2F;)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    * Feb 12, 2018 [https:&#x2F;&#x2F;blog.lambdaclass.com&#x2F;interview-with-brad-chamberlain-about-chapel-a-productive-parallel-programming-language&#x2F;](&#x2F;interview-with-brad-chamberlain-about-chapel-a-productive-parallel-programming-language&#x2F;)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    * Apr 1, 2019 [https:&#x2F;&#x2F;blog.lambdaclass.com&#x2F;an-interview-with-the-creator-of-gleam-an-ml-like-language-for-the-erlang-vm-with-a-compiler&#x2F;](&#x2F;an-interview-with-the-creator-of-gleam-an-ml-like-language-for-the-erlang-vm-with-a-compiler&#x2F;)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;</content>
        
    </entry>
    <entry xml:lang="en">
        <title>An interview with the creator of Gleam: an ML like language for the Erlang VM with a compiler…</title>
        <published>2019-04-01T00:00:00+00:00</published>
        <updated>2019-04-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/an-interview-with-the-creator-of-gleam-an-ml-like-language-for-the-erlang-vm-with-a-compiler/"/>
        <id>https://blog.lambdaclass.com/posts/an-interview-with-the-creator-of-gleam-an-ml-like-language-for-the-erlang-vm-with-a-compiler/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/an-interview-with-the-creator-of-gleam-an-ml-like-language-for-the-erlang-vm-with-a-compiler/">&lt;h3 id=&quot;an-interview-with-the-creator-of-gleam-an-ml-like-language-for-the-erlang-vm-with-a-compiler-written-in-rust&quot;&gt;An interview with the creator of Gleam: an ML like language for the Erlang VM with a compiler written in Rust&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-ivv-xih7D4rulPdRNmSYkg.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I have been writting soft real time systems with Erlang for almost a decade and for that task I think it is the best tool we have around. The concurrency model, the preemptive scheduler, the GC, the profiling tools, the libraries and the community are excellent for the task. Distribution libraries like &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;lasp-lang.readme.io&#x2F;docs&quot;&gt;Lasp&lt;&#x2F;a&gt; or distributed systems frameworks like &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;lambdaclass&#x2F;riak_core_tutorial&quot;&gt;Riak Core&lt;&#x2F;a&gt; are not easily available in other languages. At last, cheap processes, non shared state, supervisors and the let it crash philosophy are great tools when you are writing backends. Instead of trying to catch all the errors at compile time, you accept that it is impossible to catch all the possible problems and you deal with that reality. It is a very different error handling model from what you can find in Haskell or OCaml.&lt;&#x2F;p&gt;
&lt;p&gt;However Erlang language is pretty simple. I always miss sum types when I am coding in Erlang. I miss ML’s type system expressiveness, safety and practicality. That is why I am interested in the development of Gleam, a statically typed functional programming language for the BEAM.&lt;&#x2F;p&gt;
&lt;p&gt;Another interesting thing about Gleam is that its compiler is written in Rust. I think that Rust is a sort of ML + C language. I like C since the developer is at the driver seat driving with manual transmission. I can’t explain very well but I have always seen C as a simple and powerful language but I have always disliked C++. Knowing that I like ML and C you might understand why I find Rust an interesting language.&lt;&#x2F;p&gt;
&lt;p&gt;To sum up we (me and &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;JuanBono&quot;&gt;Juan Bono&lt;&#x2F;a&gt;) decided to do this interview with &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;louispilfold&quot;&gt;Louis Pilfold&lt;&#x2F;a&gt; not only because of what it is, but also because it is implemented in Rust. Go ahead and check &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;lpil&#x2F;gleam&quot;&gt;Gleam’s repo&lt;&#x2F;a&gt;!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-x_OU1YRmBR8037eqsSAfYA.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;&lt;strong&gt;Tell us a little about yourself. Have you been working on programming languages for long?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Professionally I’m a web programmer, but over the last 4 years my hobby projects have largely been compilers in one form or another. Two of the most popular ones have been Dogma (an Elixir to angry error message compiler) and exfmt (an Elixir to slightly prettier Elixir formatter). For the last year I’ve been focusing on Gleam, which is an ML inspired statically typed language for the Erlang ecosystem.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What was the first programming language you learned?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The first language I attempted to learn was C, though with no experience and nothing but a few youtube videos I didn’t make much progress. After that I discovered an online version of MIT’s introduction to computer science and worked my way through that, so Python was the first program I successfully learnt. After finishing the course I discovered Ruby, which became my day-to-day language and my introduction to the world of web dev and professional programming, and then Haskell, which really shaped how I think about solving problems with code.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Why do you think that the ML languages are a good fit for the BEAM VM?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Both families share the same lambda calculus core, and once you’ve discarded the various bells and whistles of the individual languages (such as processes, type classes, module functors, etc) they all have strikingly similar semantics. Given these shared semantics I think we can take the much loved type systems of ML languages and the proven value of the BEAM VM to create a language that has the best of both, or at least lots of fun :)&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;How does Gleam compare to the other ML-like initiatives targeting the Erlang VM? (Alpaca, Elchemy, etc). What are the main differences and what motivated you to create Gleam?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I think Gleam has a subtly different outlook to the other projects, it is more focused on using the learnings of ML to enhance the BEAM rather than creating an actual ML language. This thinking has resulted in some design differences such as simple interop in both directions, no auto-currying, no effects system, curly brace based syntax, and an Erlang style module system.&lt;&#x2F;p&gt;
&lt;p&gt;I’m very glad that there are multiple projects working in this area. If Gleam fails and one of the other projects manages to build a healthy community then I’ll still be happy, I just want at one to succeed so I can use it in the real world.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Do you compile Gleam directly to BEAM bytecode?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The Gleam compiler has had a few full rewrites. The previous version compiled to BEAM bytecode via Core Erlang, which is an intermediate representation with the Erlang compiler, but the current version compiles to regular Erlang source code that has been pretty-printed. This has a few nice advantages such as providing an escape hatch for people who no longer wish to use Gleam, and enabling Erlang&#x2F;Elixir&#x2F;etc projects to use libraries written in Gleam without having to install the Gleam compiler.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What kind of type system Gleam uses? (Hindley-Milner?)&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Gleam uses a Hindley-Milner type system with a fairly standard implementation of Algorithm W. One slightly unusual addition is that row types are used to represent both records (which are Erlang maps) and modules, making them polymorphic in a way that I believe fits the way we use maps and modules in Erlang&#x2F;Elixir.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Does the static typing provide any run-time guarantees beyond the compilation checks?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;At runtime all types have been erased and there are no run-time checks. This is nice for performance and makes calling Gleam from Erlang easier, but it means there’s no way of automatically handling an incorrect type annotation when calling Erlang from Gleam.&lt;&#x2F;p&gt;
&lt;p&gt;If you have an unruly or unreliable Erlang function that you wish to call from Gleam the standard library provides a module for handling dynamically typed data that can be used to handle the return values safely at runtime.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;How does the type system interact with message passing and distribution? How do you handle the message passing features of erlang? Have you given any thought on protocol specification as type checking?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Currently we don’t have a good solution for typed message passing and such, and development is currently focused on building the more run-of-the-mill parts of the language. Rather than introduce a flawed stop-gap solution that will later need to be replaced I’ve opted not to have first class support for the BEAM’s low level concurrency primitives, so these will have to be used via Erlang FFI.&lt;&#x2F;p&gt;
&lt;p&gt;On the other hand OTP behaviours such as gen_server can be implemented using Gleam’s first class module system, which is enough to start writing OTP applications using Gleam today.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Why did you choose Rust for implementing the Gleam compiler? (instead of choosing erlang&#x2F;elixir, etc)&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Gleam started as a few little experiments in Elixir but fairly quickly shifted over to Erlang. In December 2018 I realised I was going to have to refactor the type inference module in a fairly major fashion in order to correct a mistake in the design. The typer was easily the most complex part of the compiler and had accrued a lot of technical debt as I learnt and iterated on the language so I wasn’t feel very confident about the refactoring, especially without a static type system to guide me.&lt;&#x2F;p&gt;
&lt;p&gt;I decided that a full rewrite of the compiler would give me a chance to produce a better application without the mistakes of the first version, and using a statically typed language would enable me to refactor more easily in future. I picked Rust, and after roughly 3 months I had a new compiler with roughly the same features, fewer bugs, and less tech debt. It’s also considerably faster.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Is Rust a good language for implementing programming languages?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Yes, I think so. The type system is sophisticated and robust enough to take refactorings that would have bested me in the Erlang version and complete them with relatively little stress and fewer bugs. The tooling, documentation, and libraries are delightful, and the community is exceptionally friendly and helpful.&lt;&#x2F;p&gt;
&lt;p&gt;As a nice little bonus the performance of Rust has improved the user experience somewhat; Compilation is faster and there’s no longer a noticeable lag caused by the Erlang virtual machine booting and loading the various modules.&lt;&#x2F;p&gt;
&lt;p&gt;However it’s certainly not a perfect language for compiler implementation. Rust’s linear type system means it doesn’t need a garbage collector, but it can be a very frustrating experience learning how to write code that type checks, and the resulting code can be quite verbose. I speculate that if I had opted to use OCaml instead the type inference code would be under half the size it currently is.&lt;&#x2F;p&gt;
&lt;p&gt;I’m quite sure that someone with more Rust experience could make a lot of my code more concise and remove unnecessary memory allocations, but what we have today performs well and isn’t too difficult to modify. Overall I’m very happy with the decision to use Rust.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What kind of features do you plan to add to Gleam in the future (if any)? Were you inspired by a specific language?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The two main features I’ve been asked about are typed message passing (as you have enquired about above!) and some form of ad-hoc polymorphism like Haskell’s type classes. I don’t think that type classes are a good fit for Gleam, though perhaps something like OCaml’s proposed implicit module system could be worth exploring. Either way it will be a long time before we can start to design and experiment here, there’s plenty to do beforehand.&lt;&#x2F;p&gt;
&lt;p&gt;I’d like to enhance how atoms are represented at type level. Currently we can say “this value is an atom”, but that’s about it. It would be more useful if we could say “this value is the atom ‘ok’ or the atom ‘error’”, or “this function can takes the atom ‘up’ or the atom ‘down’, but no other atom”. This could also be extended to create polymorphic enum variants too, though I’m unsure whether it makes sense to have those as well as Gleam’s existing pre-declared enums.&lt;&#x2F;p&gt;
&lt;p&gt;It could be fun to have some alternative backends for the compiler so that we can compile to Javascript or a native binary, allowing Gleam to be used for cloud functions, command line tools, and other applications to which BEAM is less suited.&lt;&#x2F;p&gt;
&lt;p&gt;A much more mundane feature I’m interested in is record punning, as found in Javascript or Haskell. It would be nice to be able to write this&lt;&#x2F;p&gt;
&lt;p&gt;let {name, score} = player&lt;&#x2F;p&gt;
&lt;p&gt;Instead of&lt;&#x2F;p&gt;
&lt;p&gt;let {name = name, score = score} = player&lt;&#x2F;p&gt;
&lt;p&gt;However that syntax has already been taken by tuples, so something would need to change for us to have this feature.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What recommendations would you give to someone who wants to start writing their first programming language?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Write lots of code in your language before writing the compiler! Solve lots of simple problems and compile it in your mind so that you can work out how all the different features would interplay and how it might work under the hood. Writing a compiler takes a lot of time so the more experimentation and learning you can do to build confidence in your language design the better. Changing syntax when you have one file of fake code takes seconds, while with a compiler it may take many hours. Worse still, changing the semantics of your language in your compiler could take days or weeks. It pays to get the design right first.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Interview with Brad Chamberlain about a productive parallel programming language called Chapel</title>
        <published>2018-02-12T00:00:00+00:00</published>
        <updated>2018-02-12T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/interview-with-brad-chamberlain-about-chapel-a-productive-parallel-programming-language/"/>
        <id>https://blog.lambdaclass.com/posts/interview-with-brad-chamberlain-about-chapel-a-productive-parallel-programming-language/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/interview-with-brad-chamberlain-about-chapel-a-productive-parallel-programming-language/">&lt;p&gt;As you might know, I am a big fan of concurrency, parallelism and distribution but I know almost nothing about high performance computing (HPC) so I decided to get out from my comfort area. This time I’ve interviewed Brad Chamberlain about &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;chapel-lang&#x2F;chapel&quot;&gt;Chapel&lt;&#x2F;a&gt;, a productive parallel programming language.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-Vbk8JH0pBz1gSHSbxV799A.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What problems does Chapel solve? Who is the ideal user of Chapel?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Chapel supports scalable parallel programming in a portable way: programs developed on a user’s multicore laptop can be run on commodity clusters, the cloud, and supercomputers from &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.cray.com&#x2F;&quot;&gt;Cray&lt;&#x2F;a&gt; or other vendors. Chapel is also designed to vastly improve the productivity of performance-oriented programming, whether serial or parallel. As such, it supports programs with Python-like clarity while retaining the performance of lower-level approaches to programming like C, C++, Fortran, MPI, and OpenMP (the &lt;em&gt;de facto&lt;&#x2F;em&gt; standards for high-performance parallel programming).&lt;&#x2F;p&gt;
&lt;p&gt;Ideal Chapel users include Python programmers who are interested in parallel or performance-oriented programming as well as parallel programmers who are fed up with conventional approaches.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Were there any other previous languages that tried to solve the same issue?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Definitely. There’s a long list of failed attempts at developing scalable parallel programming languages, and skeptics like to remind you of them all the time: “If all of these languages have failed, how will you ever succeed?” In designing Chapel, we spent a lot of time reviewing other parallel languages to learn from their mistakes. Historically, I’d say that most parallel languages have failed for one of two reasons: Many were too high-level, limiting what an expert programmer could explicitly control while requiring a lot from their compilers. Others were lower-level, but as a result didn’t provide sufficient appeal over existing approaches like MPI.&lt;&#x2F;p&gt;
&lt;p&gt;Our response to this tension was to design a language using what we refer to as a &lt;em&gt;multiresolution&lt;&#x2F;em&gt; &lt;em&gt;philosophy&lt;&#x2F;em&gt; : Chapel supports higher-level features like parallel loops and distributed arrays for productivity and ease-of-use. Yet, it also supports lower-level features that give programmers more explicit control over the system. Notably, the high-level features are implemented in terms of the lower-level features within Chapel itself. This provides programmers with the ability to extend the language by creating their own abstractions. For example, an advanced Chapel user can implement new work-scheduling policies for their parallel loops, or new distributions or memory layouts for their arrays.&lt;&#x2F;p&gt;
&lt;p&gt;In my opinion, many scalable parallel language attempts have also failed to gain traction because they’ve been insufficiently general-purpose. Once programmers have a capability, they tend to be reluctant to give it up. This lack of generality often stems from the fact that most efforts have been undertaken by academic groups who need to pick their battles in order to publish papers and graduate students. With Chapel, we’ve created a language whose capabilities exceed C or Fortran with MPI and OpenMP, yet in a language that strives to be as attractive to read and write as Python.&lt;&#x2F;p&gt;
&lt;p&gt;It’s obviously very difficult for any new programming language to succeed, yet that’s no reason to avoid pursuing them — particularly when existing languages have major capability gaps. In our case, we believe that parallelism and locality are first-class programming concerns — not just in High-Performance Computing (HPC) where they make or break a program’s ability to scale well, but also in mainstream programming now that multicore processors and accelerators are pervasive. That said, parallelism and locality have traditionally been afterthoughts in language design. So rather than being paralyzed by the challenges of language adoption, we’re striving to fill that gap. And happily, users seem to be excited by our efforts.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;In some ways, don’t OpenMP, MPI, and CUDA solve the same problem?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;OpenMP, MPI, and CUDA are the &lt;em&gt;de facto&lt;&#x2F;em&gt; standards for HPC programmers today when targeting multicore processors, distributed memory systems, and (NVIDIA) GPUs, respectively. In that sense, Chapel is targeting a similar problem space as they are. However, they’re not considered very productive approaches and are great illustrations of my claim that parallelism and locality are traditionally afterthoughts in language design: they’re implemented using pragmas, libraries, and language extensions rather than first-class syntax and semantics. As a result, they feel like they’re “tacked on” rather than a core part of the language. This hurts not just their ease-of-use but also their ability to be optimized by compilers.&lt;&#x2F;p&gt;
&lt;p&gt;These approaches also tend to be very specific to a given type of parallelism in the system architecture: If you’ve written an OpenMP program and now want to run it at scale on a cluster or a Cray, you’ll have to rewrite it in something like MPI, which requires learning a completely different set of features and abstractions. In contrast, Chapel is designed to support parallel programming across these diverse types of parallel hardware with a single, unified set of features for expressing parallelism and locality.&lt;&#x2F;p&gt;
&lt;p&gt;To their immense credit, OpenMP, CUDA, and (especially) MPI have been responsible for the vast majority of scientific advances in high-performance computing over the past several decades. And if you program in these notations and are happy with them, Chapel may not be for you. Yet, just as early computational results were obtained using assembly language before giving way to more modern and portable approaches like Fortran, C, C++, Java, and eventually Python, we think parallel computing is overdue for a similar leap in evolution: from lower-level, detail-oriented approaches to higher-level ones that improve productivity and portability. As such, Chapel strives to empower the millions of desktop-only programmers to use distributed parallel computers for the first time, while also making existing parallel programmers even more effective.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What does Chapel do differently &#x2F; better?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;A characteristic shared by most general-purpose approaches to scalable parallel programming — including MPI, SHMEM, UPC, and Fortran 2008’s co-arrays — is that they express parallelism using the &lt;em&gt;Single Program, Multiple Data&lt;&#x2F;em&gt; (SPMD) programming model. The basic idea is that the user writes their program with the understanding that when it is run, multiple copies of ‘main()’ will execute simultaneously and cooperatively across a number of processors. This forces parallel programmers to write programs using a &lt;em&gt;local view&lt;&#x2F;em&gt; , in which the code expresses the perspective of a single process out of many: “What subset of the data do I need to allocate? What subset of the iteration space do I need to execute?” While the SPMD approach is sufficient for many computations, it’s also very different from traditional programming where one copy of ‘main()’ executes and all computation proceeds from that point. This requires programmers to think differently, to manage lots of bookkeeping details, and even to launch their programs differently. It also means that in order to get finer-grain parallelism, they need to mix in some other parallel programming model like POSIX threads, OpenMP, or CUDA.&lt;&#x2F;p&gt;
&lt;p&gt;In stark contrast, Chapel supports what we call a &lt;em&gt;global view&lt;&#x2F;em&gt; of programming, in which a single task runs ‘main()’ and then any additional parallelism is created as features that introduce tasks are encountered. Similarly, computation and data are distributed across compute nodes when features that control locality are encountered. This permits scalable parallel programming to be far more intuitive and similar to conventional desktop programming, making it accessible to the millions of developers who might never get around to learning MPI. At the same time, Chapel’s global view also supports SPMD programming for computations or users that require it, so nothing is lost.&lt;&#x2F;p&gt;
&lt;p&gt;As an illustration of Chapel’s advantages, consider the STREAM Triad benchmark which multiplies a vector by a scalar, adds it to a second vector, and assigns it to a third. In Chapel, this can be written in a way that will use all the cores of all the system’s compute nodes as follows:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;use BlockDist, HPCCProblemSize;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;config type elemType = real;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;config const m = computeProblemSize(numArrays=3, elemType),&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;         alpha = 3.0;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;proc main() {&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;  const ProblemSpace = {1..m} dmapped Block(boundingBox={1..m});&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;  var A, B, C: [ProblemSpace] elemType;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;  B = 2.0;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;  C = 1.0;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;  A = B + alpha * C;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;}&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In contrast, doing the same thing in C + MPI + OpenMP results in computation like the following, due to the SPMD programming model as well as the lower-level notations (MPI-oriented code is in red, OpenMP in blue):&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;0-7A817ub0TK9QWgLW.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Performance-wise, how does Chapel compare to languages like C, C++, Go, Rust?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Today, Chapel programs tend to perform competitively with hand-coded C and C++. I’m not aware of any detailed performance comparisons with Go and Rust, though in the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;benchmarksgame.alioth.debian.org&#x2F;&quot;&gt;Computer Language Benchmarks Game&lt;&#x2F;a&gt; (CLBG) we’re currently ranked as being a bit faster than Go and a bit slower than Rust. That said, there are specific CLBG benchmarks where any of these five languages win or lose, and many of the fastest entries take a far more heroic and painstaking approach than the Chapel versions.&lt;&#x2F;p&gt;
&lt;p&gt;Since we care about code clarity, we tend to graph the Computer Language Benchmark Game results on scatter plots showing normalized execution times versus code compactness (as a proxy metric for clarity). In such views, Chapel tends to fall in a very unique position, being competitive in speed with the fastest languages while also nearly as compact as scripting languages. The following two plots illustrate this (the right graph zooms in on the fastest entries for readability):&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;0-5HKm6tfdrqfXiXWP.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;0-YHDLOnTtFepJmsUV.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Why did you implement Chapel using LLVM?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;In all honesty, one of my biggest regrets in the project today is that we didn’t implement Chapel using LLVM from day one. When our project started, LLVM was still in its infancy, and there was no reason to believe that it would become the foundational technology that it is today. As a result, our initial compiler approach (which remains the default today) was to compile Chapel down to C which is then compiled by the back-end C compiler of your choice. This approach treats C as a portable assembly language and has worked reasonably well for us over time. However, it is also unfortunate because the Chapel compiler may have semantic information which is challenging or impossible to convey through C to the back-end compiler.&lt;&#x2F;p&gt;
&lt;p&gt;In contrast, Chapel’s LLVM back-end permits us to translate Chapel directly to LLVM’s Internal Representation (IR), giving us greater semantic control plus the possibility of adding Chapel-specific extensions. Since LLVM is a popular compiler framework, using it lets us leverage developer familiarity, not to mention open-source packages. One such example is Simon Moll’s Region Vectorizer for LLVM, developed at Saarland University. We’ve found that it tends to generate better vector performance for Chapel programs than conventional C back-end compilers. But even more importantly, LLVM gives us a single, portable back-end that saves us the trouble of wrestling with the quirks and bugs that are present across the wide diversity of back-end C compiler versions that we attempt to support today. In 2018, we hope to make LLVM our default back-end for these reasons.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What is GASNet? Why do you use it in Chapel?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;GASNet is an open-source library for portable inter-process communication developed by Berkeley Labs &#x2F; UC Berkeley. Its communication primitives include active messages and one-sided puts to (or gets from) the memory of a remote process. The GASNet team maps these calls down to the native Remote Direct Memory Access (RDMA) capabilities of various networks while also supporting fallback implementations over UDP or MPI for portability.&lt;&#x2F;p&gt;
&lt;p&gt;These primitives are precisely what a language like Chapel needs to compile to distributed memory systems: Active messages are the natural way to implement Chapel’s &lt;em&gt;on-clauses&lt;&#x2F;em&gt; which are used to migrate tasks from one compute node to another. Similarly, writing&#x2F;reading a variable back on the originating locale maps naturally to one-sided puts&#x2F;gets since only one process will know when such communications are required. As a result, GASNet gives us a portable way to run Chapel on virtually any distributed system. It’s also one of the best engineered and maintained open-source packages we’ve worked with, and the development team is incredibly responsive to questions and issues.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;How do you manage errors? If a long-running computation in multiple nodes crashes in one node, how do you recover the work done or re-execute it without having to re-run everything?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;For user-level errors within the program itself, Chapel supports the ability to throw and catch errors using a low-overhead approach that was inspired by Swift’s error-handling model. This is a relatively new feature set within Chapel, and it rounds out our core capabilities nicely.&lt;&#x2F;p&gt;
&lt;p&gt;That said, your question seems more oriented toward catastrophic errors that may be outside of the programmer’s control, such as having one of their compute nodes fail. Today, Chapel doesn’t handle such cases gracefully, which arguably reflects our HPC heritage. Runtime libraries and system software for HPC have a long tradition of tearing down jobs when fatal errors occur, and Chapel inherits this behavior to some extent. Resiliency is a growing concern within the HPC community as our system scales grow, and we have some ideas for improving Chapel’s ability to cope with such events. Similar features could also be attractive to users from cloud computing environments who are accustomed to elasticity in their environment. That said, we have not yet had the opportunity to pursue these ideas, so they remain an area of potential future research or collaboration.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Is there any way to trace what a live system is currently doing?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;We haven’t developed any Chapel-specific tools for tracing or visualizing Chapel executions in real-time. That said, third-party tools can be used with Chapel as with any other C program. We do have a tool named &lt;em&gt;chplvis,&lt;&#x2F;em&gt; developed by Professor Phil Nelson of Western Washington University, which supports visualizing the communication and tasking events logged by a Chapel program. This permits a user to visually inspect a Chapel program’s execution to find possible sources of overhead, but it is strictly a post-mortem tool at present.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Are you aware of anybody using Chapel in the AI&#x2F;Machine Learning world?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;We’ve definitely seen an uptick in interest from AI programmers in recent years as the field has become more prevalent, both in HPC and in general. Our most prominent user in this space at present is Brian Dolan, who is the Chief Scientist and Co-Founder of &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;deep6.ai&#x2F;&quot;&gt;Deep 6 AI&lt;&#x2F;a&gt;, a start-up that is accelerating the matching of medical patients to clinical trials. After being disappointed by programming solutions that didn’t live up to their hype, Brian was drawn to Chapel last summer due to its ability to support programs with Python-like clarity, combined with the promise of supporting performance and scalability like C or Fortran with MPI. Half a year later, he’s become one of our most active and vocal users.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Interview with Nenad Rakocevic about Red, a Rebol inspired programming language</title>
        <published>2015-08-28T00:00:00+00:00</published>
        <updated>2015-08-28T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/interview-with-nenad-rakocevic-about-red-a-rebol-inspired-programming-language/"/>
        <id>https://blog.lambdaclass.com/posts/interview-with-nenad-rakocevic-about-red-a-rebol-inspired-programming-language/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/interview-with-nenad-rakocevic-about-red-a-rebol-inspired-programming-language/">&lt;p&gt;After our &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;medium.com&#x2F;this-is-not-a-monad-tutorial&#x2F;interview-with-brian-mckenna-about-roy-purescript-haskell-idris-and-dependent-types-63bb1289ea3d&quot;&gt;last interview with Brian McKenna&lt;&#x2F;a&gt; for &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;medium.com&#x2F;this-is-not-a-monad-tutorial&quot;&gt;This is not a Monad tutorial&lt;&#x2F;a&gt; we interviewed &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;dockimbel&quot;&gt;Nenad Rakocevic&lt;&#x2F;a&gt;, creator of the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;www.red-lang.org&#x2F;&quot;&gt;Red&lt;&#x2F;a&gt; programming language.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-C0sMUPxpbBs40YIBX848jQ.jpeg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;From my completely subjective point of view Red and Rebol are quite strange creatures! But don’t get me wrong, that doesn’t mean something bad. For example, I am not aware of many high-level languages which features an embedded DSL for general-purpose low-level programming or that have 50 native types. You should check it out, you might find some interesting ideas inside Red development.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Please tell us a little bit about Red’s inception. Why was it created?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-869fRKUVs2sTdVDYrqblMQ.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I started programming micro-computers, an Amiga in my case, in my teens. I have now been programming for more than 30 years. After my early experiences, I was unhappy with existing programming languages and tools. This was mostly because I found them not productive or friendly enough for my taste. So, when I stumbled across the Rebol language, in 1999, it was an eye-opener on what was wrong with so called “modern” computing practice. (Nowadays it’s even worse). Fighting complexity on all software fronts became the logical course of action.&lt;&#x2F;p&gt;
&lt;p&gt;In 2010, Rebol was closed source. I deeply felt that the approach had a lot more to offer but Rebol was barely evolving. This was the trigger for me to start work on an open source relative to Rebol with much higher ambitions and a broader field of usage.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What are the main selling points of Red?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;First fullstack programming solution: combines in one tool, the ability to write high-level code (GUI apps, scripting and DSL) and fast low-level code (writing device drivers, operating systems, native interfacing, etc). Moreover, Red is also a &lt;em&gt;both-sided&lt;&#x2F;em&gt; technology (client &amp;amp; server).&lt;&#x2F;li&gt;
&lt;li&gt;Cross-platform native code compiler: from any platform the toolchain runs on, you can compile to about 15 other platforms, with a simple command-line option (-t Windows, -t Linux, -t Darwin, -t RPi, …).&lt;&#x2F;li&gt;
&lt;li&gt;Extremely lightweight: Red is a 1MB, single-file, no install, no setup, toolchain. It takes typically a few seconds to download and you can immediatly start writing and running code, there’s &lt;em&gt;nothing&lt;&#x2F;em&gt; to setup (it’s just terrible that this is the exception instead of being the norm…).&lt;&#x2F;li&gt;
&lt;li&gt;Batteries-included solution: it comes with a very rich runtime library, despite its tiny size, covering pretty much anything you need for common tasks.&lt;&#x2F;li&gt;
&lt;li&gt;DSL-oriented environment: Red comes with many embedded DSL addressing important needs (like GUI or system-programming). DSL are a very powerful way to reduce complexity arising from frameworks or API, while drastically increasing productivity. Red includes a DSL (called Parse) for constructing DSLs.&lt;&#x2F;li&gt;
&lt;li&gt;Red (like Rebol) is a Lisp derivative, but with a human-friendly syntax (no parenthesis hell). Red is its own data format. All code is treated as data until you evaluate it, code&#x2F;data serialization comes for free. The minimal punctuation makes it easy on the eye.&lt;&#x2F;li&gt;
&lt;li&gt;The underlying philosophy of Red (as was that of Rebol) is to make the simple easy and the difficult possible.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;What made Rebol the main inspiration for Red?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Rebol is one of the most innovative programming language created in the last 20 years. Sadly, it remained under the radar being closed source at a time when open-source languages like Perl, Python and Ruby hit the streets. Rebol’s approach shakes the foundation of what programmers consider “simple” or “efficient” in programming. Typically, API which other languages would call “simple”, look uselessly complicated when you are used to wear Rebol glasses. ;-) Here are a few one-liners as examples (using the Rebol2 REPL):&lt;&#x2F;p&gt;
&lt;p&gt;Create a GUI window with a button printing, on click, Hello in the console:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;view layout [button “Click Me” [print “Hello”]]&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Dump the content of a web page in console:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;print read http:&#x2F;&#x2F;rebol.com&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Extract the title of a web page:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;parse read http:&#x2F;&#x2F;rebol.com [thru &amp;lt;title&amp;gt; copy text to &amp;lt;&#x2F;title&amp;gt; (print text)]&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Send the list of files in current folder by email:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;send user@domain.com mold read %.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Retrieve records from a MySQL database and print them in console:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;foreach row read&#x2F;custom mysql:&#x2F;&#x2F;root@localhost&#x2F;books [“SELECT * FROM authors”] [print row]&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Notice that even if you never looked at Rebol code before, you can nonetheless read it and guess what most of the code is doing.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What are the main differences between Rebol and Red?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Red can be (cross-)compiled to native code, Rebol is only interpreted. Compiled code can run much faster than interpreted code.&lt;&#x2F;li&gt;
&lt;li&gt;Red allows system-programming and fast low-level code, Rebol is stuck at scripting-level.&lt;&#x2F;li&gt;
&lt;li&gt;Red relies on native widgets and native backends for GUI support, Rebol has a custom GUI engine. So Red will make your GUI apps feel more natural and better integrated to the OS user.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Besides that, the languages itself are very similar, somewhere around 95% the same. If you know Rebol, you know Red.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Red covers the whole range of abstraction between low-level and high-level programming by offering Red&#x2F;System as a dialect with C-type semantics and Rebol-type syntax. Was the distinction between Red and Red&#x2F;System present in the original design? What advantages do you gain by using Red&#x2F;System?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Absolutely, Red&#x2F;System was one of the main incentive to build a new programming stack instead of simply duplicating the Rebol implementation. Red&#x2F;System is a statically compiled language targetting native code (like C). Red&#x2F;System serves two main purposes:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;provide an embedded DSL to Red users for fast code support and system programming needs&lt;&#x2F;li&gt;
&lt;li&gt;fill the role of an IR (Intermediate Representation) language for compiled Red code&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;AFAIK, Red is the first high-level language which features such embedded DSL for general-purpose low-level programming.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Who uses Red&#x2F;Rebol?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The Rebol community used to be relatively big in the early 2000, but it shrank a lot as its evolution tailed off. The profile of users was astonishly broad on the skills scale. Many were attracted by its simplicity for simple tasks and its cross-platform GUI engine, but other were more interested by its depth (dynamic binding, easy DSL crafting, strong meta-programming abilities, …).&lt;&#x2F;p&gt;
&lt;p&gt;Since then, only the hardcore fans or companies which have built their software on top of it, continue to use and promote it. Many of those same people now form the early adopters for Red, along with many other people which were interested in Rebol when it launched, but rejected it due to its closed-source nature. Some of them wrote libraries for Red, other small games or even a Windows device driver! :-) As soon as Red is ready for production, we’ll make sure many more people will join them and have fun using Red.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;For which scenarios do you think Red is an appropriate language?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Red is a general-purpose programming solution which should be good enough for &lt;em&gt;any&lt;&#x2F;em&gt; programming task. In practice, it’s (only) limited by the available frameworks and libraries. So these tasks are a very good match for Red:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;scripting &#x2F; glue code&lt;&#x2F;li&gt;
&lt;li&gt;GUI apps (in upcoming v0.6.0)&lt;&#x2F;li&gt;
&lt;li&gt;Android apps (in v0.6.1)&lt;&#x2F;li&gt;
&lt;li&gt;data processing&lt;&#x2F;li&gt;
&lt;li&gt;grammar parsers &#x2F; DSL creation&lt;&#x2F;li&gt;
&lt;li&gt;system programming&lt;&#x2F;li&gt;
&lt;li&gt;device drivers&lt;&#x2F;li&gt;
&lt;li&gt;IoT devices programming (runinng on Intel or ARM cpu)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Once we reach 1.0 (next year), Red will also be very good for:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;webapps programming&lt;&#x2F;li&gt;
&lt;li&gt;servers creation&lt;&#x2F;li&gt;
&lt;li&gt;2D games&lt;&#x2F;li&gt;
&lt;li&gt;robotics&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;Rebol and Red offer a great variety of built in types with practical applications. Some would argue that it is better to offer a small core of language features. What is your take on that?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Rebol and Red offer about 50 datatypes in a runtime of about 500KB. Among them, two-thirds have a specific literal form (like money, email, url, time, date, colors,…) which gives you, out of the box, a rich set of literals you can use for building embedded DSL.&lt;&#x2F;p&gt;
&lt;p&gt;Another big gain is that most of the features you need for daily work are already there, as first-class citizens, perfectly integrated with the rest, working exactly the same on every supported platform. This is a productivity boost and makes learning&#x2F;using the language much more pleasant (no need to make “imports” for any simple task). Such languages are pragmatic and aiming at reducing the costs of software building.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What is a sky-high view of how Red is implemented? Are all the components (parsers, code generators, garbage collectors, etc) hand-written? What dependencies does Red have?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Excepting for a good part of the unit tests, which are generated by script, everything else is hand-written. We are bootstrapping Red using Rebol, so the toolchain (compilers, linker, builders) is written in Rebol2. Rebol offers a parsing DSL which is very effective, adding to that its deep metaprogramming abilities, there is simply no need to use any other tool for building such toolchain. Red scripts can be interpreted from the REPL or compiled to native code, using Red&#x2F;System as intermediary target. The runtime library is built in a mix of Red and Red&#x2F;System code.&lt;&#x2F;p&gt;
&lt;p&gt;Red executables are typically around 0.5MB and have no dependencies.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;How complete is Red as of Mid-2015?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;There’s already a lot implemented, so I’ll describe rather what’s missing. Right now, we are completing the cross-platform GUI support with a first backend for Windows. Android, Linux and OS X backends will follow. The I&#x2F;O is currently limited to simple file operations and HTTP client support only. Modular compilation, full garbage collector and concurrency support are the main features missing before reaching 1.0. We aim at launching the 1.0 release in 2016.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Where do you see Red in the future?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Red has the potential to seduce many developers (especially indie-developers who have the freedom of choice) who are frustrated by existing tools (even the so-called “simple” ones). I expect Red to be wide-spread in a couple of years, helping programmers achieving many different tasks while having fun doing it and making their life easier. Red will expand with many strong DSL for various domains, offering nice replacements for existing libraries direct usage. For example, we’ll push it in robotic and AI fields.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What are the most important lessons learned from the development of Red?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Open-source is a superior way to build quality software (just confirmed that fact with Red project).&lt;&#x2F;li&gt;
&lt;li&gt;Working “in the open” is not always a good thing, sometimes you need to isolate yourself from the outside “noise” to execute complex tasks (mostly design tasks). Being able to do so is increasingly difficult as the project growths up.&lt;&#x2F;li&gt;
&lt;li&gt;Having to deal with a growing community of users consumes a &lt;em&gt;lot&lt;&#x2F;em&gt; of time. Finding people to deal with the community for you is critical.&lt;&#x2F;li&gt;
&lt;li&gt;Designing good syntactic rules is &lt;em&gt;way&lt;&#x2F;em&gt; more difficult than designing good semantics. That’s a part overlooked by many language designers, which end up with great semantics but terrible syntaxes.&lt;&#x2F;li&gt;
&lt;li&gt;Writing a native code compiler for a statically typed language is really not difficult, most programmers with a minimal CS background could do it, they’re just not aware they can.&lt;&#x2F;li&gt;
&lt;li&gt;Premature optimization can (often) bite you in the back. Knowing when you’re optimizing prematurely is a bit of a black art.&lt;&#x2F;li&gt;
&lt;li&gt;Every big software project should be started by a team of at least 2 highly tuned, equally skilled developers. Working alone on big projects is insane, and not a guarantee of best results.&lt;&#x2F;li&gt;
&lt;li&gt;If you work on an open-source project that is attractive enough and gather enough followers, you can live from user’s donations (I did so for 2 years, covering all my basic life expenses). I never thought that would be possible when I started, nor did I counted on it. I guess I’m just lucky that Red has an amazing community.&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;&lt;strong&gt;What reading material do you recommend for implementing your first programming language?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;You can have a good overview of all the required parts in a book like this &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.goodreads.com&#x2F;book&#x2F;show&#x2F;112256.Modern_Programming_Languages&quot;&gt;Modern Programming Languages: A Practical Introduction&lt;&#x2F;a&gt;. If you want to go in-depth and dive into more abstract concerns, the “Dragon book” is still the reference.&lt;&#x2F;p&gt;
&lt;p&gt;But the most useful way is to study several small languages implementation, that will give you the best insights about how to achieve it yourself. For example, Red 0.1.0 release is just a 24KB zip archive, but features already a working compiler&#x2F;linker for Red&#x2F;System with many features already (including FFI). Get it from here: &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;red&#x2F;red&#x2F;releases&#x2F;tag&#x2F;v0.1.0&quot;&gt;https:&#x2F;&#x2F;github.com&#x2F;red&#x2F;red&#x2F;releases&#x2F;tag&#x2F;v0.1.0&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What other languages or technologies are you keeping an eye?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Go: it’s the language with the fastest growth in the last years, understanding why, could be a key to help Red growing faster too. Go’s concurrency model also seems attractive to users, so worth studying.&lt;&#x2F;li&gt;
&lt;li&gt;Lua: trying to understand where it’s heading and how it grows.&lt;&#x2F;li&gt;
&lt;li&gt;Python3.x: trying to understand where it’s heading, not sure I understand its strategy though.&lt;&#x2F;li&gt;
&lt;li&gt;Webassembly: the foundation for the future of web programming.&lt;&#x2F;li&gt;
&lt;li&gt;MagicLeap: the future of HCI!&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
</feed>
