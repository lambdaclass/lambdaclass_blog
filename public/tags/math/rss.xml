<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
      <title>LambdaClass Blog - Math</title>
      <link>https://blog.lambdaclass.com</link>
      <description>Deep technical insights on cryptography, distributed systems, zero-knowledge proofs, and cutting-edge software engineering from the LambdaClass team.</description>
      <generator>Zola</generator>
      <language>en</language>
      <atom:link href="https://blog.lambdaclass.com/tags/math/rss.xml" rel="self" type="application/rss+xml"/>
      <lastBuildDate>Wed, 25 Jan 2023 00:00:00 +0000</lastBuildDate>
      <item>
          <title>Climbing the tower: field extensions</title>
          <pubDate>Wed, 25 Jan 2023 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://blog.lambdaclass.com/posts/climbing-the-tower-field-extensions/</link>
          <guid>https://blog.lambdaclass.com/posts/climbing-the-tower-field-extensions/</guid>
          <description xml:base="https://blog.lambdaclass.com/posts/climbing-the-tower-field-extensions/">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;&#x2F;h2&gt;
&lt;p&gt;Finite fields are a central piece in every cryptography and &lt;a href=&quot;&#x2F;the-hunting-of-the-zk-snark&#x2F;&quot;&gt;zk-SNARKs&lt;&#x2F;a&gt;. The most common finite fields appearing in practice are the fields with prime order $\mathbb F_p$. There are multiple ways of defining them. A usual one is seeing $\mathbb F_p$ as the set&lt;br &#x2F;&gt;
$$ \{0, 1, \cdots, p-1\}$$&lt;br &#x2F;&gt;
together with the rule of addition and the rule of multiplication modulo $p$. But other finite fields play important roles, too. For example, when dealing with pairing-friendly elliptic curves. You may have seen them denoted by things like $\mathbb F_{p^n}$.&lt;br &#x2F;&gt;
The usual way of defining and introducing them is through the theory of field extensions that involve quotients of &lt;a href=&quot;&#x2F;math-survival-kit-for-developers&#x2F;&quot;&gt;polynomial rings&lt;&#x2F;a&gt;. It is the most natural and correct way from a mathematical standpoint, mainly to prove things about them. But going down that road can be obscure and confusing if you are unfamiliar with the mathematical tools involved.&lt;&#x2F;p&gt;
&lt;p&gt;The idea is straightforward, and those fields are very concrete mathematical objects. This post aims to give a non-standard but more down-to-earth way of understanding extensions of finite fields.&lt;&#x2F;p&gt;
&lt;p&gt;If you want to see examples of finite field extensions in zk-SNARKs, you can look at the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;arkworks-rs&#x2F;algebra&#x2F;tree&#x2F;master&#x2F;ff&quot;&gt;arkworks&lt;&#x2F;a&gt; finite field arithmetic library, where they build field extensions to work with elliptic curve pairings.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-is-a-field&quot;&gt;What is a field?&lt;&#x2F;h2&gt;
&lt;p&gt;To kick this off, let’s revisit what a field is. The actual definition is &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Field_(mathematics)#Classic_definition&quot;&gt;here&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Loosely speaking, a field is a set $F$ with addition and multiplication rules that behave, for example, like real numbers. There has to be an element in $x_0 \in F$ that behaves like $0$. That means that $x_0 + x = x$ for all $x$ in $F$. We even denote this element just by $0$. Similarly, there has to be an element $1$ in $F$ such that $1\cdot x = x$ for all $x$ in $F$. They are called the &lt;em&gt;neutral elements&lt;&#x2F;em&gt; of multiplication and addition, respectively. In $\mathbb F_p$, these are already denoted by $0$ and $1$, so no surprises there.&lt;&#x2F;p&gt;
&lt;p&gt;A field also has to have a &lt;em&gt;multiplicative inverse&lt;&#x2F;em&gt; for all elements different from $0$. This means that if $x$ is any element of $F$ different from $0$, there has to be another element $y$ such that $x\cdot y = 1$. This element $y$ is unique and is denoted by $x^{-1}$. For example, in $\mathbb F_3$ we have $2^{-1} = 2$.&lt;&#x2F;p&gt;
&lt;p&gt;We can deduce lots of things from the defining properties of a field. We will need this one later: if $x\cdot x = 0$, then $x=0$.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-case-of-complex-numbers&quot;&gt;The case of complex numbers&lt;&#x2F;h2&gt;
&lt;p&gt;Computer scientists are very good at naming things, like &lt;em&gt;neural networks&lt;&#x2F;em&gt; and &lt;em&gt;artificial intelligence&lt;&#x2F;em&gt;. Mathematicians, on the other hand, are very often terrible at it. Early in our lives, we encounter one of the worst examples: &lt;em&gt;complex numbers&lt;&#x2F;em&gt;. There are at least three problems with them. First of all, the name. It biases everyone to think it’s a complex concept. Second, the obscure notation $a + bi$, and finally, the fact that the new symbol is called an &lt;em&gt;imaginary number&lt;&#x2F;em&gt;. This makes an explosive combination and hides its simplicity. Complex numbers are just pairs of real numbers, also called the &lt;em&gt;cartesian plane&lt;&#x2F;em&gt;. And the interesting thing is that there is a way to define addition and multiplication rules on this set of pairs that extends the ones of the real numbers. These even have geometric interpretations!&lt;&#x2F;p&gt;
&lt;p&gt;We introduce this because we will take a similar approach to finite fields. The approach is: we start from a field, in this case, $\mathbb R$, with the usual addition and multiplication rules. We then add a new coordinate to obtain the pairs of real numbers $(a, b)$. This set is usually denoted $\mathbb R^2$. On this set we define the addition component-wise $(a,b) + (c, d) := (a+c, b+d)$. We then try to define a multiplication rule on it. That is, we want to come up with a rule for the expression $(a, b)\cdot(c, d)$ such that:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    1. It forms a field together with the component-wise addition.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    2. It extends the operations of the real numbers in the following way. For all real numbers $a$ and ${b,}$ the equality $(a,0)\cdot(b,0) = (ab, 0)$ should hold. This means we can think of the real numbers as sitting inside $\mathbb R^2$. They are those elements with a null second coordinate. And the new operation boils down to the usual one on this restricted set.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If we try to define the multiplication component-wise, we will need something else. That is, if we define $(a, b)\cdot(c, d) = (ac, bd)$, then the whole thing won’t be a field. For example, there won’t be a neutral element for multiplication (think about it!). It is not evident, but it turns out that a formula that works is the following:&lt;&#x2F;p&gt;
&lt;p&gt;$$ (a, b) \cdot (c, d) := (ac - bd, ad + bc).$$&lt;&#x2F;p&gt;
&lt;p&gt;Here the neutral element of the multiplication is $(1, 0)$. The set of pairs of real numbers $\mathbb R^2$ together with this multiplication and the component-wise addition is the field of complex numbers $\mathbb C$.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;notation-a-bi&quot;&gt;Notation $a + bi$&lt;&#x2F;h3&gt;
&lt;p&gt;Let’s play around with this to arrive at the more familiar form $a + bi$. This will also be key to understanding the usual constructions of finite fields out of the rings of polynomials.&lt;&#x2F;p&gt;
&lt;p&gt;Since we can identify the real numbers inside $\mathbb R^2$ as the elements with a null second coordinate, we can abuse notation and write $a$ instead of $(a, 0)$. If we try to do the same with second coordinates, we need a way to distinguish them from the previous ones. So we write the elements of the form $(0, b)$ as $bi$. The $i$ means that it is not a real number. Now, the point $(a, b)$ is equal to $(a, 0) + (0, b)$. And with the new notation, it is written as $a + bi$. Notice that the notation $bi$ is consistent with our identification of $\mathbb R$ inside $\mathbb R^2$ and the multiplication rule. What we mean is that $bi$ is equal to $b\cdot i$ when we think $b$ as being $(b, 0)$ and $i$ as being the element $(0, 1)$. That is, $(b,0)\cdot(0, 1)=(0, b)$.&lt;&#x2F;p&gt;
&lt;p&gt;Last but not least, note that $(0, 1) \cdot (0, 1) = (-1, 0)$. So under this notation, this is $i^2 = -1$.&lt;&#x2F;p&gt;
&lt;p&gt;So why do we prefer the $a + bi$ notation over the $(a, b)$ one? I can think of a few reasons. It is more explicit that we want to think of the real numbers as sitting inside the complex numbers. It is also handier since it does not involve all the parenthesis. But it is just a notation.&lt;&#x2F;p&gt;
&lt;p&gt;The takeaway is that complex numbers are a field constructed from real numbers by adding more coordinates. The same process creates all the finite fields. The difference is that we start from the fields $\mathbb F_p$ instead of $\mathbb R$.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;wait-what-about-other-extensions-of-the-real-numbers&quot;&gt;Wait, what about other extensions of the real numbers?&lt;&#x2F;h4&gt;
&lt;p&gt;Now that we have the complex numbers $\mathbb C:= \mathbb R^2$ constructed as before, we could try to perform the same process and define a multiplication on the pairs of complex numbers $\mathbb C^2$ that together with addition component-wise is again a field.&lt;&#x2F;p&gt;
&lt;p&gt;Another thing we could do is start from the real numbers again, but this time add three or more copies of it. That is, try to define a multiplication on triplets of real numbers $(a,b,c)$ to form a field.&lt;&#x2F;p&gt;
&lt;p&gt;Both of these will need to be changed. This is called the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Frobenius_theorem_(real_division_algebras)&quot;&gt;Frobenius theorem&lt;&#x2F;a&gt;. It states that the best we can do is to define a non-commutative multiplication on $\mathbb C^2$ so that it won’t be a field. It is called the &lt;em&gt;quaternions&lt;&#x2F;em&gt;. It is a fascinating object with many applications, for example, in computer graphics, to deal with rotations.&lt;&#x2F;p&gt;
&lt;p&gt;The good news is that both constructions will work in the land of finite fields!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;binary-strings-of-length-2&quot;&gt;Binary strings of length $2$&lt;&#x2F;h2&gt;
&lt;p&gt;Let’s start simple. Consider $\mathbb F_2$. It has only two elements&lt;&#x2F;p&gt;
&lt;p&gt;$$\mathbb F_2 = \{0, 1\}$$&lt;&#x2F;p&gt;
&lt;p&gt;The addition and multiplication rules have $0$ as the neutral element for addition, $1$ as the neutral element for multiplication, and $1+1$ equals $0$. The addition is the usual XOR on the set of bits. This will be our building block. The field $\mathbb F_2$ will play the role of the real numbers in the previous section.&lt;&#x2F;p&gt;
&lt;p&gt;Let us now add one more coordinate and consider the set of all binary strings of length $2$. So our set now is ${ (0,0), (0,1), (1,0), (1,1)}$. We will call this set $\mathbb F_2^2$ for now. We want to find a multiplication rule on $\mathbb F_2^2$ just like in the case of complex numbers. The addition on is the component-wise addition of $\mathbb F_2$&lt;&#x2F;p&gt;
&lt;p&gt;$$(a,b) + (c, d) = (a+b, c+d).$$&lt;&#x2F;p&gt;
&lt;p&gt;So for example $(1,1) + (0,1) = (1, 0)$. This is again the XOR but now on strings of length $2$. The challenge is again to come up with a multiplication rule.&lt;&#x2F;p&gt;
&lt;p&gt;Let’s try to reverse-engineer it. Assume it is somehow defined and has all the properties we want. Essential to what follows is that we also require the multiplicative neutral element to be $(1, 0)$. This is the $1$ in $\mathbb F_2$ under its usual identification as the elements with null second coordinate.&lt;&#x2F;p&gt;
&lt;p&gt;Let’s find out what would be $(0,1)\cdot(0,1)$. It surely is one of the elements of $\mathbb{F}_2^2$. So there are only four possible choices. It cannot be $(0,1)\cdot(0,1)=(0,0)$, otherwise we would get $(0, 1) = (0,0)$. This is the property we mentioned in the first section of this post: in a field, if $x\cdot x$ equals the neutral element of the addition $0$, then $x = 0$. Here the neutral element is $(0,0)$ because we are in $\mathbb F_2^2$ with the component-wise addition.&lt;&#x2F;p&gt;
&lt;p&gt;Another possibility is that $(0,1)\cdot(0,1) = (1,0)$, then we could do the following reasoning.&lt;br &#x2F;&gt;
\[ \begin{align} (1,1)\cdot(1,1) &amp;amp;= ((1,0) + (0,1))\cdot((1,0) + (0,1)) \newline&lt;br &#x2F;&gt;
&amp;amp;= (1,0)\cdot(1,0) + 2(1,0)\cdot(0,1) + (0,1)\cdot(0,1) \newline&lt;br &#x2F;&gt;
&amp;amp;= (1,0)\cdot(1,0) + (0,1)\cdot(0,1) \newline&lt;br &#x2F;&gt;
&amp;amp;= (1,0) + (1,0) \newline&lt;br &#x2F;&gt;
&amp;amp;= (0,0) \end{align} \]&lt;br &#x2F;&gt;
This is bad for the same reason, we got $(1,1)\cdot(1,1) = (0,0)$ but $(1,1)$ is different from $(0,0)$.&lt;br &#x2F;&gt;
So we are left with only two options for the result of $(0, 1)\cdot(0, 1)$. Either $(0,1)\cdot(0,1)$ is equal to $(1,1)$ or it is equal to $(0, 1)$. But a similar argument to the ones we gave rules out $(0, 1)$. And so, the only possible candidate is&lt;br &#x2F;&gt;
$$(0, 1)\cdot(0, 1) = (1, 1)$$&lt;&#x2F;p&gt;
&lt;p&gt;With this fact, we can construct the rest of the multiplication table. For example&lt;br &#x2F;&gt;
$$(1,1)\cdot(1,1) = (1,0)\cdot(1,0) + (0,1)\cdot(0,1) = (1,0) + (1,1) = (0,1).$$&lt;&#x2F;p&gt;
&lt;p&gt;And this works fine. Although not evident at first sight, it satisfies all the properties we want. The proof is easy but tedious now that there’s a candidate for the multiplication rule. We would have to go through all the properties and verify that they are satisfied (this is a finite amount of checks).&lt;&#x2F;p&gt;
&lt;h4 id=&quot;notation&quot;&gt;Notation&lt;&#x2F;h4&gt;
&lt;p&gt;Let’s introduce a notation with the same spirit as the complex numbers’ $a + bi$ notation. Similar to that case, let’s use the identification of $\mathbb F_2$ inside $\mathbb F_2^2$ and write $0$ and $1$ to mean $(0, 0)$ and $(1, 0)$. Now instead of the symbol $i$ as with the complex numbers let’s use $x$ to mean $(0, 1)$. There’s no real reason for it. Just that $i$ is highly associated with complex numbers, we want to emphasize that this is not that field. So now we have&lt;&#x2F;p&gt;
&lt;p&gt;$$(0,0) = 0 + 0x = 0$$&lt;br &#x2F;&gt;
$$(1, 0) = 1 + 0x = 1$$&lt;br &#x2F;&gt;
$$(0, 1) = 0 + 1x = x$$&lt;br &#x2F;&gt;
$$(1,1) = 1+1x = 1 + x$$&lt;&#x2F;p&gt;
&lt;p&gt;And using the multiplication rule we just discovered, we obtain $x^2 = 1 + x$.&lt;br &#x2F;&gt;
This equation is all we need to be able to multiply any two elements by repeatedly applying it whenever a power larger than $1$ appears. For example:&lt;br &#x2F;&gt;
$$(1+x)x = x + x^2 = x + 1 + x = 1.$$&lt;&#x2F;p&gt;
&lt;p&gt;The set $\mathbb F_2^2$ with this addition and multiplication has its symbol: it is denoted $\mathbb F_4$ and is called &lt;em&gt;the field with four elements&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;binary-strings-of-length-3&quot;&gt;Binary strings of length $3$&lt;&#x2F;h2&gt;
&lt;p&gt;The same process can be done with triplets $(a,b,c)$ of elements of $\mathbb F_2$. The elements of this set are $(0,0,0), (1,0,0), (0,1,0),(1,1,0)$, etc. It has $8$ elements, and we will denote it by $\mathbb F_2^3$. We have the component-wise addition&lt;br &#x2F;&gt;
$$(a,b,c) + (a’,b’,c’) = (a+a’, b+b’, c+c’)$$&lt;br &#x2F;&gt;
We can play the same game as before and discover a multiplication rule on $\mathbb F_2^3$ such that it forms a field together with the component-wise addition. In this case, we can even find one such that $(0,1,0)\cdot(0,1,0) = (0,0,1)$. We are not going to show the whole process. You can try it out for yourself!&lt;&#x2F;p&gt;
&lt;p&gt;Similar to the previous case, this field is denoted $\mathbb F_8$, and it’s the unique field with $8$ elements.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;notation-1&quot;&gt;Notation&lt;&#x2F;h4&gt;
&lt;p&gt;We identify $\mathbb F_2$ in $\mathbb F_8$ as the elements with null second and third coordinates. That is, $\mathbb F_2$ is ${(0,0,0), (1,0,0)}$.&lt;&#x2F;p&gt;
&lt;p&gt;Now that we have three coordinates, we need two new symbols, $x$ and $y$, to write an element $(a,b,c)$ as $a + bx + cy$. But, since $(0,1,0)\cdot(0,1,0)$ equals $(0,0,1)$, we have $x^2 = y$. So we need only one symbol and can write $(a,b,c)$ as $a + bx+ cx^2$.&lt;&#x2F;p&gt;
&lt;p&gt;If you construct the multiplication rule as in the case of binary strings of length $2$ you’ll find that $(0,1,0)\cdot(0,0,1) = (1,1,0)$. With this notation, this is $x^3 = 1 + x$. Similar to the previous case. This equation is all we need to multiply elements. For example&lt;&#x2F;p&gt;
&lt;p&gt;$$(1 + x^2)(1 + x) = 1 + x + x^2 + x^3 = 1 + x + x^2 + 1 + x = x^2.$$&lt;&#x2F;p&gt;
&lt;h2 id=&quot;general-case&quot;&gt;General case!&lt;&#x2F;h2&gt;
&lt;p&gt;Suppose we start with $\mathbb F_p$, where $p$ is some prime number. We can consider the set of tuples $(a_0, a_1, \dots, a_{n-1})$, all of the same length $n$, and call that set $\mathbb F_{p^n}$. In there, we have the component-wise addition. A theorem states that there always exists a multiplication rule on $\mathbb F_{p^n}$ such that it forms a field! Moreover, all multiplication rules are essentially the same. And so this means that there is a unique field of $p^n$ elements.&lt;&#x2F;p&gt;
&lt;p&gt;Everything we showed for the binary strings of length $2$ and $3$ works here. We can write every element $(a_0, a_1, \dots, a_{n-1})$ as&lt;br &#x2F;&gt;
$$a_0 + a_1x + a_2x^2 + \cdots + a_{n-1}x^{n-1}$$&lt;&#x2F;p&gt;
&lt;p&gt;This notation is consistent with the multiplication rule, just like before. Also, there will be an equality of the form $x^n = b_0 + b_1x + \cdots + b_{n-1}x^{n-1}$ for some elements $b_i$ in $\mathbb F_p$.&lt;&#x2F;p&gt;
&lt;p&gt;And every finite field is of this form!&lt;&#x2F;p&gt;
&lt;h3 id=&quot;towers-of-fields&quot;&gt;Towers of fields&lt;&#x2F;h3&gt;
&lt;p&gt;The same works if we use any finite field $F$ as a building block. For example, we could start from $F = \mathbb F_8$. We can consider tuples $(a_0, \cdots, a_{n-1})$ of elements of $F$, and everything follows the same. There will always be a multiplication rule on $F^n$, making it a field. This is useful for constructing large extensions in small steps.&lt;&#x2F;p&gt;
&lt;p&gt;Say for example we need to work with $\mathbb F_{p^{12}}$, the field with $p^{12}$ elements (for some prime number $p$). We could construct it from scratch by finding a multiplication rule on $\mathbb F_p^{12}$, the set of tuples of length $12$ elements of $\mathbb F_p$.&lt;br &#x2F;&gt;
Another approach is as follows. Construct first the field $\mathbb F_{p^6}$ of $p^6$ elements. Then consider tuples $(a,b)$ with $a,b \in \mathbb F_{p^6}$. There is a multiplicative rule on that set of tuples, making it a field. That will be $\mathbb F_{p^{12}}$. These are called field towers and are a common way of constructing finite fields.&lt;&#x2F;p&gt;
&lt;p&gt;The case of $\mathbb F_{p^{12}}$ is particularly interesting when working with the BLS12-377 or BLS12-381 curves. It is the field where all the points relevant to the pairings are defined.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-set-of-bytes&quot;&gt;The set of bytes&lt;&#x2F;h2&gt;
&lt;p&gt;Note that $\mathbb F_{256}$ is the set of all possible bytes. Its elements are tuples $(a_0, a_1,\dots, a_7)$ of elements of $\mathbb F_2$. We denote them by $a_0 + a_1x + a_2x^2 + \cdots + a_7x^7$. Here the equation is $x^8 = x^4 + x^3 + x + 1$.&lt;&#x2F;p&gt;
&lt;p&gt;The &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Advanced_Encryption_Standard&quot;&gt;Advanced Encryption Standard&lt;&#x2F;a&gt; (AES) uses this field as part of the block cipher!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;&#x2F;h2&gt;
&lt;p&gt;In the same way that complex numbers are just pairs of real numbers, field extensions of finite fields are just tuples of elements of some $\mathbb F_p$. It is not evident how to come up with the multiplication rule, but mathematicians have proved that it always exists, and the resulting field is essentially unique in a rigorous way we are not mentioning here. Field extensions are essential in many proving systems, especially those relying on Kate-Zaverucha-Goldberg (KZG) commitments.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Weird ways to multiply really fast with Karatsuba, Toom–Cook and Fourier</title>
          <pubDate>Mon, 02 Jan 2023 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://blog.lambdaclass.com/posts/weird-ways-to-multiply-really-fast-with-karatsuba-toom-cook-and-fourier/</link>
          <guid>https://blog.lambdaclass.com/posts/weird-ways-to-multiply-really-fast-with-karatsuba-toom-cook-and-fourier/</guid>
          <description xml:base="https://blog.lambdaclass.com/posts/weird-ways-to-multiply-really-fast-with-karatsuba-toom-cook-and-fourier/">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;&#x2F;h2&gt;
&lt;p&gt;The applicability and performance of algorithms depend on how fast certain routine computations can be done. For example, in &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Elliptic-curve_cryptography&quot;&gt;elliptic curve cryptography&lt;&#x2F;a&gt;, one needs to calculate the public key as $k\times g=g+g+g+….+g$, where $k$ is a very large integer (typically a number with a hundred digits or so) and $g$ is a point of the elliptic curve $(x,y)$, known as the generator. If done naïvely, that is, adding repeatedly $g$ to itself, it would take about $10^{100}$ operations (we say that the algorithm runs in $\mathcal{O}(n)$, indicating that the number of operations -up to some constant factor- increases with $k$ in a linear fashion). The fastest supercomputer can perform less than $10^{18}$ &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;FLOPS&quot;&gt;floating point operations per second&lt;&#x2F;a&gt;; it would take you forever to do just one calculation. Nevertheless, we perform such calculations or related ones everyday, thanks to developing faster algorithms (for example, we can reduce the computation time by repeatedly adding $g+g=2g$, $2g+2g=4g$, etc, reducing the number of calculations to $\mathcal{O}(\log(n))$ -compare $10^{100}$ to something like $100\times \log_2{10}$).&lt;&#x2F;p&gt;
&lt;p&gt;zk-SNARKs (zero-knowledge succinct non-interactive arguments of knowledge) are important cryptographic primitives that allow one party (the prover) to convince another (the verifier) that a certain statement is true, without revealing anything else other than the validity of that statement. The applications of zk-SNARKs are far-ranging, given their potential as a foundation for new forms of governance, data sharing, and financial systems. For example, you could delegate a hard computation to an untrusted party and get a proof that allows you to verify the integrity of the computation, without the need to re-run everything. The key is that proofs are succinct, so they can be verified in the order of hundreds of milliseconds, as opposed to performing the whole computation. The construction relies on transforming the computation to polynomials and checking conditions over the polynomials. Polynomial multiplication can be done in a very efficient way via the fast Fourier transform -one of the most important algorithms ever devised by mankind-. Moreover, this calculation can be parallelized: several processors can run parts of the algorithm to make it even faster.&lt;&#x2F;p&gt;
&lt;p&gt;Even simple calculations such as integer multiplications (which take place almost everywhere) can be done faster than the school rule, provided the numbers we are trying to multiply are large enough.&lt;&#x2F;p&gt;
&lt;p&gt;If you want to learn how to speed up some ordinary calculations and make your algorithms run faster, then the next sections are for you.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;divide-and-conquer-karatsuba&quot;&gt;Divide and conquer: Karatsuba&lt;&#x2F;h2&gt;
&lt;p&gt;We all learned at elementary school how to multiply two numbers: we write one below the other and proceed to multiply each of the numbers above by each digit of the number below and then we add all the numbers:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;1234 &lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;×          152&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;———————————————&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;      2468 ( =  1234 ×     2)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;     6170  ( =  1234 ×    50)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    1234   ( =  1234 ×   100)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;———————————————&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    187568 ( = 187568)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This algorithm has $\mathcal{O}(n^2)$. In 1960, Kolmogorov speculated that this represented the asymptotic bound for multiplication (that is, multiplication of two numbers could not take less than $\mathcal{O}(n^2)$ operations). He gave a lecture on the topic and one of the students, Karatsuba, then 23 years old, came up with a solution that runs with $\mathcal{O}(n^{\log_2(3)})$, thus disproving Kolmogorov’s conjecture. The basic idea of Karatsuba’s algorithm is the following: say we want to multiply $x$ and $y$; we can break them into smaller numbers:&lt;br &#x2F;&gt;
$x=x_1\times 10^m +x_0$&lt;br &#x2F;&gt;
$y=y_1\times 10^m +y_0$&lt;br &#x2F;&gt;
where both $x_0$ and $y_0$ are numbers less than $10^m$. The product $x\times y$ is simply:&lt;br &#x2F;&gt;
$x\times y=x_1\times y_1\times 10^{2m}+(x_1\times y_0+y_1\times x_0)\times 10^m+x_0y_0$&lt;br &#x2F;&gt;
Karatsuba found that $x_1y_0+y_1x_0$ can be calculated efficiently at the expense of some additions:&lt;br &#x2F;&gt;
$x_1\times y_0+y_1\times x_0=(x_1+x_0)\times (y_1+y_0)-x_1\times y_1-x_0\times y_0$.&lt;br &#x2F;&gt;
Even if there are some extra calculations, these operate over smaller numbers, resulting in an overall smaller cost for large numbers.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;toom-cook-algorithm&quot;&gt;Toom-Cook algorithm&lt;&#x2F;h2&gt;
&lt;p&gt;The divide and conquer strategy can be taken further, leading to a reduction in the complexity of the multiplication algorithm. Toom and Cook developed several methods (known as Toom-X, X being a number), which consist of the following stages:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    1. Splitting&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    2. Evaluation&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    3. Pointwise multiplication&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    4. Interpolation&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    5. Recomposition&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Several variants of the algorithms are implemented in &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;gmplib.org&#x2F;&quot;&gt;GNU Multiple Precision Arithmetic Library&lt;&#x2F;a&gt;. Toom-2 is the same as Karatsuba’s algorithm. Toom-X begins by splitting the numbers $x$ and $y$ in X parts of equal length(1) and these are treated as the coefficients of some polynomial (we focus on Toom-3, but you can see more details &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;gmplib.org&#x2F;manual&#x2F;Toom-4_002dWay-Multiplication&quot;&gt;here&lt;&#x2F;a&gt;)(2):&lt;br &#x2F;&gt;
$x(t)=x_2 t^2+x_1 t+x_0$&lt;br &#x2F;&gt;
$y(t)=y_2 t^2+y_1 t+y_0$&lt;br &#x2F;&gt;
If we evaluate $x$, $y$ at $t=b$, we get the numbers back. The multiplication of both numbers is equal to a polynomial of degree $2(X-1)$,&lt;br &#x2F;&gt;
$w(t)=w_4t4+w_3t3+w_2t^2+w_1t+w_0$&lt;br &#x2F;&gt;
We can evaluate the polynomials at 5 different points, which will suffice to determine uniquely the polynomial $w$ due to the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Polynomial_interpolation#Interpolation_theorem&quot;&gt;interpolation theorem&lt;&#x2F;a&gt;. We can choose 5 convenient points which make the evaluation and reconstruction of the polynomial easy. Common points are $0, 1, -1, 2$ and $\infty$ (this last one is just the product of the main coefficients). Let’s see the form of each value:&lt;br &#x2F;&gt;
$w(0)=x(0)y(0)=x_0y_0$&lt;br &#x2F;&gt;
$w(1)=x(1)y(1)=(x_0+x_1+x_2)(y_0+y_1+y_2)$&lt;br &#x2F;&gt;
$w(-1)=x(-1)y(-1)=(x_0-x_1+x_2)(y_0-y_1+y_2)$&lt;br &#x2F;&gt;
$w(2)=x(2)y(2)=(x_0+2x_1+4x_2)(y_0+2y_1+4y_2)$&lt;br &#x2F;&gt;
$w(\infty)=x(\infty)y(\infty)=x_2y_2$&lt;&#x2F;p&gt;
&lt;p&gt;If we look at things from $w$ and its coefficients, we get:&lt;br &#x2F;&gt;
$w(0)=w_0$&lt;br &#x2F;&gt;
$w(1)=w_4+w_3+w_2+w_1+w_0$&lt;br &#x2F;&gt;
$w(-1)=w_4-w_3+w_2-w_1+w_0$&lt;br &#x2F;&gt;
$w(2)=16w_4+8w_3+4w_2+2w_1+w_0$&lt;br &#x2F;&gt;
$w(\infty)=w_4$&lt;&#x2F;p&gt;
&lt;p&gt;This is just solving one linear system (where 2 coefficients are straightforward). Once the coefficients are known, all that remains is to evaluate $w$ at $t=b$ and add. Toom-3 has a lower order ($\mathcal{O}(n{\log(5)&#x2F;\log(3)})=\mathcal{O}(n{1.46}$)) than Karatsuba’s method ($\mathcal{O}(n^{1.58})$, so it runs faster for sufficiently large integers.&lt;&#x2F;p&gt;
&lt;p&gt;For larger integers (in the order of 10,000 to 40,000 digits), we can go faster by means of the Schönhage-Strassen algorithm, which uses the fast-Fourier transform (FFT) to achieve a complexity $\mathcal{O}(n\log(n)\log\log(n))$. Before we can explain the algorithm, we need to introduce the FFT. The order can be further reduced to &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;hal.archives-ouvertes.fr&#x2F;hal-02070778&#x2F;document&quot;&gt;$\mathcal{O}(n\log(n))$&lt;&#x2F;a&gt;, but this algorithm is only practical for (super-ultra) incredibly large numbers and is an example of a &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Galactic_algorithm&quot;&gt;galactic algorithm&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-fast-fourier-transform&quot;&gt;The Fast-Fourier Transform&lt;&#x2F;h2&gt;
&lt;p&gt;The FFT is one of the key building blocks of many important algorithms, such as fast multiplication of very large numbers, polynomial multiplication, solving finite difference equations, error correcting codes (Reed-Solomon codes), and digital signal processing. It was used by Gauss early in the 19th century when he was trying to interpolate the orbits of asteroids Pallas and Juno. A simple implementation requires $\mathcal{O}(n^2)$ operations. In 1965, Cooley and Tukey realized that the algorithm could be implemented more efficiently, reducing it to $\mathcal{O}(n\log(n))$, which led to its widespread use. Almost every language and numerical computation library have it implemented. In Rust, you can check this &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;docs.rs&#x2F;GSL&#x2F;latest&#x2F;rgsl&#x2F;fft&#x2F;index.html&quot;&gt;link&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;To get an idea of the huge improvement over the naïve algorithm, let’s look at the number of calculations for different samples:&lt;&#x2F;p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Number of samples&lt;&#x2F;th&gt;&lt;th&gt;$10^3$&lt;&#x2F;th&gt;&lt;th&gt;$10^6$&lt;&#x2F;th&gt;&lt;th&gt;$10^{12}$&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;DFT operations&lt;&#x2F;td&gt;&lt;td&gt;$10^6$&lt;&#x2F;td&gt;&lt;td&gt;$10^{12}$&lt;&#x2F;td&gt;&lt;td&gt;$10^{24}$&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;FFT operations&lt;&#x2F;td&gt;&lt;td&gt;$10^4$&lt;&#x2F;td&gt;&lt;td&gt;$2\times10^{7}$&lt;&#x2F;td&gt;&lt;td&gt;$4\times10^{13}$&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
&lt;p&gt;We see that the amount of computations is reduced by more than two orders of magnitude for samples with $1000$ or more elements!&lt;&#x2F;p&gt;
&lt;h3 id=&quot;fft-over-complex-numbers&quot;&gt;FFT over complex numbers&lt;&#x2F;h3&gt;
&lt;p&gt;The Fourier transform maps a function from its original domain (space or time) to another function depending on the (space or time) frequency. Stated another way, it decomposes a function into a collection of sine waves with different frequencies and amplitudes, which are useful to analyze the behavior of a given system. We can also perform the inversion, adding all those waves to recover the original function. Even though (continuous) Fourier transforms have many applications, we will be interested in discrete Fourier transforms (DFT), where we have a finite collection of data. Given data $x_0$, $x_1$,…$x_{N-1}$, the DFT gives a sequence $X_0, X_1,…X_{N-1}$, where&lt;br &#x2F;&gt;
$X=\sum_{k=0}^{N-1} x_k\exp(-2\pi i k&#x2F;N)$&lt;br &#x2F;&gt;
where $i^2=-1$ is the imaginary unit. Inversion of the DFT is given by&lt;br &#x2F;&gt;
$x=\frac{1}{N}\sum_{k=0}^{N-1} X_k\exp(2\pi i k&#x2F;N)$.&lt;&#x2F;p&gt;
&lt;p&gt;The DFT can be cast in the form of a matrix-vector product, $X=Mx$, where $M$ is the $N\times N$ DFT matrix:&lt;br &#x2F;&gt;
$M_{ij}=\omega^{(i-1)\times (j-1)}$&lt;br &#x2F;&gt;
where $\omega=\exp(2\pi i&#x2F;N)$ and $i$ and $j$ take the values $1,2,3,…N$&lt;&#x2F;p&gt;
&lt;p&gt;Implemented this way, the DFT requires $N^2$ operations, resulting from vector-matrix multiplication. The FFT will make this calculation more efficient, by taking advantage of the structure and using a divide and conquer strategy.&lt;&#x2F;p&gt;
&lt;p&gt;We can also see the DFT as evaluating a polynomial with coefficients $x_k$ over the roots of unity. This will be useful when discussing fast polynomial multiplication.&lt;&#x2F;p&gt;
&lt;p&gt;The key point is that computing the DFT with $N$ points can be reduced to calculating two DFTs with $N&#x2F;2$ points. We can apply this recursively to break down a very large problem into a collection of smaller and easier-to-solve subproblems and then recombine those results to get the DFT.&lt;&#x2F;p&gt;
&lt;p&gt;The algorithm also takes advantage of the properties of the $n$-th roots of unity in the complex plane. A number $z$ is known as an $n$-root of unity if $z^n=1$. These are of the form&lt;br &#x2F;&gt;
$z_k=\exp(2\pi i k&#x2F;n)$ for $k=0,1,2,…,n-1$. An interesting point is that these roots come in conjugate pairs: for each root $r$ we have the corresponding $\bar{r}$ (as a matter of fact, they form a finite group of order $n$ under multiplication). For example, the fourth roots of unity are: $1, i, -1, -i$. It is easy to see which are the pairs.&lt;&#x2F;p&gt;
&lt;p&gt;To see how all works, suppose we have a vector $x=(x_0,x_1,x_2,…x_{n-1})$ and we want to compute the FFT. We can split between even and odd numbered terms:&lt;br &#x2F;&gt;
$X=\sum_{k=0}^{n&#x2F;2-1} x_{2k}\exp(2\pi i 2k&#x2F;n)+\sum_{k=0}^{n&#x2F;2-1} x_{2k+1}\exp(2\pi i (2k+1)&#x2F;n)$&lt;br &#x2F;&gt;
We can express the odd terms in a different way, by taking out a factor of $\exp(2\pi i&#x2F;n)$,&lt;br &#x2F;&gt;
$X=\sum_{k=0}^{n&#x2F;2-1} x_{2k}\exp(2\pi i 2k&#x2F;n)+\exp(2\pi i&#x2F;n)\sum_{k=0}^{n&#x2F;2-1} x_{2k+1}\exp(2\pi i (2k)&#x2F;n)$&lt;br &#x2F;&gt;
We can now see that the factors corresponding to the $n$-roots of unity repeat themselves whenever $k$ is larger than $n&#x2F;2$. Another way to see this is to rearrange the terms by taking $2$ from the numerator of the exponential and sending it to the denominator:&lt;br &#x2F;&gt;
$X=\sum_{k=0}^{n&#x2F;2-1} x_{2k}\exp(2\pi i k&#x2F;(n&#x2F;2))+\exp(2\pi i&#x2F;n)\sum_{k=0}^{n&#x2F;2-1} x_{2k+1}\exp(2\pi i (k)&#x2F;(n&#x2F;2))$&lt;br &#x2F;&gt;
We now find that $\sum_{k=0}^{n&#x2F;2-1} x_{2k}\exp(2\pi i k&#x2F;(n&#x2F;2))=DFT(x_{2k})$ is just the DFT of the even terms, which contains $n&#x2F;2$ points. Similarly, $\sum_{k=0}^{n&#x2F;2-1} x_{2k+1}\exp(2\pi i (k)&#x2F;(n&#x2F;2))$ is the DFT of the odd terms, containing $n&#x2F;2$ points. This way, we broke the $n$ point DFT into two smaller $n&#x2F;2$ point DFTs, which can be combined to yield the original one. Now, each of those $n&#x2F;2$ DFTs can be broken into two smaller ones, so we can recursively reduce the number of computations by working with smaller samples (this way, we save ourselves of the large vector-matrix product).&lt;&#x2F;p&gt;
&lt;h3 id=&quot;extending-the-fft-to-arbitrary-rings&quot;&gt;Extending the FFT to arbitrary rings&lt;&#x2F;h3&gt;
&lt;p&gt;FFT can be extended from complex or real numbers to arbitrary rings, such as integers or polynomials (check our &lt;a href=&quot;&#x2F;math-survival-kit-for-developers&#x2F;&quot;&gt;math survival kit&lt;&#x2F;a&gt;). In particular, we can use the number theoric transform which specializes the FFT to $\mathbb{Z}&#x2F;p\mathbb{Z}$, that is, the integers modulo $p$ (a prime number). Here we also have the $n$-roots of unity, given by&lt;br &#x2F;&gt;
$\alpha^n\equiv 1 \pmod{p}$&lt;br &#x2F;&gt;
It is important that we restrict ourselves to prime numbers: in this case, we have that the square root of $1$ are just $1$ and $-1$. For example, if we take $p=5$, $1^2\equiv 1 \pmod{5}$ and $-1\equiv 4$, $4^2 =16 \equiv 1 \pmod{5}$. This is not true for $8$ since $1^2\equiv 3^2\equiv 5^2\equiv 7^2\equiv 1 \pmod{8}$ and we would have $4$ square roots!&lt;&#x2F;p&gt;
&lt;p&gt;The problem with using FFT in finite fields is that we are not free to choose the domain and the field just as we please. We need to select a multiplicative subgroup of order $2^n$ (in other words, we need to select a group that is generated by an element $g$ and which contains its powers up to $2^n$). For example, if we take $p=5$, we have a group of order $4=2^2$ which is generated by $2$: ${21=2,22=4,2^3\equiv 3, 2^4\equiv 1}$; it does not need to span all the elements of the field, though.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;fft-multiplication-algorithm&quot;&gt;FFT multiplication algorithm&lt;&#x2F;h2&gt;
&lt;p&gt;The algorithm follows the same line as Karatsuba’s and Toom’s:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    1. Split&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    2. Evaluation&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    3. Pointwise multiplication&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    4. Interpolation&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    5. Combination&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The key difference lies in the use of the FFT to speed up calculations.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;polynomial-multiplication&quot;&gt;Polynomial multiplication&lt;&#x2F;h3&gt;
&lt;p&gt;Let’s start with polynomial multiplication. Given two polynomials, $p(x)=p_d xd+p_{d-1}x{d-1}+…+p_0$ and $q(x)=q_d xd+q_{d-1}x{d-1}+…+q_0$, we want to find their product, $w(x)=p(x)q(x)$. The simplest algorithm would be to apply repeatedly the distributive property, perform the multiplications and rearrange everything. The product of two polynomials of degree $d$ is a polynomial of degree $2d$. We can see that this strategy involves operations of the order $\mathcal{O}(d^2)$, that is, operations grow quadratically with the degree of the polynomials involved. We can take advantage of the structure of the polynomials and the interpolation theorem. We have at least two forms to describe the same polynomial:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    * Giving the $d+1$ coefficients.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    * Specifying the value of the polynomial at exactly $d+1$ points(3).&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;What are the advantages of the second option? That we get to choose the points freely and reduce the number of calculations. For example, if we have an even function, $f(x)=f(-x)$ we can evaluate fewer points. Similarly, if the function is odd, $f(-x)=-f(x)$ and we have to change the sign to get the value of $-x$. So, choosing pairs $x$ and $-x$ we reduce the number of evaluations by half (except if we choose $0$, for example). We can split our polynomial between two polynomials: one has odd number terms, and the other even:&lt;br &#x2F;&gt;
$p(x)=p_e(x)+xp_o(x)$.&lt;br &#x2F;&gt;
For example, if $p=x5+3x4+5x3+2x2+6x+3$, we split it:&lt;br &#x2F;&gt;
$p(x)=(3x4+2x2+3)+x(x4+5x2+6)$&lt;br &#x2F;&gt;
We have then:&lt;br &#x2F;&gt;
$p_e=(3x4+2x2+3)$ and $p_o=(x4+5x2+6)$, where both polynomials are even functions! This way, we easily see that:&lt;br &#x2F;&gt;
$p(-x)=p_e(x)-xp_o(x)$&lt;br &#x2F;&gt;
If we have pairs $(x_k,p(x_k))$ and $(x_k,q(x_k))$, the product polynomial evaluated at $x_k$ is $(x_k,p(x_k)q(x_k))$.&lt;&#x2F;p&gt;
&lt;p&gt;To determine the product polynomial, we need $2d+1$ points; taking advantage of the above strategy, we need fewer point evaluations. If we could convert easily from the coefficient form to point evaluations, perform the multiplications in that form, and then transform back to coefficient form, we can achieve a lower complexity. We can recursively break the polynomials $p_e(x^2)$ and $p_o(x^2)$ into smaller polynomials.&lt;&#x2F;p&gt;
&lt;p&gt;We can choose as evaluation points the $n$ roots of unity, which come in pairs: $exp(2\pi i k&#x2F;n)$ with $k=0,1,2…n-1$. In other words, we can quickly calculate the DFT of the polynomials, multiply the coefficients and reverse the DFT once the product has been found. This leads to operations in the order $\mathcal{O}(d\log(d))$.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;integer-multiplication&quot;&gt;Integer multiplication&lt;&#x2F;h3&gt;
&lt;p&gt;To apply the FFT to integer multiplication, we need to transform our numbers to the coefficients of polynomials, perform the FFT multiplication and finally reconstruct the result. Overall this will take $\mathcal{O}(n\log(n)\log(\log(n))$. There is a large overhead, which will make this algorithm practical only for very large integers. For example, if we want to multiply $3578$ and $2457$, we can define vectors $(8,7,5,3,0,0,0,0)$ and $(7,5,4,2,0,0,0,0)$, where we conveniently pad the numbers with zeros.&lt;&#x2F;p&gt;
&lt;p&gt;Typically, operations are performed modulo $2^N+1$, where $N$ is larger than the combined number of bits of the integers $x$ and $y$, to make sure that results never wrap around.&lt;&#x2F;p&gt;
&lt;p&gt;The Fourier transform has the advantage that an operation such as the convolution of $x$ and $y$ can be calculated from the product of the transforms $X$ and $Y$ and transforming back:&lt;br &#x2F;&gt;
$\sum_{k=0}^{N} x_k y_{N-k}=IFFT(FFT(y)\times FFT(x))$&lt;&#x2F;p&gt;
&lt;p&gt;The Schönhage-Strassen algorithm makes use of the negacyclic convolution. Given vectors $x$ and $y$ of length $n$ and $r$ a $2n$-th (primitive) root of unity (that is, $r^{2n}\equiv 1 \pmod{p}$ and $r^k\not\equiv 1$ if $0&amp;lt;k&amp;lt;2n$), we can define the following weight vectors:&lt;br &#x2F;&gt;
$W_j=r^j$ for $0\leq j&amp;lt;n$&lt;br &#x2F;&gt;
$W_j{-1}=r{-j}$ for $0\leq j&amp;lt;n$&lt;br &#x2F;&gt;
The negacyclic convolution (NCC) of $x$ and $y$ can be computed as:&lt;br &#x2F;&gt;
$NCC(x,y)=W^{-1}IFFT(FFT(Wx)\times FFT(Wy))$&lt;&#x2F;p&gt;
&lt;p&gt;A comparison of the different methods implemented in GNU Multiple Precision Arithmetic Library is shown in this &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;gmplib.org&#x2F;devel&#x2F;&quot;&gt;link&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;&#x2F;h2&gt;
&lt;p&gt;Choosing the right algorithms to carry out routine calculations, such as integer or polynomial multiplications, can have a dramatic effect on the performance of software. Depending on the size of the integers, it is possible to speed up (reducing the number of calculations) by adopting a divide and conquer approach: we break the calculation into smaller ones, which can be easily tackled, or continue breaking them down until they are manageable. All the fast algorithms we presented make use of this approach, leading to significant savings in computations. The FFT, thanks to its complexity $\mathcal{O}(n\log(n))$ can be a valuable tool to accelerate computations, even though it may at first seem weird or farfetched!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;notes&quot;&gt;Notes&lt;&#x2F;h2&gt;
&lt;p&gt;(1) If this is not possible, the most significant part can be shorter than the rest.&lt;br &#x2F;&gt;
(2) We will drop the multiplication symbol just for convenience.&lt;br &#x2F;&gt;
(3) We mentioned this earlier with the Toom-Cook method. For example, we know from geometry that we need to give two points to determine a straight line, which is a one-degree polynomial.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Math Survival Kit for Developers</title>
          <pubDate>Fri, 19 Aug 2022 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://blog.lambdaclass.com/posts/math-survival-kit-for-developers/</link>
          <guid>https://blog.lambdaclass.com/posts/math-survival-kit-for-developers/</guid>
          <description xml:base="https://blog.lambdaclass.com/posts/math-survival-kit-for-developers/">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;&#x2F;h2&gt;
&lt;p&gt;When working with cryptographic applications you need to understand some of the underlying math (at least, if you want to do things properly). For example, the RSA cryptographic system (which was one of the earliest methods and most widely adopted, until it lost ground to better methods, such as those based on elliptic curves) works by encrypting a message $M$ (expressed as a number in the range 1,2,3,…$n-1$, with $n$ a large composite number) with a public key $e$ doing the following calculation:&lt;br &#x2F;&gt;
$E(M)=M^e \pmod{n}$&lt;br &#x2F;&gt;
If you want to decrypt the message, you need the private key, $d$ and perform:&lt;br &#x2F;&gt;
$M=E(M)^d \pmod{n}$.&lt;br &#x2F;&gt;
Now, what do all these calculations mean and why does RSA work? The trick relies on Euler’s theorem and the fact that $d$ and $e$ are related by $d\times e \equiv 1 \pmod{\phi(n)}$, so that when we apply $e$ and afterward $d$, “it is the same as” elevating the message to 1. Of course, there are quite many symbols you might not understand, but some key concepts are, in fact, quite straightforward. They are just shrouded in the mist by all the math jargon, which makes things very easy to state for those knowing the meaning, but it can be quite challenging for someone who is not acquainted with them.&lt;&#x2F;p&gt;
&lt;p&gt;Another problem frequently showing up is finding prime numbers (in general, very large numbers, with 100 or more digits) or determining whether a certain number is prime or composite. For example, in zk-SNARKs (zero-knowledge succinct non-interactive arguments of knowledge), one of the key ingredients is the ability to perform (something similar to) homomorphic encryption. This is achieved in practice by pairing two elliptic curves over two sets of numbers, where the total number of elements is the prime $m$, satisfying $m=k\times 2^N+1$, with $k$ an odd number and $N$ a large number. We say that $m$ has large 2-adicity and is expressed in compact form as $m-1\equiv 0 \pmod{2^N}$ or $2^N \mid m-1$ (this is read as $2^N$ divides $m-1$). In RSA, the number $n$ is the product of two large prime numbers, $p$ and $q$, that is, $n=p\times q$. If you choose two primes that are very close to each other, your cryptographic system could be easily broken using &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fermat%27s_factorization_method&quot;&gt;Fermat’s method to factorize numbers&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;We see, therefore, that we need to understand the math behind it to know which tricks we can apply to solve a problem easily, how to break a cryptographic system or what are the limitations or weaknesses of our own systems. We will be explaining many key ideas of number theory and abstract algebra to help you build the foundations you need to deal with cryptography.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;natural-numbers-integers-rational-real-and-complex-numbers&quot;&gt;Natural numbers, Integers, Rational, Real and Complex numbers.&lt;&#x2F;h2&gt;
&lt;p&gt;Natural numbers are those we use to count objects and were the first things we learned at school: $1,2,3,4…$ are natural numbers. The set (collection) of these numbers is frequently represented by $\mathbb{N}$. Numbers like $-1$, $-2$, $0$, etc, are part of the integers; the set is represented by $\mathbb{Z}$ (from German, &lt;em&gt;zahlen&lt;&#x2F;em&gt; , numbers). Numbers that can be expressed as the ratio of two integers $a$ and $b$ (with $b\neq 0$) are called rational, $r=a&#x2F;b$ and the set is denoted by $\mathbb{Q}$. Rational numbers can be extended with the addition of irrational numbers (such as $\pi$ and $e$) to form the set of real numbers $\mathbb{R}$. You might have also heard of the complex numbers $\mathbb{C}$, which contain numbers such as $i$, where $i^2=-1$.&lt;&#x2F;p&gt;
&lt;p&gt;In the integers, we have the four basic operations: addition, subtraction, multiplication and division. Let’s focus first on addition and subtraction:&lt;br &#x2F;&gt;
If we take $a$ and $b$ in $\mathbb{Z}$, then $c=a+b$ and $d=a-b$ are also in $\mathbb{Z}$. We say the sum and subtraction are closed operations on the set.&lt;br &#x2F;&gt;
2. If we add $0$ to any number $a$, we get $a$, that is, $a+0=0+a=a$. $0$ is the additive identity of $\mathbb{Z}$.&lt;br &#x2F;&gt;
3. We know that if we sum $a$ and $-a$ we get $0$. That is, $a+(-a)=a-a=0$, so subtracting is the same as adding $-a$. $-a$ is the additive inverse of $a$.&lt;br &#x2F;&gt;
4. Given $a$, $b$ and $c$, $a+(b+c)=(a+b)+c$. This is the associative property.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;groups&quot;&gt;Groups&lt;&#x2F;h2&gt;
&lt;p&gt;The above properties show that the set of integers $\mathbb{Z}$ with the $.+.$ operation form an algebraic group. Other sets, combined with different operations, have the same mathematical structure. For example, positive rational numbers with multiplication have a group structure. $n\times n$ invertible matrices form a group under the matrix multiplication. &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Vector_space&quot;&gt;Vector spaces&lt;&#x2F;a&gt; form a group under the addition (if you take any two vectors $u$ and $v$, their sum is always in the vector space). Elliptic curve cryptography uses the fact that adding two points over an elliptic curve always results in a third point over the curve. Groups appear in many applications in Mathematics, Physics and Chemistry. We can define a group as a (non-empty) set $G$ together with a binary operation (that is, an operation that takes two input elements from the set $G$) $\times$ satisfying:&lt;br &#x2F;&gt;
G1. If $a$ and $b$ are in the set, then $a\times b=c$ is also in the set.&lt;br &#x2F;&gt;
G2. There is an identity element, $e$, such that $e\times a=a\times e=a$.&lt;br &#x2F;&gt;
G3. If $a$ is in the set, there is some $b$ in the set such that $a\times b=e$. We say that $b$ is the inverse of $a$ and denote it $b=a^{-1}$.&lt;br &#x2F;&gt;
G4. For $a,b,c$, $a\times (b\times c)=(a\times b)\times c$.&lt;&#x2F;p&gt;
&lt;p&gt;The notation in groups is sometimes confusing and people can freely use additive (+) or multiplicative ($\times$) notation, and call their identities either $0$ or $1$. This doesn’t matter much, since the binary operation can be quite weird (such as “addition” on elliptic curves). If you can start by looking at things a little bit more abstractly, it will pay off very quickly.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Exercise: Take the space of $n\times n$ matrices, such that their determinant is non-zero (that is, the set of invertible matrices). Show that this is a group.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;We also learned at school that addition in the integers is commutative (that is, the order of the factors does not change the result $a+b=b+a$). Not all groups satisfy this condition, though. For those privileged groups, we have the name Abelian (or commutative) group. An Abelian group has an additional condition:&lt;br &#x2F;&gt;
G5. If $a$, $b$ are in $G$, $a\times b = b\times a$.&lt;&#x2F;p&gt;
&lt;p&gt;When we look at multiplication and division in the integers, we see that there are some problems.&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    1. If $a$ and $b$ are integers, $a\times b=c$ is also an integer. The operation is closed under multiplication.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    2. If we multiply any number by $1$, we get the same number. $1$ is the multiplicative identity.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    3. Given $a,b,c$, we have $a\times (b\times c)=(a\times b)\times c$.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    4. Given $a$, $b$ and $c$, $a\times (b+c)=a\times b+a\times c$ and $(b+c)\times a=b\times a+c\times a$. This is the distributive property.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    5. If $a$ and $b\neq 0$ are integers, their division $a&#x2F;b$ is not necessarily an integer. For example, $a=3$ and $b=2$ results in $c=3&#x2F;2$, which is a rational (not integer) number. In other words, the operation is not closed.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;&lt;h2 id=&quot;rings-and-fields&quot;&gt;Rings and fields&lt;&#x2F;h2&gt;
&lt;p&gt;The set $\mathbb{Z}$ together with addition and multiplication forms a ring. The polynomials with ordinary addition and multiplication also form a ring. $n\times n$ matrices also form a ring under addition and multiplication. Formally, a ring is a set $R$ with two operations $+$ and $\times$ such that:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    1. R is an abelian group under $+$ (that is, R fulfills all the conditions for a group G1 to G4, plus commutativity, G5).&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    2. There is a multiplicative identity $e$, such that $a\times e=e\times a=a$. Frequently, we use $e=1$.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    3. Multiplication is associative.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    4. We have the distributive property of multiplication concerning addition.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;em&gt;Exercise: Check that the $n\times n$ matrices form a ring with ordinary matrix addition and multiplication.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;If we look at the rational numbers, for any non-zero element, we have a multiplicative inverse. For example, $1&#x2F;5$ is the multiplicative inverse of $5$, since $5\times 1&#x2F;5=1$. The division is now a closed operation. Besides, multiplication is also commutative. $\mathbb{Q}$ with the ordinary addition and multiplication is a field. Other examples of fields are $\mathbb{R}$ and $\mathbb{C}$. When the number of elements in the set is finite (such as $4$, $2^{255}-19$, etc), the field is known as a finite field. These will be very important for cryptography.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;some-concepts-from-number-theory&quot;&gt;Some concepts from number theory&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;divisibility&quot;&gt;Divisibility&lt;&#x2F;h3&gt;
&lt;p&gt;We will start by talking about divisibility. Given two natural numbers, $a$ and $b$, we say that $a$ divides $b$ (and write it $a\mid b$) if there is another number $c$ such that $a\times c=b$. $a$ is called a divisor of $b$. If $a$ does not divide $b$, we write $a\nmid b$ and we can write $b=q\times a+r$, where $r&amp;lt;a$, with $q$ the quotient and $r$ the remainder of the division. If $a$ divides $b\times c$, then $a\mid b$ or $a\mid c$. Another fact is that if $a\mid b$ and $a\mid c$, then $a\mid (x\times b+y\times c)$ for any numbers $x,y$.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;prime-numbers&quot;&gt;Prime Numbers&lt;&#x2F;h3&gt;
&lt;p&gt;A number $p&amp;gt;1$ is called prime if its only divisors are $1$ and itself. Otherwise, the number is composite. Examples of prime numbers are $2,3,5,7,11,13,17,19,23,29,31,…$. The &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fundamental_theorem_of_arithmetic&quot;&gt;fundamental theorem of arithmetic&lt;&#x2F;a&gt; tells us that any number can be expressed in a unique way (up to ordering) as a product of powers of prime numbers. For example, $20=2^2\times 5$, $186=2\times 3\times 31$, $5=5$, etc. Finding prime numbers is crucial for cryptography. One easy way (but by no means practical for large numbers) to see whether a number $p$ is prime or not consists in checking whether it is divisible by all primer numbers smaller than $p$. The problem is that, if $p$ is very large, this can be pretty inefficient. There are some better and faster algorithms, but we will cover them some other time.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Exercise: Find all prime numbers that are smaller than 100.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;greatest-common-divisor-and-euclid-s-algorithm&quot;&gt;Greatest common divisor and Euclid’s algorithm&lt;&#x2F;h3&gt;
&lt;p&gt;An important concept is that of the greatest common divisor: given two numbers $a$ and $b$ we want to find the largest number $c$ such that $c\mid a$ and $c\mid b$. We denote this by $c=gcd(a,b)$ or simply $c=(a,b)$. For example, $20=2^2\times 5$ and $50=2\times 5^2$. Both numbers are divisible by $1,2,5,10$. $10$ is the greatest number dividing both and so $gcd(20,50)=10$. Two numbers $a,b$ are called relatively prime (or coprime) if $gcd(a,b)=1$. If $a$ and $b$ are both prime (and different), $1$ is the only common divisor. However, $8$ and $9$ are not prime themselves ($8=2^3$ and $9=3^2$), but their only common divisor is $1$ and are coprime.&lt;&#x2F;p&gt;
&lt;p&gt;The greatest common divisor satisfies the following equation, for some $x$ and $y$:&lt;br &#x2F;&gt;
$x\times a+y\times b=gcd(a,b)$&lt;br &#x2F;&gt;
The greatest common divisor can be found very efficiently using the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Euclidean_algorithm&quot;&gt;Euclidean algorithm&lt;&#x2F;a&gt; and the numbers $x$ and $y$ can also be found with little extra cost using the extended Euclidean algorithm.&lt;&#x2F;p&gt;
&lt;p&gt;To understand the algorithm, let’s look at an example: say we want to calculate the gcd(2502,864). The algorithm takes advantage that the remainder is always less than the divisor, so we can “chop down” the larger number; this chopping does not affect the largest common divisor.&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    1. Let&amp;#39;s find the remainder of $2502&#x2F;864$, $r_0=774$.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    2. Let&amp;#39;s find the remainder of $864&#x2F;774$, $r_1=90$.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    3. The remainder of $774&#x2F;90$ is $r_2=54$.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    4. $r_3=36$&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    5. $r_4=18$&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    6. $r_5=0$, since $36$ is divisible by $18$. So, the greatest common divisor is $18$.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We can see, from the factorization of $864=2^5\times 3^3$ and $2502=2\times 3^2\times 139$, that the $gcd$ is equal to $2\times 3^2=18$. The advantage is that we found it in a few steps (6) and we didn’t have to know the factorization (which, for large numbers can be really hard to find. As a matter of fact, that is the key to the RSA cryptosystem).&lt;&#x2F;p&gt;
&lt;h3 id=&quot;congruences-and-modular-arithmetic&quot;&gt;Congruences and modular arithmetic&lt;&#x2F;h3&gt;
&lt;p&gt;One problem we face with computers is that the numbers we can work with are limited. Besides, in some cases, we are not interested in a number itself, but rather in its belonging to a certain class or group. For example, when we bet on a roulette, we can choose whether the result will be even or odd. If it is even, then $r=2\times k$, for some $k \in {0,1,2,3…18}$. If it is odd, then $r=2\times k+1$. We notice that if we want to check parity, we only need to look at the remainder, which can take two values in this case: $0$ or $1$. In fact, when we want to check whether a number is even in the computer, we look at the leftmost bit and check whether it is zero or not. For the case of $2$, we see that any number $a$ satisfies either:&lt;br &#x2F;&gt;
$a\equiv 0 \pmod{2}$&lt;br &#x2F;&gt;
$a\equiv 1 \pmod{2}$&lt;br &#x2F;&gt;
We say that $a$ is congruent to $0$ (or $1$) modulo $2$. This way, we split all the numbers into two categories: even and odd. We can do the same for any number $p&amp;gt;1$, remembering that the remainder is $0 \leq r \leq p-1$. This can also be seen as $a\equiv r \pmod{p}$ as $p\mid a-r$ or $a=k\times p+r$. This notation was invented by Gauss and is really powerful to study a lot of complex problems. We can perform usual operations such as addition and multiplication, but we have to be careful of how things work, given that results will always have to be in the range $0 \leq r \leq p-1$ (As a side note, you could choose a different range, such as ${-2,-1,0,1,2,p-3}$, but it can be confusing and we should better stick to our first choice).&lt;&#x2F;p&gt;
&lt;p&gt;In the case of the sum, we can add them just as regular numbers and, if the result exceeds $p$, take the remainder. For example, let’s take $p=7$, so the elements we have are ${0,1,2,3,4,5,6}$. First, we see that $0$ is an element of the set and that adding it to any number does not change the result. If we add $2$ and $3$ the result is $5$. If we add $5$ and $4$, we get $9$, but&lt;br &#x2F;&gt;
$4+5=9\equiv 2 \pmod{7}$&lt;br &#x2F;&gt;
$2$ is just the remainder of the division of $9$ by $7$. We see that the result stays in the original set. What happens when we add $4$ and $3$?&lt;br &#x2F;&gt;
$4+3=7\equiv 0 \pmod{7}$&lt;br &#x2F;&gt;
We get $0$! That is because $7$ is divisible by itself and the remainder is $0$. We see that $4$ is the additive inverse of $3$ under this arithmetic. Similarly, $1$ and $6$ are each other’s inverse, $2$ and $5$. We can recognize that the set ${0,1,2,3,4,5,6}$ with the sum done modulo $7$ is an abelian group. Subtraction can be easily defined as adding the inverse of the number or just performing ordinary subtraction and then taking the result modulo $p$.&lt;&#x2F;p&gt;
&lt;p&gt;With multiplication we get something similar. For example,&lt;br &#x2F;&gt;
$4\times 5=20\equiv 6 \pmod{7}$.&lt;br &#x2F;&gt;
Taking the modulo operation ensures that we always stay inside the set. We also see that $1$ works as the multiplicative identity since any number multiplied by $1$ stays the same. Let’s look at what happens with $6\times 6$:&lt;br &#x2F;&gt;
$6\times 6=36\equiv 1 \pmod{7}$.&lt;br &#x2F;&gt;
We multiplied $6$ by itself and got $1$! We talked before that division $a&#x2F;b$ could be restated as $a\times b^{-1}$, where $b\times b^{-1} = 1 = b^{-1} \times b$. We see that $6$ is its own multiplicative inverse with the multiplication modulo $p$. We can also see that:&lt;br &#x2F;&gt;
$3\times 5 = 15\equiv 1 \pmod{7}$&lt;br &#x2F;&gt;
$2\times 4 = 8\equiv 1 \pmod{7}$&lt;br &#x2F;&gt;
So, $3 = 5^{-1}$ and $2 = 4^{-1}$! This can sound weird, but we have to remember that we are working with congruence. We can understand the precise meaning of this by rephrasing. Let’s take the case of $6$ and $6$. There are two numbers $a = q_1\times 7+6$ and $b = q_2\times 7+6$ (because that is what the congruence means). Let’s take the product $a\times b$:&lt;br &#x2F;&gt;
$a\times b = (q_1\times 7+6)\times (q_2\times 7+6)$&lt;br &#x2F;&gt;
Let’s apply the distributive law:&lt;br &#x2F;&gt;
$a\times b = q_1\times q_2 \times 7^2+6\times 7\times (q_1+q_2)+36$&lt;br &#x2F;&gt;
Let’s split this further $36=1+35=1+7\times 5$ and regroup, taking as a common factor $7$:&lt;br &#x2F;&gt;
$a\times b = 7\times (q_1\times q_2\times 7+6\times(q_1+q_2)+5)+1$&lt;br &#x2F;&gt;
The first term is divisible by $7$, so it is congruent to $0$. Or, if we subtract $1$ to $a\times b$, we see that it is divisible by $7$ (since it is the product of $7$ and an integer).&lt;&#x2F;p&gt;
&lt;p&gt;We can see that, if $p$ is prime, then the set ${0,1,2,…p-1}$ with addition and multiplication modulo $p$ is a finite field.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Exercise: Prove that this is indeed a finite field.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;mathbb-z-n-mathbb-z-as-a-group-cyclic-groups&quot;&gt;$\mathbb{Z}&#x2F;n\mathbb{Z}$ as a group. Cyclic groups.&lt;&#x2F;h3&gt;
&lt;p&gt;You will frequently see these sets are denoted as $\mathbb{Z}&#x2F;p\mathbb{Z}$. We have to be very careful if we want to work with $n$ not prime in $\mathbb{Z}&#x2F;n\mathbb{Z}$ (in this case, it is not a finite field either). For example, let’s try to solve this equation:&lt;br &#x2F;&gt;
$(x+2)\times(x+1)\equiv 0 \pmod{12}$&lt;br &#x2F;&gt;
We could use our knowledge of math and, when the product of two numbers is $0$, at least one of them is $0$ (spoiler’s alert: this will go wrong):&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    1. $(x+2)\equiv 0 \pmod{12}$. If $x=10$, then $x+2=12\equiv 0$, since it is divisible by 12.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    2. $(x+1)\equiv 0 \pmod{12}$. If $x=11$, then $x+1=12\equiv 0$, since it is divisible by 12.  &lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Let’s pick now $2$ and see what happens:&lt;br &#x2F;&gt;
$(2+2)\times(2+1)=12\equiv 0 \pmod{12}$.&lt;br &#x2F;&gt;
So $2$ is a solution to the equation, but $2+2\equiv 4\not\equiv 0$ and $2+1\equiv 3\not\equiv 0$. This happens because $12$ is not a prime number.&lt;&#x2F;p&gt;
&lt;p&gt;As a matter of fact, given $a$ and $n$, we have that $a$ has an inverse (modulo $n$) if and only if $gcd(a,n)=1$, that is, $a$ and $n$ are coprime. In the previous example, $3$ is not coprime to $12$ (they have $3$ as a common divisor).&lt;&#x2F;p&gt;
&lt;p&gt;If the set is not too large, we can find inverses just by trial and error. However, it would be nice to have some results that help us compute inverses and how to calculate (integer) powers of numbers.&lt;&#x2F;p&gt;
&lt;p&gt;Let’s focus on a prime number $p$ and take all the non-zero elements of the set, $(\mathbb{Z}&#x2F;p\mathbb{Z})^\star$. Let’s fix $p=7$, so $(\mathbb{Z}&#x2F;p\mathbb{Z})^\star = {1,2,3,4,5,6}$ and let’s focus on multiplication over the set. We can define the power $a^n=a\times a\times a\times …\times a$. Obviously, $1$ is not interesting, because $1^n=1$, so let’s take $5$:&lt;br &#x2F;&gt;
$5^1\equiv 5 \pmod{7}$&lt;br &#x2F;&gt;
$5^2\equiv 4 \pmod{7}$&lt;br &#x2F;&gt;
$5^3\equiv 6 \pmod{7}$&lt;br &#x2F;&gt;
$5^4\equiv 2 \pmod{7}$&lt;br &#x2F;&gt;
$5^5\equiv 3 \pmod{7}$&lt;br &#x2F;&gt;
$5^6\equiv 1 \pmod{7}$&lt;br &#x2F;&gt;
$5^7\equiv 5 \pmod{7}$&lt;br &#x2F;&gt;
$5^8\equiv 4 \pmod{7}$&lt;br &#x2F;&gt;
$5^{13}\equiv 5 \pmod{7}$&lt;br &#x2F;&gt;
We see that the powers of $5$ span all the elements of the group. We also see that numbers repeat themselves at an interval of $6$, that is $4 = 5^2 = 5^8 = 5^{14}…$. Let’s look at $3$:&lt;br &#x2F;&gt;
$3^1\equiv 3 \pmod{7}$&lt;br &#x2F;&gt;
$3^2\equiv 2 \pmod{7}$&lt;br &#x2F;&gt;
$3^3\equiv 6 \pmod{7}$&lt;br &#x2F;&gt;
$3^4\equiv 4 \pmod{7}$&lt;br &#x2F;&gt;
$3^5\equiv 5 \pmod{7}$&lt;br &#x2F;&gt;
$3^6\equiv 1 \pmod{7}$&lt;br &#x2F;&gt;
$3^7\equiv 3 \pmod{7}$&lt;br &#x2F;&gt;
We got all the elements (albeit in a different order). Finally, let’s look at $2$:&lt;br &#x2F;&gt;
$2^1\equiv 2 \pmod{7}$&lt;br &#x2F;&gt;
$2^2\equiv 4 \pmod{7}$&lt;br &#x2F;&gt;
$2^3\equiv 1 \pmod{7}$&lt;br &#x2F;&gt;
$2^4\equiv 2 \pmod{7}$&lt;br &#x2F;&gt;
This time we didn’t span all the elements of the group and we got to the same number after $3$. We will show that these results are valid in general (provided we’re working modulo a prime number).&lt;&#x2F;p&gt;
&lt;p&gt;First, we can prove that the set $(\mathbb{Z}&#x2F; p\mathbb{Z})^\star$ together with multiplication forms an abelian group (the product can never give 0 since all the numbers are not divisible by $p$). Second, the group is finite, since the number of elements is finite (6 in our example); its order is $6$. We also saw that by repeatedly multiplying $5$ by itself (that is, taking powers of $5$), we can generate all the elements of the group (note that everything repeats after $6$, which is the order of the group). Since the group can be generated by one of its elements, it is a (finite) cyclic group.&lt;&#x2F;p&gt;
&lt;p&gt;For an element $a$, the lowest positive integer $n$ such that $a^n\equiv 1 \pmod{p}$ is known as the order of $a$. The elements of the group with their respective order in parentheses are: $1 (1)$, $2 (3)$, $3 (6)$, $4 (2)$, $5(6)$, $6(2)$. We can see that the orders of each element divide the order of the group, $6$. We will present the following theorems, which show that this is not a coincidence.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;three-useful-theorems-and-the-magic-behind-rsa&quot;&gt;Three useful theorems and the magic behind RSA&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fermat%27s_little_theorem&quot;&gt;Fermat’s Little Theorem&lt;&#x2F;a&gt;: If $p$ is prime, then, for any integer $a$ we have that $a^p-a$ is divisible by $p$:&lt;br &#x2F;&gt;
$a^p\equiv a \pmod{p}$.&lt;br &#x2F;&gt;
&lt;em&gt;Exercise: Check that this is indeed valid for all elements of $(\mathbb{Z}&#x2F;7\mathbb{Z})^\star$&lt;&#x2F;em&gt;&lt;br &#x2F;&gt;
If $a$ is coprime to $p$, we can write this equivalently:&lt;br &#x2F;&gt;
$a^{p-1}\equiv 1 \pmod{p}$&lt;br &#x2F;&gt;
An interesting consequence is that we can calculate inverses by doing $a^{-1} = a^{p-2}$, even though in some cases we are overestimating the power (for example, $6\times 6\equiv 1 \pmod{7}$).&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Euler%27s_theorem&quot;&gt;Euler’s theorem&lt;&#x2F;a&gt;: If $a$ and $n$ are positive coprime integers, then $a^{\phi(n)}\equiv 1 \pmod{n}$, where $\phi(n)$ is &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Euler%27s_totient_function&quot;&gt;Euler’s phi (or totient) function&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Euler’s $\phi(n)$ function counts the numbers $m &amp;lt; n$ that are coprime to $n$. For example, if we take $n = 5$, the numbers $1,2,3,4$ are all coprime to $5$ and $\phi(5) = 4$ (this is reasonable, since $5$ is prime). If we take $8$, we have ${ 1 , 2 , 3 , 4 , 5 , 6 , 7}$; however, only $1,3,5,7$ are coprime to $8$, so $\phi(8)=4$. For prime numbers, we have&lt;br &#x2F;&gt;
$\phi(p)=p-1$&lt;br &#x2F;&gt;
so, Euler’s theorem gives us Fermat’s theorem as a particular case. Another useful property is that if $m$ and $n$ are relatively prime, then&lt;br &#x2F;&gt;
$\phi(m\times n)=\phi(n)\times \phi(m)$&lt;br &#x2F;&gt;
This shows that $\phi$ is a &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Multiplicative_function&quot;&gt;multiplicative function&lt;&#x2F;a&gt;. In particular, if $n$ is the product of two primes, $p$ and $q$, then&lt;br &#x2F;&gt;
$\phi(n) = (p-1)\times (q-1)$&lt;br &#x2F;&gt;
RSA’s working principle is here. The public key $e$ and private $d$ are multiplicative inverses, modulo $\phi(n)$,&lt;br &#x2F;&gt;
$d\times e \equiv 1 \pmod{\phi(n)}$&lt;br &#x2F;&gt;
This means that $d\times e = 1+k\phi(n)$ for some integer $k$, so when we compute&lt;br &#x2F;&gt;
$M^{ e \times d } = M^{ 1 + k \phi(n) } = M \times M^{ k \phi(n) } \equiv M \pmod{n}$&lt;br &#x2F;&gt;
since $M^{k \phi(n) } = {(M^{ \phi(n) })}^k \equiv 1^k \pmod{n}$. RSA is only as hard as it is factoring the number $n$ and over the years the length of the keys has increased significantly (it is around 2000 to 4000 bits); elliptic curves, on the other hand, give the same level of security for shorter keys.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;subgroups-lagrange-s-theorem&quot;&gt;Subgroups. Lagrange’s theorem&lt;&#x2F;h3&gt;
&lt;p&gt;We saw that the order of $(\mathbb{Z}&#x2F;7\mathbb{Z})^\star$ was 6 and that if we take any element $a$, doing $a^6\equiv 1 \pmod{7}$. However, for $2$ we can do $2^3\equiv 1 \pmod{7}$. A subgroup $H$ is a subset of $G$, that is itself a group, that is, satisfies G1-G4. For example, if we consider the subset $H={1}$, this is a subgroup of order $1$. Why? Because $1\times 1=1$, so the operation is closed and all other properties follow from the operations of the group $G$. $G$ is also a subgroup of itself. These two are called the trivial subgroups of $G$ (which are not very interesting). The set ${1,2,4}$ is a subgroup of $(\mathbb{Z}&#x2F;7\mathbb{Z})^\star$. To check this, we need to see that if an element is in the set, so is its inverse, the identity belongs to the set and the operation is closed. Let’s check this:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    * $1$ is in the set and $1$ is its own inverse.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;    * The operation is closed, because $2\times 2\equiv 4 \pmod{7}$, because $4\times 4=16\equiv 2 \pmod{7}$ and because $2\times 4=8\equiv 1 \pmod{7}$ (we don&amp;#39;t need to check the products with $1$ since that is obvious). We also checked the inverses, since $4=2^{-1}$.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The subset ${1,2,4}$ forms a subgroup of order $3$. &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Lagrange%27s_theorem_(group_theory)&quot;&gt;Lagrange’s theorem&lt;&#x2F;a&gt; states that the order of a subgroup divides the order of the group. We have another subgroup ${1,6}$, which is of order $2$. These are non-trivial subgroups. If the order of a group is prime, then its only subgroups are the trivial subgroups (since $p$ is prime, the subgroups can only be of order $1$ and $p$). A group whose only subgroups are the trivial ones is known as a simple group. For example, $\mathbb{Z}&#x2F;7\mathbb{Z}$ with addition is the group ${0,1,2,3,4,5,6}$ of order $7$. There are no subgroups other than the whole group and ${0}$. Note that the order of each element (other than zero, which has order $1$) is $7$, since $7\times a=a+a+a+a+a+a+a$ is divisible by $7$ and, therefore, congruent to $0$ modulo $7$. The fact that some groups can be broken down into smaller subgroups is of concern when working with elliptic curves: if the group is not of prime order, it can be broken down into smaller groups and an attacker may break the system by performing searches on these subgroups.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;the-discrete-logarithm-problem&quot;&gt;The discrete logarithm problem&lt;&#x2F;h3&gt;
&lt;p&gt;Given a group, we can apply the operation repeatedly on a point $g$ to get to a point $P$, that is $g^k=g\times g\times g\times … \times g=P$. For example, in $(\mathbb{Z}&#x2F;7\mathbb{Z})^\star$, $5$ generates all the elements by successive multiplications with itself. We could then ask how many times $x$ should we multiply $5$ with itself to get to $3$, that is, $5^x\equiv 3 \pmod{7}$. Since we know that the order of the group is $6$, we should only concern ourselves with numbers $0-6$. If we look above or try all combinations, $5^5\equiv 3 \pmod{7}$ so $x=5$. Similarly, if we look for $y$ such that $5^y\equiv 4 \pmod{7}$, we get $y=2$. The problem of finding $x$ so that $g^k=P$ is known as the discrete logarithm problem (in number theory, $x$ and $y$ are known as indices). We quickly see that this logarithm works quite differently from the common logarithm on the real numbers (though the idea is the same, given $y$, find $x$ such that $e^x=y$). There is no obvious pattern, it is not increasing and if we had to search over a large set, it could be really daunting. Many cryptographic systems rely on the hardness of this problem over a finite cyclic group.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;&#x2F;h2&gt;
&lt;p&gt;We presented some basic terms and concepts from number theory and algebra that will be useful when reading cryptography, since many key concepts and strategies rely on math. The notions of groups, rings and fields and prime numbers show up almost all the time. Soon we will continue with other important tools and concepts that will help us understand how elliptic curve cryptography works, how to perform faster operations over groups and how to combine elliptic curves to build zk-SNARKs.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>What every developer needs to know about elliptic curves</title>
          <pubDate>Sat, 06 Aug 2022 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://blog.lambdaclass.com/posts/what-every-developer-needs-to-know-about-elliptic-curves/</link>
          <guid>https://blog.lambdaclass.com/posts/what-every-developer-needs-to-know-about-elliptic-curves/</guid>
          <description xml:base="https://blog.lambdaclass.com/posts/what-every-developer-needs-to-know-about-elliptic-curves/">&lt;p&gt;Elliptic curves (EC) have become one of the most useful tools for modern cryptography. They were proposed in the 1980s and became widespread used after 2004. Its main advantage is that it offers smaller key sizes to attain the same level of security of other methods, resulting in smaller storage and transmission requirements. For example, EC cryptography (ECC) needs 256-bit keys to attain the same level of security as a 3000-bit key using RSA (another public-key cryptographic system, born in the late 70s). ECC and RSA work by hiding things inside a certain mathematical structure known as a finite cyclic group (we will explain this soon). The hiding is done rather in plain sight: you could break the system if you could reverse the math trick (spoiler alert: if done properly, it would take you several lifetimes). It is as if you put $1.000.000 inside an unbreakable glass box and anyone could take it if they could break it.&lt;&#x2F;p&gt;
&lt;p&gt;In order to understand these objects and why they work, we need to go backstage and look at the math principles (we won’t enter into the hard details or proofs, but rather focus on the concepts or ideas). We will start by explaining finite fields and groups and then jump onto the elliptic curves (over finite fields) and see whether all curves were created equal for crypto purposes.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;finite-fields&quot;&gt;Finite fields&lt;&#x2F;h2&gt;
&lt;p&gt;We know examples of fields from elementary math. The rational, real and complex numbers with the usual notions of sum and multiplication are examples of fields (these are not finite though).&lt;&#x2F;p&gt;
&lt;p&gt;A finite field is a set equipped with two operations, which we will call + and ×. These operations need to have certain properties in order for this to be a field:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;If &lt;em&gt;a&lt;&#x2F;em&gt; and &lt;em&gt;b&lt;&#x2F;em&gt; are in the set, then &lt;em&gt;c=a+b&lt;&#x2F;em&gt; and &lt;em&gt;d=a×b&lt;&#x2F;em&gt; should also be in the set. This is what is mathematically called a closed set under the operations +, ×.&lt;&#x2F;li&gt;
&lt;li&gt;There is a zero element, 0, such that &lt;em&gt;a&lt;&#x2F;em&gt; +0=&lt;em&gt;a&lt;&#x2F;em&gt; for any a in the set. This element is called the additive identity.&lt;&#x2F;li&gt;
&lt;li&gt;There is an element, 1, such that 1× &lt;em&gt;a&lt;&#x2F;em&gt; =&lt;em&gt;a&lt;&#x2F;em&gt; for any a in the set. This element is the multiplicative identity.&lt;&#x2F;li&gt;
&lt;li&gt;If a is in the set, there is an element &lt;em&gt;b&lt;&#x2F;em&gt; , such that &lt;em&gt;a+b&lt;&#x2F;em&gt; =0. We call this element the additive inverse and we usually write it as &lt;em&gt;−a&lt;&#x2F;em&gt;.&lt;&#x2F;li&gt;
&lt;li&gt;If &lt;em&gt;a&lt;&#x2F;em&gt; is in the set, there is an element &lt;em&gt;c&lt;&#x2F;em&gt; such that &lt;em&gt;a×c=1&lt;&#x2F;em&gt;. This element is called the multiplicative inverse and we write is as &lt;em&gt;a&lt;&#x2F;em&gt; −1.&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;Before we can talk about examples of finite fields, we need to introduce the modulo arithmetic.&lt;&#x2F;p&gt;
&lt;p&gt;We learned that given a natural number or zero, &lt;em&gt;a&lt;&#x2F;em&gt; and a non-zero number &lt;em&gt;b&lt;&#x2F;em&gt; , we could write out a in the following way &lt;em&gt;a=q×b+r&lt;&#x2F;em&gt; where &lt;em&gt;q&lt;&#x2F;em&gt; is the quotient and &lt;em&gt;r&lt;&#x2F;em&gt; is the remainder of the division of &lt;em&gt;a&#x2F;b&lt;&#x2F;em&gt;. This &lt;em&gt;r&lt;&#x2F;em&gt; can take values 0,1,2,…,b−1 We know that if &lt;em&gt;r&lt;&#x2F;em&gt; is zero, then a is a multiple of &lt;em&gt;b&lt;&#x2F;em&gt;. It may not seem new, but this gives us a very useful tool to work with numbers. For example, if &lt;em&gt;b&lt;&#x2F;em&gt; =2 then &lt;em&gt;r&lt;&#x2F;em&gt; =0,1. When it is 0, &lt;em&gt;a&lt;&#x2F;em&gt; is even (it is divisible by 2) and when it is 1, &lt;em&gt;a&lt;&#x2F;em&gt; is odd. A simple way to rephrase this (due to Gauss):&lt;&#x2F;p&gt;
&lt;p&gt;a≡1(mod2)&lt;&#x2F;p&gt;
&lt;p&gt;if &lt;em&gt;a&lt;&#x2F;em&gt; is odd and&lt;&#x2F;p&gt;
&lt;p&gt;a≡0(mod2)&lt;&#x2F;p&gt;
&lt;p&gt;if &lt;em&gt;a&lt;&#x2F;em&gt; is even. We can see that if we sum two odd numbers &lt;em&gt;a1&lt;&#x2F;em&gt; and &lt;em&gt;a2&lt;&#x2F;em&gt; ,&lt;&#x2F;p&gt;
&lt;p&gt;a1+a2≡1+1≡0(mod2)&lt;&#x2F;p&gt;
&lt;p&gt;This shows us that, if we want to know whether a sum is even or not, we can simply sum the remainders of their division by 2 (an application of this is that in order to check divisibility by two, we should only look at the last bit of the binary representation).&lt;&#x2F;p&gt;
&lt;p&gt;Another situation where this arises every day is with time. If we are on Monday at 10 am and we have 36 hours till the deadline of a project, we have to submit everything by Tuesday 10 pm. That is because 12 fits exactly 3 times in 36, leading to Mon-10 pm, Tue-10 am, Tue-10 pm. If we had 39 hours, we jump to Wed-1 am.&lt;&#x2F;p&gt;
&lt;p&gt;An easy way to look at this relation (formally known as congruence modulo p) is that if &lt;em&gt;a≡b&lt;&#x2F;em&gt;(mod &lt;em&gt;p&lt;&#x2F;em&gt;), then &lt;em&gt;p&lt;&#x2F;em&gt; divides &lt;em&gt;a−b&lt;&#x2F;em&gt; , or &lt;em&gt;a=k×p+b&lt;&#x2F;em&gt; for an integer &lt;em&gt;k&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;More informally, we see that operating (mod &lt;em&gt;p&lt;&#x2F;em&gt;) wraps around the results of certain calculations, giving always numbers in a bounded range by &lt;em&gt;p&lt;&#x2F;em&gt; −1.&lt;&#x2F;p&gt;
&lt;p&gt;We can see that if a1≡b1(modp) and a2≡b2(modp), then a1+a2≡b1+b2(mod &lt;em&gt;p&lt;&#x2F;em&gt;) (if b1+b2&amp;gt;p we can wrap around the result). Similar results apply when using subtraction and multiplication. Division presents some difficulties, but we can change things a little bit and make it work this way: instead of thinking of dividing &lt;em&gt;a÷b&lt;&#x2F;em&gt; we can calculate &lt;em&gt;a×b−1&lt;&#x2F;em&gt; , where &lt;em&gt;b&lt;&#x2F;em&gt; −1 is the multiplicative inverse of &lt;em&gt;b&lt;&#x2F;em&gt; (remember &lt;em&gt;b×b −1&lt;&#x2F;em&gt;=1). Consider &lt;em&gt;p&lt;&#x2F;em&gt; =5, so the elements of the group are 0,1,2,3,4.&lt;&#x2F;p&gt;
&lt;p&gt;We can see that 1 is its own multiplicative inverse, since 1×1=1≡1  (mod5). If we take 2 and 3, then 2×3=6≡1  (mod5) (so 3 is the multiplicative inverse of 2) and 4×4=16≡1 (mod5). The set and the operations defined satisfy the conditions for a field.&lt;&#x2F;p&gt;
&lt;p&gt;We can also define integer powers of field elements in a simple way. If we want to square a number &lt;em&gt;a&lt;&#x2F;em&gt; , it is just doing &lt;em&gt;a×a&lt;&#x2F;em&gt; and take mod &lt;em&gt;p&lt;&#x2F;em&gt;. If we want a cube, we do &lt;em&gt;a×a×a&lt;&#x2F;em&gt; and take mod &lt;em&gt;p&lt;&#x2F;em&gt;. RSA uses exponentiation to perform encryption. It is easy to see that if the exponent is rather large (or the base is very large, or both), numbers get really big. For example, we want to evalute 265536(mod &lt;em&gt;p&lt;&#x2F;em&gt;). When we reach a 1000, we get numbers with over 300 digits and we are still a long way to go. We can do this calculation much simpler realizing that 65536=216 and squaring the number and taking the remainder every time. We end up doing only 16 operations like this, instead of the original 65536! thus avoiding huge numbers. A similar strategy will be used when we work with ECs!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;groups&quot;&gt;Groups&lt;&#x2F;h2&gt;
&lt;p&gt;We saw that whenever we add two even integers, we get another one. Besides, as 0 is even and if we sum &lt;em&gt;a&lt;&#x2F;em&gt; and &lt;em&gt;−a&lt;&#x2F;em&gt; we get 0, which is the identity element for the sum. Many different objects have a similar behavior when equipped with a certain operation. For example, the multiplication of two invertible matrices results in an invertible matrix. If we consider the set of invertible matrices of &lt;em&gt;N&lt;&#x2F;em&gt; × &lt;em&gt;N&lt;&#x2F;em&gt; equipped with the multiplication, we can see that if &lt;em&gt;A&lt;&#x2F;em&gt; is in the set, &lt;em&gt;A −1&lt;&#x2F;em&gt; is in the set; the identity matrix is in the set (and it plays the role of identity element with respect to multiplication). In other words, some sets equipped with a certain operation share some properties and we can take advantage of the knowledge of this structure. The set, together with the operation, forms a group. Formally, a group is a set &lt;em&gt;G&lt;&#x2F;em&gt; equipped with a binary operation × such that:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 1. The operation is associative, that is, _(a×b)×c=a×(b×c)_.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 2. There is an identity element, _e: e×a=a_ and _a×e=a_. &lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 3. For every element _a_ in the set, there is an element _b_ in the set such that _a×b=e_ and _b×a=e_. We denote _b=a−1_ for simplicity.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We can easily see that any field is, in particular, a group with respect to each one of its two operations (conditions 1, 2 and 4 for the field indicate it is also a group with respect to the sum and 1, 3 and 5 for multiplication). If the operation is commutative (that is, &lt;em&gt;a×b=b×a&lt;&#x2F;em&gt;) the group is known as an abelian (or commutative) group. For example, the invertible matrices of &lt;em&gt;N×N&lt;&#x2F;em&gt; form a group, but it is not abelian, since &lt;em&gt;A×B≠B×A&lt;&#x2F;em&gt; for some matrices &lt;em&gt;A&lt;&#x2F;em&gt; and &lt;em&gt;B&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;We will be interested in finite groups (those where the set contains a finite number of elements) and, in particular, cyclic groups. These are groups which can be generated by repeatedly applying the operation over an element &lt;em&gt;g&lt;&#x2F;em&gt; , the generator of the group. The &lt;em&gt;n&lt;&#x2F;em&gt; -th roots of unity in the complex numbers form an example of a cyclic group under multiplication; this is the set of solutions of &lt;em&gt;x n&lt;&#x2F;em&gt;=1, which are of the form exp(2 &lt;em&gt;πik&#x2F;n&lt;&#x2F;em&gt;), with &lt;em&gt;k&lt;&#x2F;em&gt; =0,1,2…,&lt;em&gt;n&lt;&#x2F;em&gt; −1. This group can be generated by taking integer powers of exp(2 &lt;em&gt;πi&#x2F;n&lt;&#x2F;em&gt;). The roots of unity play an important role in the calculation of the fast Fourier transform (FFT), which has many applications.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;elliptic-curves-in-a-nutshell&quot;&gt;Elliptic curves in a nutshell&lt;&#x2F;h2&gt;
&lt;p&gt;Elliptic curves are very useful objects because they allow us to obtain a group structure with interesting properties. Given a field &lt;em&gt;F&lt;&#x2F;em&gt; , an elliptic curve is the set of points &lt;em&gt;(x,y)&lt;&#x2F;em&gt; which satisfy the following equation:&lt;&#x2F;p&gt;
&lt;p&gt;_y 2+a1xy+a3y=x3+a2x2+a4x+a6 _&lt;&#x2F;p&gt;
&lt;p&gt;This is known as the general Weierstrass equation. In many cases, this can be written in the simpler form&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;y 2=x3+ax+b&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;which is the (Weierstrass) short-form. Depending on the choice of the parameters a and b and the field, the curve can have some desired properties or not. If _4a 3+27b2≠0 _, the curve is non-singular.&lt;&#x2F;p&gt;
&lt;p&gt;We can define an operation which allows us to sum elements belonging to the elliptic curve and obtain a group. This is done using a geometric construction, the chord-and-tangent rule. Given two points on the curve &lt;em&gt;P1=(x 1,y1)&lt;&#x2F;em&gt; and &lt;em&gt;P 2=(x2,y2)&lt;&#x2F;em&gt;, we can draw a line connecting them. That line intersects the curve on a third point &lt;em&gt;P 3=(x3,y3)&lt;&#x2F;em&gt;. We set the sum of &lt;em&gt;P 1&lt;&#x2F;em&gt; and &lt;em&gt;P 2&lt;&#x2F;em&gt; as &lt;em&gt;(x 3,−y3)&lt;&#x2F;em&gt;, that is, point &lt;em&gt;P 3&lt;&#x2F;em&gt; flipped around the &lt;em&gt;x&lt;&#x2F;em&gt; -axis. The formulae are:  &lt;img src=&quot;&#x2F;images&#x2F;2022&#x2F;12&#x2F;imagen-1.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;We can easily see that we have a problem if we try to sum &lt;em&gt;P 1=(x1,y1)&lt;&#x2F;em&gt; and &lt;em&gt;P 2=(x1,−y1)&lt;&#x2F;em&gt;. We need to add an additional point to the system, which we call the point at infinity &lt;em&gt;O&lt;&#x2F;em&gt;. This inclusion is necessary to be able to define the group structure and works as the identity element for the group operation.&lt;&#x2F;p&gt;
&lt;p&gt;Another problem appears when we want to sum &lt;em&gt;P 1&lt;&#x2F;em&gt; and &lt;em&gt;P 1&lt;&#x2F;em&gt; to get to &lt;em&gt;P 3=2P1&lt;&#x2F;em&gt;. But, if we draw the tangent line to the curve on P1, we see that it intersects the curve at another point. If we want to perform this operation, we need to find the slope of the tangent line and find the intersection:&lt;&#x2F;p&gt;
&lt;p&gt;$$s=\frac{3x21+a}{2y1}$$&lt;br &#x2F;&gt;
$$x3=s2−2x1$$&lt;br &#x2F;&gt;
$$y3=s(x1−x3)−y1$$&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;2022&#x2F;12&#x2F;imagen-5.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;It takes a little bit of work, but we can prove that the elliptic curve with this operation has the properties of a group. We will use finite fields to work with these curves and the groups that we will obtain are finite cyclic groups, that is, groups which can be generated by repeteadly using the operation on a generator, &lt;em&gt;g: g,2g,3g,4g,5g,….&lt;&#x2F;em&gt; &lt;img src=&quot;&#x2F;images&#x2F;2022&#x2F;12&#x2F;imagen-3.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;If we plot the collection of points onto a graph, we see that the points are distributed in a rather “random” fashion. For example, &lt;em&gt;2 g&lt;&#x2F;em&gt; could be very far from &lt;em&gt;3 g&lt;&#x2F;em&gt; which in turn are very far from &lt;em&gt;4 g&lt;&#x2F;em&gt;. If we wanted to know how many times &lt;em&gt;k&lt;&#x2F;em&gt; we have to add the generator to arrive at a certain point &lt;em&gt;P&lt;&#x2F;em&gt; (that is solving the equation &lt;em&gt;kg=P&lt;&#x2F;em&gt;) we see that we don’t have an easy strategy and we are forced to perform a brute search over all possible &lt;em&gt;k&lt;&#x2F;em&gt;. This problem is known as the (elliptic curve) discrete logarithm (log for friends) problem (other friends prefer ECDLP).&lt;&#x2F;p&gt;
&lt;p&gt;On the other hand, if we know &lt;em&gt;k&lt;&#x2F;em&gt; , we can compute in a very fast way &lt;em&gt;P=kg&lt;&#x2F;em&gt;. This offers us a way to hide (in plain sight) things inside the group. Of course, if you could break the DLP, you could get k, but it is rather infeasible. If we want to calculate 65536 &lt;em&gt;g&lt;&#x2F;em&gt; , we can do it by realizing that &lt;em&gt;g+g=2 g, 2g+2g=4g, 4g+4g=8&lt;&#x2F;em&gt;…until &lt;em&gt;32768 g+32768g=65535g&lt;&#x2F;em&gt;, so we narrowed the operations 65536 to 16. There are many useful algorithms that allow us to speed up the operations over elliptic curves, allowing us to avoid expensive calculations such as inversions, which appear when we want to calculate the slope.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;are-all-elliptic-curves-useful-for-crypto&quot;&gt;Are all elliptic curves useful for crypto?&lt;&#x2F;h2&gt;
&lt;p&gt;The strength of elliptic curve cryptography lies on the hardness to solve the discrete logarithm problem. This is related to the number of elements (the order of the set) making the cyclic group. If the number is a very large prime, or it contains a very large prime in its factorization (that is, the number is a multiple of a large prime), then the problem becomes infeasible. However, if the order is made up of small primes, it is possible to search over the subgroups and reconstruct the answer with help from the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Chinese_remainder_theorem&quot;&gt;Chinese Remainder Theorem&lt;&#x2F;a&gt;. This is because the difficulty depends on the size of the largest prime involved.&lt;&#x2F;p&gt;
&lt;p&gt;Some curves have desired properties and have been given names. For example, Bitcoin uses secp256k1, which has the following parameters:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;a=0&lt;&#x2F;em&gt;&lt;br &#x2F;&gt;
&lt;em&gt;b&lt;&#x2F;em&gt; =7 &lt;em&gt;p&lt;&#x2F;em&gt; =2256−232−977 &lt;em&gt;g x&lt;&#x2F;em&gt;=&lt;em&gt;0x79be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f81798&lt;&#x2F;em&gt; &lt;em&gt;g y=0x483ada7726a3c4655da4fbfc0e1108a8fd17b448a68554199c47d08ffb10d4b8&lt;&#x2F;em&gt; &lt;em&gt;r=0xfffffffffffffffffffffffffffffffebaaedce6af48a03bbfd25e8cd0364141&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;To get an idea on the number of elements of the group, they’re about &lt;em&gt;r&lt;&#x2F;em&gt; ≈1077. Even if we had 1012 supercomputers performing over 1017 search points per second for a hundred million years we wouldn’t even get close to inspecting all the possibilities.&lt;&#x2F;p&gt;
&lt;p&gt;To be able to guarantee 128-bits of security, ECs need group orders near 256-bits (that is, orders with prime factors around 1077). This is because there are algorithms which can solve the problem doing operations around √r. If the largest prime is less than 94-bits long, it can be broken with help from a desktop computer. Of course, even if your group is large enough, nothing can save you from a poor implementation.&lt;&#x2F;p&gt;
&lt;p&gt;The question arises: how can we know the number of elements of our EC? Luckily, math comes once again to our aid like the Hasse bound, Schoof’s algorithm and how to test whether a number is prime or not. Next time we will continue revealing the math principles behind useful tools in cryptography.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>A brief introduction to the beauty of Information Theory</title>
          <pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://blog.lambdaclass.com/posts/a-brief-introduction-to-the-beauty-of-information-theory/</link>
          <guid>https://blog.lambdaclass.com/posts/a-brief-introduction-to-the-beauty-of-information-theory/</guid>
          <description xml:base="https://blog.lambdaclass.com/posts/a-brief-introduction-to-the-beauty-of-information-theory/">&lt;h4 id=&quot;or-how-to-be-a-hardcore-guess-who-gamer&quot;&gt;Or how to be a hardcore Guess Who gamer&lt;&#x2F;h4&gt;
&lt;p&gt;&lt;em&gt;Authors: Juan Pablo Amoroso, Javier Rodríguez Chatruc, Camilo Plata, and Federico Carrone.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;The fundamental problem of communication is that of reproducing at one point either exactly or approximately a message selected at another point.&lt;br &#x2F;&gt;
— Claude Shannon, 1948&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;Imagine you were tasked with designing a comunications system between a space station and a ground control headquarters back in Earth. The system would transmit and receive messages encoded in binary, that is, as a sequence of 1s and 0s. As the message travels, there may be interferences from other radio signals, so that what is picked up in ground control is not exactly the same as the original message. Under these circumstances, is it possible to devise a scheme that allows reliable comunication?&lt;&#x2F;p&gt;
&lt;p&gt;A simple workaround would be to add redundancy: send each bit a number of times, let’s say 5:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;11111&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;00000&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;…&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If ground control receives the message &lt;em&gt;11101&lt;&#x2F;em&gt; , they could be fairly certain that what was truly sent was &lt;em&gt;11111&lt;&#x2F;em&gt;. Although this simple system would work (up to a point), we can see that it is very wasteful: we have to send 4 extra bits for every bit in the original message. The &lt;em&gt;transmission rate&lt;&#x2F;em&gt; is therefore only 20%. Can we do any better?&lt;&#x2F;p&gt;
&lt;p&gt;There seems to be a dilemma here: if we want accuracy, we must lower the rate of transmission.&lt;&#x2F;p&gt;
&lt;p&gt;This is the problem Claude Shannon tackled in his 1948 paper &lt;em&gt;A Mathematical Theory of Communication&lt;&#x2F;em&gt;. In it, he proved that there is a limit for the rate of information that can be reliably transmitted over a noisy channel (the &lt;em&gt;Shannon limit&lt;&#x2F;em&gt;). However, below this limit we can transmit information with an increasingly small error. This important result tells us that there &lt;em&gt;exists&lt;&#x2F;em&gt; a code that allows arbitrary accuracy over a given comunication channel, but it does not tell us how to build it.&lt;&#x2F;p&gt;
&lt;p&gt;More precisely, let’s say a channel has a probability &lt;em&gt;p&lt;&#x2F;em&gt; of transmitting a bit correctly, and a corresponding probability of 1 —  &lt;em&gt;p&lt;&#x2F;em&gt; of sending the wrong bit, Shannon proved that the optimum rate of transmission is:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-kCNAUFlhWJv1kUzKatqINA.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-TgCse1znfuWYULYwXeo4Aw.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The plot is symmetrical around &lt;em&gt;p = 0.5&lt;&#x2F;em&gt; , with maxima at &lt;em&gt;p = 0&lt;&#x2F;em&gt; and &lt;em&gt;p = 1&lt;&#x2F;em&gt;. The case of &lt;em&gt;p = 0&lt;&#x2F;em&gt; is interesting, the channel has perfect noise: it flips all the bits in the original message. But if we know that, then the message is trivially deciphered, we just flip them back.&lt;&#x2F;p&gt;
&lt;p&gt;The formula is commonly stated in terms of &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Entropy_%28information_theory%29&quot;&gt;information entropy&lt;&#x2F;a&gt;, a measure Shannon devised that can be interpreted as the level of ‘uncertainty’ or ‘surprise’ associated with the channel.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-fCyO-nZidJEiOqwqDGWJ3g.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-s0z3MUCTtJvh_AsvxGg72g.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;We can see that the entropy has a maximum at 1 when &lt;em&gt;p&lt;&#x2F;em&gt; = ½, and minima at 0 for &lt;em&gt;p =&lt;&#x2F;em&gt; 0 and &lt;em&gt;p =&lt;&#x2F;em&gt; 1.&lt;&#x2F;p&gt;
&lt;p&gt;More generally, given a random message &lt;em&gt;M&lt;&#x2F;em&gt; that can take &lt;em&gt;n&lt;&#x2F;em&gt; different values with probability &lt;em&gt;pᵢ&lt;&#x2F;em&gt; for &lt;em&gt;i =&lt;&#x2F;em&gt; 1,…,&lt;em&gt;n&lt;&#x2F;em&gt; , we define the entropy of the message as:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-ezweLprVK1INseQwDCN2yg.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;guess-who-example&quot;&gt;Guess Who example&lt;&#x2F;h4&gt;
&lt;p&gt;Let’s take a different approach. Suppose you are playing &lt;em&gt;Guess Who&lt;&#x2F;em&gt; , the game where you ask yes&#x2F;no questions about the appearance of your opponent’s character in order to single him or her out among a set of characters. You ask yourself: what order should I ask the questions in to maximise the probability of winning? Intutively, you try to ask first about features most of the characters have.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-TkW9quvg52IBgM06fM-7IA.jpeg&quot; alt=&quot;&quot; &#x2F;&gt;Hardcore Guess Who gamers apply Information Theory for optimal results&lt;&#x2F;p&gt;
&lt;p&gt;Moreover, an optimal question is one that divides the population evenly, that is, one that regardless of the answer (&lt;em&gt;yes&lt;&#x2F;em&gt; or &lt;em&gt;no&lt;&#x2F;em&gt;) discards half the characters. In any other case, you are not gaining the optimal amount of information with each question.&lt;&#x2F;p&gt;
&lt;p&gt;But what if you can’t divide the characters evenly by their characteristics? To answer the question, first we recall the concept of entropy defined above. We can think of a question as a variable &lt;em&gt;X&lt;&#x2F;em&gt; that splits the population into groups &lt;em&gt;xᵢ&lt;&#x2F;em&gt; with probabilities &lt;em&gt;pᵢ&lt;&#x2F;em&gt;. For example, think of a question about the eye color of the character (the questions in the game are technically only &lt;em&gt;yes&lt;&#x2F;em&gt; or &lt;em&gt;no&lt;&#x2F;em&gt; but this can be generalized). With this in mind, the entropy of a question becomes:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-KZq1CO03SyEnsH0qLamzRQ.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The intuition here is that with each possible answer, we gain an amount of information  &lt;em&gt;— log&lt;&#x2F;em&gt; &lt;em&gt;p&lt;&#x2F;em&gt;(&lt;em&gt;x&lt;&#x2F;em&gt; ᵢ), meaning that if we receive an answer with a very low probability (i.e. we ask if the character has a feature that is shared by very few people, and the answer is yes), the amount of information we gained is higher than an answer with more probability.&lt;&#x2F;p&gt;
&lt;p&gt;On the other hand, entropy is related to uncertainty. For example, if we flip a coin, the uncertainty in the outcome is higher with a &lt;em&gt;p&lt;&#x2F;em&gt; = 0.5 than with any other value of &lt;em&gt;p&lt;&#x2F;em&gt;. And in our case, more uncertainty is better. Why? If we choose a question with an uneven distribution in the population, lets say 0.7 and 0.3, the odds are that our character is among the 70%, discarding with the &lt;em&gt;no&lt;&#x2F;em&gt; answer only the remaining 30%, but with a more even division (and therefore more uncertain), we always tend to discard 50% of the population, leading to an advantage in the long run. This means that the best questions to ask are those that maximize the entropy, i.e, the ones with the higher uncertainty.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;decision-trees&quot;&gt;Decision Trees&lt;&#x2F;h4&gt;
&lt;p&gt;One common use of entropy is in decision trees, where one uses a set of features (features that split the data into disjoint sets) to construct a flowchart for a classification problem. Here, a common question is: which order should we “apply” the features in to get the best splits? A possible solution is to recursively always use the feature that maximizes the &lt;em&gt;information gain&lt;&#x2F;em&gt;. If we’re working with a dataset &lt;em&gt;S&lt;&#x2F;em&gt; and our feature is called &lt;em&gt;X&lt;&#x2F;em&gt; , the information gained on &lt;em&gt;S&lt;&#x2F;em&gt; by &lt;em&gt;X&lt;&#x2F;em&gt; , &lt;em&gt;I&lt;&#x2F;em&gt;(&lt;em&gt;S&lt;&#x2F;em&gt; ,&lt;em&gt;X&lt;&#x2F;em&gt;), is calculated as:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-tIzlfBpMihRvpfZICpWZJA.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;where &lt;em&gt;H&lt;&#x2F;em&gt;(&lt;em&gt;S&lt;&#x2F;em&gt; |&lt;em&gt;X&lt;&#x2F;em&gt;) is the conditional entropy of &lt;em&gt;S&lt;&#x2F;em&gt; given &lt;em&gt;X&lt;&#x2F;em&gt;. Intuitively, this is just the reduction in the entropy of the dataset &lt;em&gt;S&lt;&#x2F;em&gt; if we know &lt;em&gt;X&lt;&#x2F;em&gt;. Thus, it makes sense to choose the features &lt;em&gt;X&lt;&#x2F;em&gt; that maximize this value, as they will be the ones that reduce uncertainty the most, effectively obtaining the best splits.&lt;&#x2F;p&gt;
&lt;p&gt;Algorithms that consider the information gain at each node to choose the next feature are called &lt;em&gt;greedy&lt;&#x2F;em&gt; algorithms. Such algorithms do not take into account the overall information gain and may lead in some cases to suboptimal queries, but they are well-behaved and have a straightforward approach.&lt;&#x2F;p&gt;
&lt;p&gt;As an example, consider the picture below, where a decision tree method was used on the famous Iris flower dataset and two features were selected, the petal width, first with 0.8 cm as a threshold and then 1.75 cm. Setting aside how these specific features are selected, why use the ≤ 0.8 first? With the information gain calculation we described, we can provide an answer. We will call the feature that separates petal width on 0.8 cm &lt;em&gt;X&lt;&#x2F;em&gt; and the other one &lt;em&gt;Y&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-dEesB-YyIVG81qhIDn_T_w.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Applying &lt;em&gt;X&lt;&#x2F;em&gt; first splits the 150 data points (usually one would split between training and test sets, here for simplicity we use the entire set) into two sets: one containing the entire &lt;em&gt;setosa&lt;&#x2F;em&gt; class (50 points, corresponding to ≤ 0.8 cm) and nothing else, and the other containing the rest. In that case the calculations yield:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-2dDOZS_8PGYonq3RZYoyAg.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;On the other hand, applying &lt;em&gt;Y&lt;&#x2F;em&gt; first gives us one set with 50 &lt;em&gt;setosa&lt;&#x2F;em&gt; , 49 &lt;em&gt;versicolor&lt;&#x2F;em&gt; and 5 &lt;em&gt;virginica&lt;&#x2F;em&gt; (≤ 1.75 cm) and another with no &lt;em&gt;setosa&lt;&#x2F;em&gt; , 1 &lt;em&gt;versicolor&lt;&#x2F;em&gt; and 45 &lt;em&gt;virginica&lt;&#x2F;em&gt;. This leaves us with:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-VCQsujq_mEufMZi1X4DGdw.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Thus the information gain from &lt;em&gt;X&lt;&#x2F;em&gt; (petal width being under or over 0.8 cm) is greater than the one from &lt;em&gt;Y&lt;&#x2F;em&gt; , and we should use it first. This makes sense intuitively, as &lt;em&gt;X&lt;&#x2F;em&gt; completely separates the &lt;em&gt;setosa&lt;&#x2F;em&gt; class from the other two, whereas using &lt;em&gt;Y&lt;&#x2F;em&gt; first gives a more entangled split.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h4&gt;
&lt;p&gt;It is hard to overstate the importance of Shannon’s work: the Theory of Information has found &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.britannica.com&#x2F;science&#x2F;information-theory&#x2F;Applications-of-information-theory&quot;&gt;many applications&lt;&#x2F;a&gt; in fields as diverse as statistical inference and machine learning, natural language processing, genetics, data compression, coding theory, and cryptography. With over 120,000 citations, few papers can boast a similar impact. In the words of information theorist Anthony Ephremides:&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;It was like an earthquake and the aftershocks haven’t finished yet!&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
</description>
      </item>
    </channel>
</rss>
