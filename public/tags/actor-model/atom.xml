<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title>LambdaClass Blog - Actor Model</title>
    <subtitle>Deep technical insights on cryptography, distributed systems, zero-knowledge proofs, and cutting-edge software engineering from the LambdaClass team.</subtitle>
    <link rel="self" type="application/atom+xml" href="https://blog.lambdaclass.com/tags/actor-model/atom.xml"/>
    <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2021-09-02T00:00:00+00:00</updated>
    <id>https://blog.lambdaclass.com/tags/actor-model/atom.xml</id>
    <entry xml:lang="en">
        <title>Simulations are about to get way, way faster with JuliaSim</title>
        <published>2021-09-02T00:00:00+00:00</published>
        <updated>2021-09-02T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/simulations-are-about-to-get-way-way-faster-with-juliasim/"/>
        <id>https://blog.lambdaclass.com/posts/simulations-are-about-to-get-way-way-faster-with-juliasim/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/simulations-are-about-to-get-way-way-faster-with-juliasim/">&lt;p&gt;Today we’re excited to bring you a first glance at the result of a major multi-year project by the Julia Computing team.&lt;&#x2F;p&gt;
&lt;p&gt;JuliaSim is a cloud-based simulation platform built on top of the Julia open source stack, including SciML and ModelingToolkit, which we explored in depth &lt;a href=&quot;&#x2F;scientific-machine-learning-with-julia-the-sciml-ecosystem&#x2F;&quot;&gt;here&lt;&#x2F;a&gt; and &lt;a href=&quot;&#x2F;modeling-complexity-with-symbolics-jl-and-modelingtoolkit-jl&#x2F;&quot;&gt;here&lt;&#x2F;a&gt;, respectively. These were just the base of JuliaSim, which aims to change the way the industry does modeling and simulation with powerful acceleration and integration within a complete ecosystem.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;juliacomputing.com&#x2F;products&#x2F;juliasim&#x2F;&quot;&gt;JuliaSim&lt;&#x2F;a&gt;’s first beta will be released in a few months. We interviewed Chris Rackauckas to learn more about the project.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h4 id=&quot;what-is-juliasim-how-does-it-compare-to-alternatives-like-modelica-dymola&quot;&gt;What is JuliaSim? How does it compare to alternatives like Modelica&#x2F;Dymola?&lt;&#x2F;h4&gt;
&lt;p&gt;JuliaSim is a cloud-based platform for accelerated modeling and simulation. Unlike tools like Dymola, it integrates with a large open source community, the Julia programming language and the SciML ecosystem, to enhance its environment with offerings like easy parallelism, automated generation of ML surrogate models, and much more. In &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=lNbU5jNp67s&quot;&gt;a recent talk at JuliaCon 2021&lt;&#x2F;a&gt; I highlight this community integration as one of its core aspects that gives JuliaSim a competitive advantage in terms of features and performance, since it allows us to contribute to and benefit from the work of many scientists and engineers from across the world.&lt;&#x2F;p&gt;
&lt;p&gt;While JuliaSim has acausal modeling as one of its core features, unlike Modelica-based tools that is just one of its domains. Accelerated simulation of PDEs with neural networks, integrating stochastic simulation into workflows, specific simulation environments for pharmacology and circuit modeling, and much more are all part of the JuliaSim product. We see the future as a place where composability will be necessary to achieve the next level of simulations.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;can-it-integrate-with-the-fmi-will-we-be-able-to-use-models-written-in-e-g-modelica-inside-juliasim&quot;&gt;Can it integrate with the FMI? Will we be able to use models written in, e.g. Modelica, inside JuliaSim?&lt;&#x2F;h4&gt;
&lt;p&gt;Yes, JuliaSim at its release will offer features for integrating with the FMI standard, allowing for FMI imports and FMI exports. This will allow for example the ability to build surrogates of models from Modelica or Simulink platforms, and allow for generating binaries that can integrate back into these platforms.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;a-key-aspect-of-modelica-is-its-standard-library-which-includes-many-of-the-most-common-components-for-modeling-will-there-be-a-similar-thing-in-juliasim&quot;&gt;A key aspect of Modelica is its standard library, which includes many of the most common components for modeling. Will there be a similar thing in JuliaSim?&lt;&#x2F;h4&gt;
&lt;p&gt;With JuliaSim we are building a standard library which includes similar domains to the Modelica Standard Library, but also includes many other domains related to the customers we have been working with. For example, with JuliaSim one will be able to easily search a database of hundreds of physiological and systems biological models for accelerating workflows in biomedical simulation and drug development. We plan to continually improve this model library and mold it to the needs of our customers.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-are-surrogate-models-what-makes-them-important-especially-beyond-academic-applications&quot;&gt;What are surrogate models? What makes them important, especially beyond academic applications?&lt;&#x2F;h4&gt;
&lt;p&gt;Surrogate models are an amortization of compute cost to improve simulation workflows. It gives you a way to say “do 100 simulations now, and all of my future simulations are 100x faster”. When you mix this with cloud resources you can get a major workflow update: pay for a bit of cloud compute to spawn a bunch of simulations in parallel, but now every time you click the simulate button you do not have to wait 30 minutes to check the result.&lt;&#x2F;p&gt;
&lt;p&gt;When I was in graduate school I noticed that there is a very nonlinear effect of code speed on productivity which I captured in a &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.stochasticlifestyle.com&#x2F;the-nonlinear-effect-of-code-speed-on-productivity&quot;&gt;blog post&lt;&#x2F;a&gt;. If you have to wait 30 minutes for a result, that means that instead you’ll start it before lunch or before a 1 hour meeting, so the true “time to see simulation results” gets amplified further. 2 hour simulations are something you will start in the morning and check at night. Thus a surrogate changing a long simulation to something that you can analyze in real-time is invaluable to decreasing labor costs because of how simulation time effects the day-to-day life of an engineer.&lt;&#x2F;p&gt;
&lt;p&gt;While in an academic sense we focus on issues like “training the surrogate costs 100 simulations, but we needed 10,000 simulations for to optimize the building design and thus we saved in the end”, I do not think this calculus is really the major change that surrogates will bring. Even if it takes 100 simulations to train a surrogate that you use 10 times, if you integrate this will cloud compute to do those all in parallel, then to the user you only have to sit through what is effectively 2 simulations. If that’s a two hour simulation time, you’ve now changed a workflow that takes a full day to something that you set to train in the morning and then after lunch you can interactively fiddle with parameters until your controls are correct. And then any time you revisit in the future, it’s ready to be fiddled with again. When you view surrogates in this light, I think you can see why we believe this will be a gamechanger for the everyday engineer.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;one-of-the-main-innovations-brought-by-juliasim-is-the-generation-of-fast-and-accurate-surrogate-models-that-can-speedup-simulations-as-much-as-500x-even-in-the-presence-of-stiff-models-how-is-this-achieved-what-s-a-ctesn&quot;&gt;One of the main innovations brought by JuliaSim is the generation of fast and accurate surrogate models that can speedup simulations as much as 500x, even in the presence of stiff models. How is this achieved? What’s a CTESN?&lt;&#x2F;h4&gt;
&lt;p&gt;A continuous-time echo state network (CTESN) is an implicitly trained machine learning framework for capturing the dynamics of stiff models. These are models with phase transitions, fast transient behavior, and are well-known to be numerically difficult. Across many domains we have shown the CTESN training procedure to be robust due to how it incorporates implicit features of stable differential equation solvers. All that we need to generate it is a chunk of simulations done beforehand, and what results is this really fast object that will predict the simulation behavior at new parameters.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;how-easy-is-it-to-compose-surrogate-models-with-normal-ones-in-juliasim-what-are-the-advantages-of-this-approach&quot;&gt;How easy is it to compose surrogate models with normal ones in JuliaSim? What are the advantages of this approach?&lt;&#x2F;h4&gt;
&lt;p&gt;The CTESN represents the surrogate of a differential equation model as a differential equation model. Because of this representation, it’s not different from the other physical components. As long as you train it to cover the right states and observables, it will slot right into where you had the larger model before.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;paramount-to-surrogatization-is-the-ability-to-check-the-accuracy-of-the-surrogate-model-and-its-performance-against-the-original-one-how-does-juliasim-tackle-this-are-these-metrics-appropriately-exposed-to-the-user&quot;&gt;Paramount to surrogatization is the ability to check the accuracy of the surrogate model and its performance against the original one. How does JuliaSim tackle this? Are these metrics appropriately exposed to the user?&lt;&#x2F;h4&gt;
&lt;p&gt;JuliaSim generates diagnostics of the surrogate training process to signal to the user important features like the projected maximum error over the timeseries over the user-defined parameter space. A lot of this is done through quasi-random sampling right now, though we are investigating more complex techniques to more quickly achieve good estimates.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;does-juliasim-run-on-top-of-juliahub-or-are-they-separate-things-is-the-pricing-model-expected-to-be-the-same&quot;&gt;Does JuliaSim run on top of &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;juliahub.com&#x2F;lp&#x2F;&quot;&gt;JuliaHub&lt;&#x2F;a&gt; or are they separate things? Is the pricing model expected to be the same?&lt;&#x2F;h4&gt;
&lt;p&gt;JuliaSim is JuliaHub-based platform. JuliaSim users receive a subscription to a set of proprietary packages, such as the standard library and the surrogatization tools, which grants access to their use on JuliaHub. The pricing model of JuliaSim is simply the subscription and pay-for-compute, so users only pay for what they use but have access to the full suite.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;will-there-be-a-gui-for-modeling-or-will-we-mostly-have-to-write-all-the-julia-code-explicitly&quot;&gt;Will there be a GUI for modeling or will we mostly have to write all the Julia code explicitly?&lt;&#x2F;h4&gt;
&lt;p&gt;There will be many GUIs! The first GUI that we are building is more pharmaceutical modeling focused given our early customer base and connections with Pumas-AI. This allows for quickly building chemical reaction network and systems pharmacology models, and representing models in a visual form for presentations and reporting. It also will serve as the basis for visual programming of compartmental models in pharmacokinetics. We also will have a GUI at launch which simplifies the FMU surrogatization process, allowing non-Julia users to quickly accelerate their FMUs by entering in parameter information and clicking “surrogatize”. We have other GUIs planned for the near future as well, such as GUIs for block diagrams and acausal modeling, along with 3D visualization tools.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;juliasim-is-launching-pretty-soon-what-can-we-expect-from-this-first-version-what-features-are-next&quot;&gt;JuliaSim is launching pretty soon; what can we expect from this first version? What features are next?&lt;&#x2F;h4&gt;
&lt;p&gt;JuliaSim’s first beta will be launching fairly soon. I wouldn’t call it the first version quite yet, though the beta will already be usable as we have been working with a group of customers to showcase the performance advantage for their specific applications. The first release will be a mix of GUIs, cloud parallel surrogatization, and standard libraries. And for the future we are aiming for a lot more. The full vision of JuliaSim is expressed in &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=lNbU5jNp67s&quot;&gt;the JuliaCon 2021 video&lt;&#x2F;a&gt; so refer to that for more details.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>LAM: an actor-model VM for WebAssembly and native</title>
        <published>2021-02-26T00:00:00+00:00</published>
        <updated>2021-02-26T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/lam-an-actor-model-vm-for-webassembly-and-native/"/>
        <id>https://blog.lambdaclass.com/posts/lam-an-actor-model-vm-for-webassembly-and-native/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/lam-an-actor-model-vm-for-webassembly-and-native/">&lt;p&gt;An interview with its creator, Leandro Ostera.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-ZA5-hKa-yYGz8FX-kmZh9g.png&quot; alt=&quot;&quot; &#x2F;&gt;Source: &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;abstractmachines.dev&#x2F;&quot;&gt;https:&#x2F;&#x2F;abstractmachines.dev&#x2F;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Here, at NAMT, we are in love with the Actor Model.&lt;br &#x2F;&gt;
Within this paradigm, the basic units of computation are called actors. There is no shared state between them, instead, they interact via message passing. This has the advantage that actors become trivial to paralellize (in Erlang, an actor is called a &lt;em&gt;process&lt;&#x2F;em&gt;) and errors became easier to handle.&lt;&#x2F;p&gt;
&lt;p&gt;The actor model is a concurrency paradigm created by Carl Hewitt in 1973 with the goal of making the task of writing concurrent programs simpler. It is based on the idea of actors, entities that can only send, receive and process messages. By reducing the amount of shared state it reduces the need of locks for synchronization. There exists several battle-tested implementations of the Actor Model such as Erlang&#x2F;OTP, Akka (Scala&#x2F;Java) and Orleans (C#).&lt;&#x2F;p&gt;
&lt;p&gt;In this interview, we chat with Leandro Ostera, the founder of Abstract Machines. Ostera is working on LAM, The Little Actor Machine, an embeddable virtual machine for the actor model that runs native or compiles to WebAssembly.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;The questions for this interview were thought by Juan Pablo Amoroso, Javier Chatruc &amp;amp; Federico Carrone. Joaquín Centeno and Juan Bono wrote the introduction and edited the article.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;&lt;strong&gt;Tell us a bit about your project lab, Abstract Machines. What kind of work do you do?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I started Abstract Machines with a single goal in mind: build tools that would help me think more clearly.&lt;&#x2F;p&gt;
&lt;p&gt;Right now what I do think about the most is writing software. I think typed languages help me think clearly, so I’m building Caramel, an OCaml for the BEAM. I also think that understanding the program that runs your programs is fundamental to thinking clearly about the quality of what you build, so I’m building LAM, an actor-model VM.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;LAM’s tagline is “A Little Actor Machine that runs on Native and WebAssembly”. Could you give us a brief overview of the actor system?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The original name was Leandro’s Abstract Machine. Like Prolog’s WAM was named after Warren, Warren’s Abstract Machine, and the early Erlang VM was JAM after Joe’s Abstract Machine. But Little I think it’s a much better name overall: LAM should be small, tiny even.&lt;&#x2F;p&gt;
&lt;p&gt;The actor system it implements is in spirit very close to Erlang’s take on the actor model — processes with mailboxes, message passing across them, fair scheduling through reduction counting. There’s a few more things in the roadmap, like process linking and monitoring. Overall, if you have worked with Erlang or Elixir before, you should feel right at home with LAM.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What is the motivation behind LAM? Why build a BEAM alternative?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;LAM’s mission is to make Actor concurrency available everywhere by providing a specified, lightweight runtime. Think LuaVM meets the Actor Model. I’ve always liked the LuaVM, there’s a certain elegance to it that I find very appealing.&lt;&#x2F;p&gt;
&lt;p&gt;One of the reasons to build an alternative is that the BEAM is rather large, and the implementation is the only real spec. [Erik Stenmans’ Beam Book] or [kvavks Beam Wisdoms] have tried to document it, but without an official effort to produce a JVM style spec (like the one you can get in a bookshelf), it’s unlikely we will have a reliable drop-in alternative any time soon.&lt;&#x2F;p&gt;
&lt;p&gt;So I thought I could instead make a new thing that could learn from both the LuaVM and the BEAM. At 35 instructions, LAM can run an interesting amount of Erlang programs, in fact I’d like most code that runs on the BEAM to be bytecode-translatable to run on LAM. Not all of it tho, and we’ll see what doesn’t make the cut.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;One of LAM’s targets is WebAssembly. Is there any alternative actor system for the web? How do they compare with LAM?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Yes, there are plenty! A most promising one these days is Lunatic, but on the Erlang side of things, there’s the up-and-coming Lumen.&lt;&#x2F;p&gt;
&lt;p&gt;Most of the rest are libraries for building actor applications in other languages, like how Actix lets you use Actors in Rust. Lumen in particular is more of a compiler + runtime that brings Erlang down to LLVM and gives you this single optimized executable.&lt;&#x2F;p&gt;
&lt;p&gt;LAM by contrast is a higher level VM: you feed it bytecode (spawn, send, receive, call, make list, etc), and as it runs it, side-effects happen through FFI&#x2F;Bindings depending on the platform.&lt;&#x2F;p&gt;
&lt;p&gt;Around LAM there’s a tiny compilation toolchain that takes that bytecode, lowers it to something that can be run a little faster, and packs it &lt;em&gt;with the VM&lt;&#x2F;em&gt; in a single binary that is optimized for a specific platform.&lt;&#x2F;p&gt;
&lt;p&gt;Because the VM is tiny, and the FFIs are pluggable, it’s straightforward to compile it to WebAssembly and run your bytecode there.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;The documentation mentions that one of the goals is to support Erlang&#x2F;OTP’s supervision tree structure. Would this allow more reliable&#x2F;resilient web UIs, capable of gracefully recovering from errors?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Absolutely! I expect it to let you build even more natural and flexible UIs. After all the “event” model fits perfectly: when process Button receives message Click, do this&#x2F;that.&lt;&#x2F;p&gt;
&lt;p&gt;The main problem is that preemptive scheduling makes it impossible to guarantee certain processes will have enough time to make stuff like animations run smoothly. But I’m borrowing the idea of dirty schedulers and considering introducing Greedy Processes instead, that can either request upfront how much time they need, or just run to completion. Definitely interesting to experiment with hard-real time scheduling as well.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What are some interesting use cases for LAM?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Off the top of my head, there’s 2. The first one is perhaps why I want it the most these days: fast cli tools. Write ’em in Erlang&#x2F;Elixir&#x2F;Caramel, ships as a single binary.&lt;&#x2F;p&gt;
&lt;p&gt;The second one will have the largest impact on how we build for the BEAM: actually writing full-stack applications in a single BEAM Language.&lt;&#x2F;p&gt;
&lt;p&gt;Write your backend in Elixir and run it on the BEAM, write your frontend in Elixir too but run it on LAM. And it doesn’t have to be a web-based app, it could be an actual native GUI application too.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Why write it in Rust? Is the Rust-WASM toolchain mature enough to target WASM reliably with LAM?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I love Rust. It’s a good language and the learning curve has certainly taught me a lot about how to build software. I think the Rust-wasm toolchain is pretty mature these days too.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Besides performance (LAM compiles AOT), what will be the advantages of LAM over the BEAM?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Really the AOT stuff I can’t consider an advantage — I don’t expect LAM to be fundamentally faster than the BEAM, especially after the BeamJIT work. Nor do I expect it to compete in speed with Lumen.&lt;&#x2F;p&gt;
&lt;p&gt;What I see as an advantage is that LAM is being built to have a Specification and to be Embeddable.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;WebAssembly lacks a garbage collector and the BEAM is a GC environment. How does LAM tackle this?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;There is a wasm-gc spec in the works, and some other folks are waiting on it as well (like the OCaml-wasm efforts).&lt;&#x2F;p&gt;
&lt;p&gt;But since WebAssembly isn’t the only LAM target, we’ll have to embed a GC anyway. I expect it to work very closely to the BEAMs (per process collections, ref counted binary strings, etc). I haven’t looked so deeply into this, but I have a chunky book waiting for me (The Garbage Collection Handbook).&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Is this a solo project or are you looking for contributors? If you are looking for contributors, how should they get started (first issues, roadmap, etc)?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;So far it is just me, but I’d love to build a friendly and welcoming community around it. At the moment I’ve been focused on getting this vertical slice of the project up and running so it becomes easier to do some horizontal scoping: how far along are we with the specification, or how much of the BEAM bytecode can we support via translation.&lt;&#x2F;p&gt;
&lt;p&gt;There’s tons of work to do starting at the design level. From figuring out how to build the right layers to FFIs across platforms (native, wasi, web), to how to optimize the main emulator loop to crunch the bytecode as fast as possible, to GC and bundling the final binaries, to writing the spec and the manual.&lt;&#x2F;p&gt;
&lt;p&gt;Formalizing the spec is a big topic where I hope I can get some interest from the TLA+ community to guide me into doing justice to both TLA+ and LAM.&lt;&#x2F;p&gt;
&lt;p&gt;LAM could use help across the board, so if you’re reading this please tweet at me (&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;leostera&#x2F;&quot;&gt;@leostera&lt;&#x2F;a&gt;)!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;For our last question, in general, what are your favorite books, articles or resources for programmers?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I think that if you asked me this a year ago I would have regurgitated a bunch of books that I should list here, but that didn’t really further my understanding. There’s a lot of reference material that is just terrible for learning, because its meant to be a compendium of information rather than a pedagogically written introduction to a subject.&lt;&#x2F;p&gt;
&lt;p&gt;For example, Types and Programming Languages by Benjamin Pierce is deemed &lt;em&gt;the ultimate&lt;&#x2F;em&gt; reference for type stuff. But I learned more about the nature of typing by reading The Little Typer. After that it was a lot easier to get into the right headspace to understand what Pierce wanted me to get out of the book.&lt;&#x2F;p&gt;
&lt;p&gt;So if you’re getting into a subject, don’t rush for the ultimate reference, and find something written to teach you &lt;em&gt;the core&lt;&#x2F;em&gt; of the subject. Then the rest becomes a little easier.&lt;&#x2F;p&gt;
&lt;p&gt;Virtual Machines by Iain D. Craig, and Formal Development of a Network-Centric RTOS have been very useful in working with LAM. Hillel Wayne’s Practical TLA+, and Alloy’s Software Abstraction books have been really good to get a better grip on how to specify systems as well. Of course &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;lamport.azurewebsites.net&#x2F;tla&#x2F;book.html&quot;&gt;“Specifying Systems” by Lamport&lt;&#x2F;a&gt; has been a good reference as well.&lt;&#x2F;p&gt;
&lt;p&gt;Some books that have had a massive impact in how I think and communicate have (unsurprisingly) nothing to do with computers. Like Umberto Eco’s “6 Walks in the Fictional Woods” (focused on how to create narratives and rhetoric) or Mandelbrot’s “The (Mis)Behavior of Markets” (a historical account of how fractal geometry describes better the financial markets). Nonetheless, they’ve helped shape the way I think and I’ve come out a better programmer.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;0-nPPWbd4-7dJavk5P.gif&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
</content>
        
    </entry>
</feed>
