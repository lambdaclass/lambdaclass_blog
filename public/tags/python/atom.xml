<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title>LambdaClass Blog - Python</title>
    <subtitle>Deep technical insights on cryptography, distributed systems, zero-knowledge proofs, and cutting-edge software engineering from the LambdaClass team.</subtitle>
    <link rel="self" type="application/atom+xml" href="https://blog.lambdaclass.com/tags/python/atom.xml"/>
    <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2020-11-02T00:00:00+00:00</updated>
    <id>https://blog.lambdaclass.com/tags/python/atom.xml</id>
    <entry xml:lang="en">
        <title>Stumpy: unleashing the power of the matrix profile for time series analysis</title>
        <published>2020-11-02T00:00:00+00:00</published>
        <updated>2020-11-02T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/stumpy-unleashing-the-power-of-the-matrix-profile-for-time-series-analysis/"/>
        <id>https://blog.lambdaclass.com/posts/stumpy-unleashing-the-power-of-the-matrix-profile-for-time-series-analysis/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/stumpy-unleashing-the-power-of-the-matrix-profile-for-time-series-analysis/">&lt;h4 id=&quot;an-interview-with-stumpy-creator-sean-law&quot;&gt;An interview with Stumpy creator Sean Law&lt;&#x2F;h4&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-4Y5wJGqZM2AxKb7fmT9-og.png&quot; alt=&quot;&quot; &#x2F;&gt;Source: &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;stumpy.readthedocs.io&#x2F;en&#x2F;latest&#x2F;Tutorial_Time_Series_Chains.html&quot;&gt;Stumpy documentation&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;In the mid-20th century, the Information Age started. Every day an astonishing amount of data is created and analyzing it in an efficient way requires computational tools that combine novel and clever approaches that benefit from cutting edge technology.&lt;&#x2F;p&gt;
&lt;p&gt;Time series are a particular kind of data: the points measured are related by time, and analyzing them can often become quite difficult because time is not just like any other variable. More traditional methods like ARIMA or machine learning methods like LSTM can quickly become computationally inefficient as the amount of points increase, and sometimes they can be too elaborate for simple results such as finding overall patterns in the data, not to mention the complications arising when finding more complex patterns in the data is the final goal.&lt;&#x2F;p&gt;
&lt;p&gt;Stumpy is a library for analyzing time series, that tries to address the problems that appear when working with this kind of data. By design, Stumpy high performance, simplicity, and to employ general purpose approaches for extracting meaningful information. We interviewed the team to learn more about this promising project.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-NWV2vLKBciK49BAVfzvN4Q.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-is-stumpy-what-are-the-goals-of-the-project&quot;&gt;What is STUMPY? What are the goals of the project?&lt;&#x2F;h4&gt;
&lt;p&gt;Numerous classical methods exist for understanding and analyzing time series data, such as data visualization, summary statistics, ARIMA modeling, Markov modeling, anomaly detection, forecasting, machine learning, deep learning, etc. The list goes on. However, when a data practitioner is presented with new or unfamiliar time series data, many of the aforementioned approaches often fail to uncover any significant pattern, anomaly, or unique observation since it isn’t known, a priori, whether or not an interesting insight even exists. Of course, if a behavior is found to be conserved within your time series (though, this may not always be true), then there must have been a reason why it was conserved and teasing out those reasons or causes can often be very useful. Note that with time series analysis we are rarely interested in single point statistics (i.e., global max, global min, etc) and, instead, it is more valuable to discover interesting “subsequences” (i.e., a continuous run of values along your time series with a preset length). So, when starting with time series analysis, one should really be asking:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Do any conserved behaviors (i.e., repeating subsequences) exist in my time series data?&lt;&#x2F;li&gt;
&lt;li&gt;If there are conserved behaviors, what are they and where are they?&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;A naive but straightforward approach that can help answer these questions (covered in more detail &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;stumpy.readthedocs.io&#x2F;en&#x2F;latest&#x2F;Tutorial_The_Matrix_Profile.html&quot;&gt;here&lt;&#x2F;a&gt;) could involve comparing the Euclidean distance for every subsequence within the time series in a pairwise fashion in order to identify subsequences that are either highly conserved or exceptionally rare. This seems intuitive at first and it provides an exact solution to our problem but, as the size of the dataset increases (&amp;gt;10,000 data points), this brute force search can quickly become computationally intractable and reveals why approximate solutions (i.e., allowing for false positives and false negatives) or less interpretable solutions (above) have prevailed. Recently, &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.cs.ucr.edu&#x2F;~eamonn&#x2F;MatrixProfile.html&quot;&gt;independent research conducted at UC Riverside&lt;&#x2F;a&gt; has spawned a collection of brand new ideas and they have developed scalable algorithms that directly addresses this hard computational problem. However, the knowledge and capabilities that have been transferred to the scientific Python community has been limited.&lt;&#x2F;p&gt;
&lt;p&gt;And so, STUMPY was born. &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;TDAmeritrade&#x2F;stumpy&quot;&gt;STUMPY&lt;&#x2F;a&gt; is a powerful and scalable Python package that faithfully reproduces the aforementioned academic work and, at its core, efficiently computes something called a “matrix profile”, which can be used for a variety of time series data mining tasks. Essentially, a matrix profile is a vector that stores the Euclidean distance (and index location) between each subsequence within a time series and its nearest neighbor. And, with 100% code coverage and multi-CPU&#x2F;multi-GPU support out of the box, the goal of STUMPY is to provide a highly reliable and user-friendly interface for modern time series analysis that can quickly and easily scale up to accommodate your ever-growing data needs.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-kind-of-time-series-analysis-can-be-done-with-stumpy-in-what-fields-do-you-think-it-will-help-the-most&quot;&gt;What kind of time series analysis can be done with Stumpy? In what fields do you think it will help the most?&lt;&#x2F;h4&gt;
&lt;p&gt;As mentioned above, STUMPY is focused on efficiently computing a simple-to-interpret but highly useful data structure called the “matrix profile”. Earlier, Eamonn Keogh, one of the original academic researchers, claimed that “Given the matrix profile, most time series data mining problems are easy or trivial to solve in a few lines of code.” In fact, Keogh and his colleagues have since published over 20 papers demonstrating the many things that can be done once you’ve computed the matrix profile and, below, are a just few examples:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Motif discovery — identify conserved subsequences (related to pattern recognition)&lt;&#x2F;li&gt;
&lt;li&gt;Discord discovery — uncover subsequences that are poorly conserved (related to anomaly detection)&lt;&#x2F;li&gt;
&lt;li&gt;Time series chains — find related patterns that are evolving monotonically over time (related to forecasting)&lt;&#x2F;li&gt;
&lt;li&gt;Semantic segmentation — automatically determine regime changes within your time series data (related to change point detection)&lt;&#x2F;li&gt;
&lt;li&gt;Streaming data analysis&lt;&#x2F;li&gt;
&lt;li&gt;Multi-dimensional matrix profiles&lt;&#x2F;li&gt;
&lt;li&gt;Time series clustering&lt;&#x2F;li&gt;
&lt;li&gt;And more…&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;One of the benefits of computing matrix profiles with STUMPY is that it is 100% domain agnostic. This means that it is completely generalizable and can be applied in any field where you need to analyze continuous sequential data! In addition to the previously published examples, STUMPY has been applied in analyzing the stock market, bettering server uptime and resiliency, investigating call center conversation flow, understanding IoT sensor data, improving cryptocurrency model predictions, and stabilizing ion acceleration at CERN, just to name a few. Today, time series data is ubiquitous in both academia as well as industry and so we believe that STUMPY is a new tool that is extremely well positioned to help researchers and data scientists explore their data in a systematic and focused way and, hopefully, allow them to discover new insights with much less frustration and time spent. If you already have Python installed then you should be able to get started with STUMPY in less time than it takes for you to make a cup of coffee.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-are-the-benefits-of-computing-the-matrix-profile-in-the-context-of-analyzing-a-time-series-what-are-the-advantages-over-other-methods&quot;&gt;What are the benefits of computing the matrix profile in the context of analyzing a time series? What are the advantages over other methods?&lt;&#x2F;h4&gt;
&lt;p&gt;Matrix profiles are simple, intuitive, and interpretable. Basically, if you understand what Pythagorean theorem is then you’re all set! Whereas with other methods, if you step away from the analysis for six months and then come back to it, you often have to perform a lot of mental gymnastics in order to remember and understand what was going on. With a single line of STUMPY code, you can compute your matrix profile and &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;stumpy.readthedocs.io&#x2F;en&#x2F;latest&#x2F;Tutorial_STUMPY_Basics.html&quot;&gt;quickly identify motifs (conserved patterns) and discords (potential anomalies) by looking at the minima and maxima&lt;&#x2F;a&gt;, respectively. From there, a slew of rapid post-analyses can be performed using the matrix profile and the subsequent results can help you develop further hypotheses and questions about your data. Additionally, unlike other methods which may be riddled with false positives and false negatives, matrix profiles are exact and don’t require any “training” in order to find patterns. It just works right out-of-the-box!&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-is-the-general-criteria-when-choosing-a-window-size-is-there-some-indicator-to-look-up-when-analysing-a-time-series&quot;&gt;What is the general criteria when choosing a window size? Is there some indicator to look up when analysing a time series?&lt;&#x2F;h4&gt;
&lt;p&gt;That’s a good question. Usually, the window size (i.e., the length of your subsequence or sliding window) should be chosen to be large enough to encompass a potential pattern. This usually requires a little bit of domain knowledge but the academic researchers have found that matrix profiles are not so sensitive to the choice of the window size so long as it isn’t smaller than the subsequence pattern. So, being in the rough ballpark is usually enough. However, since matrix profiles are pretty fast and cheap to compute, your best bet is to simply try several different window sizes, perhaps, by repeatedly doubling your window size and observing where there may be conserved minima&#x2F;maxima across the set of matrix profiles. The academic researchers have also published a paper (which you can download &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.cs.ucr.edu&#x2F;~eamonn&#x2F;PAN_SKIMP%20%28Matrix%20Profile%20XX%29.pdf&quot;&gt;here&lt;&#x2F;a&gt;) detailing a similar approach called a “pan matrix profile” that can help narrow down the search space. So, look out for this new STUMPY feature in an upcoming release!&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-is-semantic-segmentation-in-the-context-of-time-series-what-were-the-problems-in-the-past-with-this-method-and-how-do-you-solve-them&quot;&gt;What is semantic segmentation in the context of time series? What were the problems in the past with this method and how do you solve them?&lt;&#x2F;h4&gt;
&lt;p&gt;In the context of time series, “semantic segmentation” is “the division of a time series into internally consistent areas&#x2F;regimes” or, sometimes, you can think of it as a “special type of clustering with the additional constraint that the elements in each cluster are contiguous in time”. Basically, if you have a time series where the values are repeating periodically within some range and then, in response to some external change or event, the time series shifts into another mostly periodic range so that you are left with two distinct “regimes”, then semantic segmentation may be useful for helping you identify the boundary in between the regimes. Now, methods like “change point detection” exist for detecting changes in various statistical properties of the time series (i.e., the mean or variance) but, fundamentally, we are interested in regimens which are defined by changes in the shapes of the time series subsequences, which can change without any obvious effect on the statistical properties. And this is where matrix profiles come into play. By simply using the information stored within your matrix profile, you can automatically identify and label these boundary regions in a systematic way. You can learn more in this illustrative &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;stumpy.readthedocs.io&#x2F;en&#x2F;latest&#x2F;Tutorial_Semantic_Segmentation.html&quot;&gt;STUMPY tutorial&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;how-does-the-sampling-rate-affect-the-analysis-of-a-time-series-how-often-are-important-patterns-hidden-because-of-a-bad-sampling-method&quot;&gt;How does the sampling rate affect the analysis of a time series? How often are important patterns hidden because of a bad sampling method?&lt;&#x2F;h4&gt;
&lt;p&gt;In general, sampling rate is quite important but it is often independent of the analysis method. If you have a conserved pattern that spans a full minute (i.e., it is a unique shape that is captured within 60 data points spaced one second apart) but you only collect a single aggregate data point once every hour, then it is impossible for any method to discover this pattern. Conversely, if you collect a data point once every microsecond then you might run out of storage space or lack the ability to analyze this large data set after 5 years. Unfortunately, in either case, having the best algorithms and the fastest hardware will not help you fix poor sampling. Or, as they say, “garbage in, garbage out”.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1--71VCPSQe2aIyw49RucHCQ.png&quot; alt=&quot;&quot; &#x2F;&gt;Source: &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;stumpy.readthedocs.io&#x2F;en&#x2F;latest&#x2F;Tutorial_Time_Series_Chains.html&quot;&gt;Stumpy documentation&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;stumped-is-the-distributed-version-of-stump-and-it-is-implemented-using-dask-why-have-you-chosen-dask-over-other-solutions-to-implement-stumped&quot;&gt;STUMPED is the distributed version of STUMP and it is implemented using Dask. Why have you chosen Dask over other solutions to implement STUMPED?&lt;&#x2F;h4&gt;
&lt;p&gt;As a research scientist, one of my pet peeves is software that is slow or that takes way too much time and effort to install. So, it was imperative for STUMPY to have minimal dependencies, be easy to install, and also be fast and scalable. Initially, when we prototyped STUMPY, everything was written using NumPy and SciPy and this worked well for time series that contained around 10K data points. However, we noticed that not all of the threads on our machine were being used (due to the GIL) and things started to take forever as we increased the length of our time series. At the time, Cython was a popular option for releasing the GIL but it seemed really hard to maintain from a packaging perspective and the coding style never felt “Pythonic”. In contrast, we had starting hearing a lot of great things about Numba’s ability to JIT-compile Python code into performant machine code and so, within two days, we were able to parallelize STUMPY using Numba and leverage all of the compute power available on our local server. For data scientists, this is great and usually sufficient for small to medium-sized data sets but, naturally, we starting thinking about distributed computing. Dask is a wonderful Python package that offers scalable analytics, can be easily distributed to over a thousand servers, and has a large user community. Additionally, we knew that Dask interoperated well with Numba and so, within five days, we were able to go from a single server to distributing our matrix profile computation across a 32 server Dask cluster. While other solutions currently exist for distributed computing, we really liked that Dask was lightweight, heavily battle-tested, and was supported by knowledgeable maintainers who had the right vision. While STUMPY does not leverage Dask’s “big data collections” (i.e., parallel arrays and dataframes), the robust dynamic task scheduling used by STUMPY is well beyond experimental.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;was-gpu-compatibility-challenging-to-integrate-in-the-project&quot;&gt;Was GPU compatibility challenging to integrate in the project?&lt;&#x2F;h4&gt;
&lt;p&gt;This is a great question! In our journey, we carefully assessed the landscape and seriously considered the idea of using PyCUDA, CuPy, TensorFlow, PyTorch, or even writing raw CUDA kernels and interfacing it with Cython. However, these technologies can either be too hard to install, too low level and verbose, too difficult to maintain (or for others to contribute to), or their APIs are simply too unstable. Ultimately, the best solution for adding GPU support was right underneath our noses and we didn’t even need to add any additional dependencies! Because, luckily for us, Numba is also able to JIT-compile Python code to target GPUs. Of course, it is important to point out that since the programming paradigm for GPUs is quite different from CPUs, STUMPY has to maintain separate Python modules that target the different hardware and we’ve had to develop new and unique ways to ensure proper and thorough testing of our software. However, the massive performance benefits gained from leveraging GPUs and not having to switch from Python to writing CUDA is well worth the tradeoffs. If anybody tries to convince you that “Python is slow” then I’d highly recommend trying Numba and Dask as they can easily help take your Python performance scaling to the next level. If you are interested in computing matrix profiles with STUMPY using GPUs then please check out this &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;colab.research.google.com&#x2F;drive&#x2F;1FIbHQoD6mJInkhinoMehBDj2E1i7i2j7&quot;&gt;Google Colab notebook&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;considering-you-have-chosen-numba-for-optimizing-and-parallelizing-computation-have-you-thought-about-using-julia-in-the-future-which-has-built-in-features-for-this-tasks&quot;&gt;Considering you have chosen Numba for optimizing and parallelizing computation, have you thought about using Julia in the future, which has built-in features for this tasks?&lt;&#x2F;h4&gt;
&lt;p&gt;Julia has certainly grown over the years but its adoption has been slow and so we’ve yet to consider it as a viable option. However, given the amount of effort that we’ve put in to keeping our code base easy to read and digest, it shouldn’t be difficult to port STUMPY over to other languages and we’d certainly be open to sharing and collaborating in the future.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;how-do-you-justify-the-comparison-between-the-benchmark-using-256-cpus-stumped-256-against-the-one-using-16-gpus-gpu-stump-dgx2-especially-economically-speaking&quot;&gt;How do you justify the comparison between the benchmark using 256-CPUs (STUMPED.256) against the one using 16 GPUs (GPU-STUMP.DGX2), especially economically speaking?&lt;&#x2F;h4&gt;
&lt;p&gt;The STUMPY README provides rough &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;stumpy.readthedocs.io&#x2F;en&#x2F;latest&#x2F;#performance&quot;&gt;performance benchmarks&lt;&#x2F;a&gt; but the point isn’t to debate whether GPUs are “faster” or “better suited” for computing matrix profiles than CPUs. If you have access to one or more GPUs, then you should definitely use them! However, if you don’t have access to top-of-the-line GPUs or national super computing clusters, STUMPY can still be useful. Benchmarks are always biased and outdated but our goal is to be transparent and to give people a clearer sense of how long their computation might take (depending on the size of their data) and what hardware resources they may need in order to realistically complete their analysis. Otherwise, the user should be able to make an informed decision as to whether or not STUMPY is suitable for their situation. For all intents and purposes, STUMPY is more than “fast enough” and, more importantly, it faithfully reproduces the academic work and users can feel confident that STUMPY can perform equally as well on better hardware and with larger data set! Thanks to Moore’s law, you don’t have to take our word for it. Give STUMPY a try and let us know what you think!&lt;&#x2F;p&gt;
&lt;h4 id=&quot;in-the-paper-presenting-the-stomp-algorithms-an-implementation-in-a-seismologic-dataset-is-shown-working-with-a-really-huge-amount-of-data-and-analysing-it-within-days-how-near-are-we-from-real-time-anomaly-detection-systems-that-analyse-datasets-as-large-at-that-scale&quot;&gt;In the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.cs.ucr.edu&#x2F;~eamonn&#x2F;STOMP_GPU_final_submission_camera_ready.pdf&quot;&gt;paper&lt;&#x2F;a&gt; presenting the STOMP algorithms, an implementation in a seismologic dataset is shown, working with a really huge amount of data and analysing it within days. How near are we from real-time anomaly detection systems that analyse datasets as large at that scale?&lt;&#x2F;h4&gt;
&lt;p&gt;To answer this question, one first needs to clearly define what is meant by “real-time”. Typically, this involves a situation where large amounts of data is being streamed in continuously and at a reasonably high frequency rate. Additionally, when discussing real-time analysis, it is important to identify how much data needs to be collected before the analysis can begin (i.e., is it one data point or do you need to collect 10 days worth of data before you can start) and it is also worth considering whether this is a sliding window analysis (i.e., where the oldest data point is removed as a new data point arrives). I can’t speak directly to the primary research but, in the 100 million data point seismology example, the dataset was actually recorded at 20 Hz and collected over 58 days but the the matrix profile was computed in just over 12 days. In that particular case, the speed of analysis (12 days) was actually faster than the speed of data collection (58 days) and, naturally, if you could initiate your analysis with less data then the matrix profile computation would require substantially less time as well. Of course, this feels more like a batch analysis than a streaming analysis but hopefully the point that we’re trying to make is clear. In fact, the academic researchers have published additional work on how to incrementally update your matrix profile on-the-fly as additional data points are streamed in. This streaming-friendly capability is currently available in STUMPY and more detail can be found in &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;stumpy.readthedocs.io&#x2F;en&#x2F;latest&#x2F;Tutorial_Matrix_Profiles_For_Streaming_Data.html&quot;&gt;this STUMPY tutorial&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;how-do-you-think-stumpy-will-evolve-do-you-have-in-mind-new-features-to-implement-in-the-near-future&quot;&gt;How do you think STUMPY will evolve? Do you have in mind new features to implement in the near future?&lt;&#x2F;h4&gt;
&lt;p&gt;One of the co-founders of Explosion, Ines Montani, gave a &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;speakerdeck.com&#x2F;inesmontani&#x2F;let-them-write-code-keynote-pycon-india-2019&quot;&gt;wonderful talk at PyCon India 2019&lt;&#x2F;a&gt; titled “Let Them Write Code” where she identified that ‘Good tools help people do their work. You don’t have to do their work for them. Worst developer experiences: tools that want to be “fully integrated solution”’, which I think embodies our approach to developing STUMPY. We have purposely limited the scope of STUMPY and stayed laser-focused on making our code base rock solid, performant and well tested, and super user-friendly. While it may be tempting to over-simplify time series analysis and offer additional things like data cleaning or custom visualization tools all in one package, we want to enable all of our users to really think through their analysis approach rather than relying on a package to make false assumptions about their data, which is more than likely to be wrong anyways. To that extent, STUMPY has already achieved its goal in providing an efficient way for users to compute matrix profiles and that is scalable on a wide variety of hardware. Additionally, there has been a lot of interest in &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;stumpy.readthedocs.io&#x2F;en&#x2F;latest&#x2F;api.html&quot;&gt;computing matrix profiles with non-normalized Euclidean distances&lt;&#x2F;a&gt; (as opposed to z-normalized Euclidean distances) and so we’ve added a suite of new features that addresses these needs and you can check out our &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;TDAmeritrade&#x2F;stumpy&#x2F;issues&quot;&gt;current backlog of feature enhancements on our public Github page&lt;&#x2F;a&gt;. There is still a lot of work that needs to be done to socialize the matrix profile approach, to educate others through public talks and tutorials that use real-world examples, and to continue building and fostering a transparent and supportive community. Of course, this will take time and is easier said than done but we’re making progress everyday.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;are-there-any-books-you-recommend-reading-on-the-topic&quot;&gt;Are there any books you recommend reading on the topic?&lt;&#x2F;h4&gt;
&lt;p&gt;Unfortunately, there aren’t any books on the topic yet but, for starters, readers may be interested in exploring the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;stumpy.readthedocs.io&#x2F;en&#x2F;latest&#x2F;tutorials.html&quot;&gt;STUMPY tutorials&lt;&#x2F;a&gt; or watching this &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=xLbPP5xNIJs&quot;&gt;STUMPY video&lt;&#x2F;a&gt; (hosted by the Stitch Fix Algorithms team) as they provide a balanced mixture of background information, relevant context, and technical detail to help you develop the right intuition. Additionally, I strongly recommend skimming the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.cs.ucr.edu&#x2F;~eamonn&#x2F;MatrixProfile.html&quot;&gt;plethora of articles published by Eamonn Keogh’s group&lt;&#x2F;a&gt;. They’re actually a pleasure to read and I continually learn more each time I re-read these foundational papers.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;where-can-readers-find-you-and-where-can-they-learn-more-about-stumpy&quot;&gt;Where can readers find you and where can they learn more about STUMPY?&lt;&#x2F;h4&gt;
&lt;p&gt;I blog occasionally &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;seanlaw.github.io&#x2F;&quot;&gt;on my personal website&lt;&#x2F;a&gt; but you can follow me on Twitter @seanmylaw and you can stay up-to-date on the development of STUMPY @stumpy_dev. Additionally, please post all of your STUMPY questions to our &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;TDAmeritrade&#x2F;stumpy&#x2F;issues&quot;&gt;Github issues page&lt;&#x2F;a&gt; as this will help ensure that all user questions are recorded and searchable by others. Also, we’re always looking for new contributors and, especially if you are a tech minority, we’d love to work together with you. And don’t forget to &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;stumpy.readthedocs.io&#x2F;en&#x2F;latest&#x2F;&quot;&gt;share STUMPY&lt;&#x2F;a&gt; with all of your friends and colleagues and let us know how you are using STUMPY!&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Interview with Dask’s creator: Scale your Python from one computer to a thousand</title>
        <published>2019-09-03T00:00:00+00:00</published>
        <updated>2019-09-03T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/interview-with-dasks-creator-scale-your-python-from-one-computer-to-a-thousand/"/>
        <id>https://blog.lambdaclass.com/posts/interview-with-dasks-creator-scale-your-python-from-one-computer-to-a-thousand/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/interview-with-dasks-creator-scale-your-python-from-one-computer-to-a-thousand/">&lt;p&gt;My love for building distributed systems with Erlang, databases and fetching huge volumes of data still lives on. But nowadays I want to have better theoretical and practical tools to understand the data. That is why I have been seriously studying probability, statistics and getting better at Python, numpy, pandas, scikit-learn, scipy and R. If you have read my earlier interviews you are probably aware of this.&lt;&#x2F;p&gt;
&lt;p&gt;That is why I decided to interview Dask’s creator Matthew Rocklin. Dask is a great bridge between the two areas that we specialize at my company &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;lambdaclass.com&#x2F;&quot;&gt;LambdaClass&lt;&#x2F;a&gt;: distributed systems and data science. Dask is a great tool to parallelize python libraries. When you have some spare time I highly recommend that you check its code. Meanwhile I leave you with Matthew’s answers.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;&lt;strong&gt;What is Dask? Why did you create it?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Dask is a Python library designed to parallelize other common Python libraries, like NumPy, Pandas, Scikit-Learn and others. It helps people use Python on either a single multi-core machine, or a large distributed cluster.&lt;&#x2F;p&gt;
&lt;p&gt;People tend to use it either as a “Big Pandas” or “Big NumPy”, or as a lower level library to build their own parallel systems.&lt;&#x2F;p&gt;
&lt;p&gt;Originally we created Dask to parallelize Numpy and Pandas. We quickly found that the internals of Dask were useful for many more things, so we quickly pivoted to exposing the internals as a generic parallel system.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Dask dataframes are a full replacement of pandas dataframes?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;No, the Pandas API is &lt;strong&gt;huge&lt;&#x2F;strong&gt; , so a full replacement is nearly impossible.&lt;&#x2F;p&gt;
&lt;p&gt;That being said, Dask Dataframe does implement the vast majority of popularly used Pandas functionality. Common staples like elementwise, reductions, groupbys, joins, rolling, timeseries, and more operations are all there. Additionally, because Dask dataframes are just a bunch of Pandas dataframes spread around a cluster it’s often pretty easy to convert custom code from Pandas to Dask easily.&lt;&#x2F;p&gt;
&lt;p&gt;It’s also worth noting that Dask != Dask Dataframes. Dataframes only account&lt;br &#x2F;&gt;
for about a third of Dask use out there. Dask goes way beyond just&lt;br &#x2F;&gt;
parallelizing Pandas.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Is there any downside of using Dask dataframes instead of pandas dataframes?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Oh definitely. If Pandas is solving your problem today, please don’t switch to Dask.&lt;&#x2F;p&gt;
&lt;p&gt;As with any distributed system, Dask adds a lot of complexity like network&lt;br &#x2F;&gt;
overheads, function serialization, and longer tracebacks in errors. We do a&lt;br &#x2F;&gt;
lot of work to keep our overhead small, both by keeping Dask lightweight and&lt;br &#x2F;&gt;
taking care of Python usability, but still, if you don’t need to switch, then&lt;br &#x2F;&gt;
don’t.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;How is it different form other distributed computation solutions (eg Hadoop MapReduce, Spark, Storm, Luigi, Airflow)?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Dask is a bit lower level and more generic than those systems, and so can be used to build up similar solutions using existing Python libraries.&lt;&#x2F;p&gt;
&lt;p&gt;For example:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;When we combine Dask with Pandas we get &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;docs.dask.org&#x2F;en&#x2F;latest&#x2F;dataframe.html&quot;&gt;Dask Dataframes&lt;&#x2F;a&gt;, which are comparable with Spark DataFrames&lt;&#x2F;li&gt;
&lt;li&gt;When we combine Dask with Scikit-Learn we get &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;ml.dask.org&quot;&gt;Dask-ML&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;When we combine Dask with Python’s &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;docs.dask.org&#x2F;en&#x2F;latest&#x2F;futures.html&quot;&gt;futures or async&#x2F;await&lt;&#x2F;a&gt; APIs we get a real-time framework, somewhat similar to Storm&lt;&#x2F;li&gt;
&lt;li&gt;When we combine Dask with &lt;em&gt;cron&lt;&#x2F;em&gt; like logic, we get an ETL framework like Airflow or Luigi. In fact, some of the Airflow developers split off and made &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.prefect.io&#x2F;&quot;&gt;Prefect&lt;&#x2F;a&gt; a successor to Airflow which delegates the execution and data movement to Dask&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Additionally, Dask can be combined with other libraries to get novel systems&lt;br &#x2F;&gt;
that aren’t in your list. For example:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;When we combine Dask with Numpy we get a scalable multi-dimensional &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;docs.dask.org&#x2F;en&#x2F;latest&#x2F;array.html&quot;&gt;Dask Arrays&lt;&#x2F;a&gt;.&lt;&#x2F;li&gt;
&lt;li&gt;When we combine Dask with GPU-accelerated Pandas or Numpy like libraries like &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;rapids.ai&quot;&gt;RAPIDS&lt;&#x2F;a&gt; we get distributed GPU-accelerated dataframes and arrays.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Internally, Dask has the scalability of a system like MapReduce or Spark, with&lt;br &#x2F;&gt;
the flexibility of a system like Luigi or Airflow. This combination is nice both when you’re building new systems, and means that Dask gets used in a ton of novel work.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;How does data locality affect the performance of Dask? Does it assume all data is local to workers?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;By data locality you might mean two things (both of which Dask handles well):&lt;&#x2F;p&gt;
&lt;p&gt;1. Where does the data live in some storage system, like S3 or HDFS?&lt;&#x2F;p&gt;
&lt;p&gt;Dask is more than happy to query a data-local storage system like HDFS,&lt;br &#x2F;&gt;
find out where all the data lives, and target computations appropriately.&lt;&#x2F;p&gt;
&lt;p&gt;However, this kind of workload is becoming increasingly rare. More often&lt;br &#x2F;&gt;
people are using storage systems that prefer global accessibility over data&lt;br &#x2F;&gt;
locality, so this matters less and less these days in practice.&lt;&#x2F;p&gt;
&lt;p&gt;2. Once data is in memory, can Dask avoid moving it around?&lt;&#x2F;p&gt;
&lt;p&gt;Dask thinks a lot about where to run computations, and avoiding needless&lt;br &#x2F;&gt;
data communication is a big part of this decision. Sometimes we do need to&lt;br &#x2F;&gt;
move data around, but yes, Dask certainly avoids this when possible.&lt;&#x2F;p&gt;
&lt;p&gt;Moreover, because Dask gets used with a &lt;strong&gt;wide&lt;&#x2F;strong&gt; variety of workloads, our&lt;br &#x2F;&gt;
scheduling heuristics have had to evolve quite a bit over the years. It’s very&lt;br &#x2F;&gt;
rare for us to find problems today on which Dask’s data locality heuristics&lt;br &#x2F;&gt;
don’t respond optimally.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What is the biggest Dask cluster you have seen in production?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;One thousand Windows machines.&lt;&#x2F;p&gt;
&lt;p&gt;Dask gets used on some of the world’s largest super-computers (I was&lt;br &#x2F;&gt;
logged into &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.olcf.ornl.gov&#x2F;summit&quot;&gt;Summit&lt;&#x2F;a&gt;, the worlds largest super computer, just a few hours ago), and is deployed routinely on all major clouds.&lt;&#x2F;p&gt;
&lt;p&gt;However, Dask also scales down nicely. You can also just &lt;em&gt;import dask&lt;&#x2F;em&gt; and run it on a thread pool in a single python process or Jupyter notebook. As we like to say, &lt;em&gt;“The median cluster size is one”&lt;&#x2F;em&gt;. Dask is pure-Python, and super-lightweight if it needs to be. You can just &lt;code&gt;pip install dask&lt;&#x2F;code&gt; and it ships with the popular Anaconda distribution, which is deployed on millions of machines around the world.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;The Dask scheduler and Dask worker architecture, implementation and protocol was inspired by any other project?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The central scheduler + distributed worker architecture is pretty common today. It’s a pragmatic choice for systems that want to scale between 1–1000 nodes.&lt;&#x2F;p&gt;
&lt;p&gt;So sure, Dask was inspired by other projects. All of them :). Notably, Dask tries hard not to reinvent too much. We rely a ton on other infrastructure within the Python ecosystem. We use Tornado and asyncio for concurrency and peer-to-peer networking, Numpy, Pandas, and Scikit-learn for computation, and other Python APIs like concurrent.futures and joblib for user APIs.&lt;&#x2F;p&gt;
&lt;p&gt;Dask is really just a smashing together of Python’s networking stack with its&lt;br &#x2F;&gt;
data science stack. Most of the work was already done by the time we got here.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Which do are for you the most interesting frameworks, tools or libraries implemented on top of Dask and why?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I’ll list a few interesting frameworks, but there are a ton out there these days:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;xarray.pydata.org&quot;&gt;Xarray&lt;&#x2F;a&gt; is a library commonly used to study Earth system data, like the climate, meteorology, oceanography, satellite imagery, and more. It’s really gratifying to see people use Dask to finally be able to analyze these huge climate science simulations, and help us better understand the planet.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;prefect.io&quot;&gt;Prefect&lt;&#x2F;a&gt; provides a bunch of niceties on top of Dask for common Data Engineering or ETL workloads, similar to Airflow&#x2F;Luigi. We got these feature requests constantly when we were starting out but declared them out of scope. It was great to have another project come by, take that feature set, and implement it way better than we ever could.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;epistasislab.github.io&#x2F;tpot&quot;&gt;TPot&lt;&#x2F;a&gt; is a library for automatic machine learning. You give it a dataset, and it tries out a bunch of models and pre-processors to find a good model. TPot existed well before Dask, and it has really gnarly parallelism internally, which makes it hard for non-experts to accelerate. Fortunately the TPot and Dask developers were able to get this going in a weekend, and now you can scale out this search with Dask on whatever parallel hardware you have.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;rapids.ai&quot;&gt;RAPIDS&lt;&#x2F;a&gt; is a GPU-accelerated data science stack by NVIDIA. They were building out their own fast GPU implementation of Pandas and Numpy and wanted something to solve the multi-node problem for them. Dask was able to step in, handle all of the distributed communication, scheduling, and load balancing, and then step aside while NVIDIA’s fast GPU algorithms took over. (disclaimer, this is my current employer).&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;Could you please tell us about the work you are doing at NVIDIA to offload Dask computations to the GPU?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Yeah, RAPIDS is really exciting. It turns out that GPUs are good for things other than graphics and deep learning. They’re surprisingly effective at accelerating more traditional computing in data science (and actual science). Operations like dataframe joins, CSV parsing, FFTs, text processing, and more can often be accelerated 10x-200x. Historically you had to know C and CUDA to use these libraries though, which made them accessible only to somewhat experience software developers.&lt;&#x2F;p&gt;
&lt;p&gt;The RAPIDS project within NVIDIA is wrapping up all of these algorithms in Python, and exposing APIs to data science users that look like drop-in replacements for Numpy&#x2F;Pandas&#x2F;Scikit-Learn.&lt;&#x2F;p&gt;
&lt;p&gt;They use Dask to provide multi-GPU parallelism (some people have many GPUs in a single machine) and multi-node parallelism across a cluster. Dask’s&lt;br &#x2F;&gt;
flexibility, and the fact that it’s pretty unopinionated about what you run as&lt;br &#x2F;&gt;
computation make it the perfect fit. It’s also one of the only task schedulers&lt;br &#x2F;&gt;
out there that run in a non-JVM language, which helps if you use natively&lt;br &#x2F;&gt;
compiled code, like CUDA.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Do you have any book, MOOC or resource that you would recommend to those of us that want to learn more about the implementation of schedulers, concurrency models and distributed systems?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Ha! Sadly no.&lt;&#x2F;p&gt;
&lt;p&gt;Centrally managed distributed schedulers are, unfortunately, not a common topic of research these days. From an academic&#x2F;intellectual level it’s a fairly&lt;br &#x2F;&gt;
simple problem. Most of the difficult parts are in the details of engineering,&lt;br &#x2F;&gt;
which are unfortunately not that interesting to anyone who isn’t building a&lt;br &#x2F;&gt;
distributed scheduler.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Interview with Osvaldo Martin about Bayesian Analysis with Python</title>
        <published>2019-02-11T00:00:00+00:00</published>
        <updated>2019-02-11T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/interview-with-osvaldo-martin-about-bayesian-analysis-with-python/"/>
        <id>https://blog.lambdaclass.com/posts/interview-with-osvaldo-martin-about-bayesian-analysis-with-python/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/interview-with-osvaldo-martin-about-bayesian-analysis-with-python/">&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-NpQf9G3ZdnMXLT-QT3sErQ.jpeg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Like our &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;notamonadtutorial.com&#x2F;inteview-with-thomas-wiecki-about-probabilistic-programming-and-pymc-66a12b6f3f2e&quot;&gt;previous interviewee&lt;&#x2F;a&gt; &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;aloctavodia&quot;&gt;Osvaldo Martin&lt;&#x2F;a&gt; is one of the developers of PyMC3 and ArviZ. He is a researcher specialized in Bayesian statistics and data science. He will be speaking at our &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;lambdaclass&#x2F;buzzconf&quot;&gt;BuzzConf&lt;&#x2F;a&gt; this year. I hope you like this interview as much as we did!&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h4 id=&quot;can-you-tell-us-how-data-analysis-has-improved-over-the-years&quot;&gt;Can you tell us how data analysis has improved over the years?&lt;&#x2F;h4&gt;
&lt;p&gt;This is not a simple question to answer, specially if we take into account that we have been doing data analysis from ancient times. The analysis of astronomical data has a long tradition it even predates (modern) science. For most of our history it was motivated by the many different religious liturgies we have invented over the centuries and the more &lt;em&gt;grounded&lt;&#x2F;em&gt; need of improving and controlling the food production. Fast-forwarding thousand of years one can argue that the data-driven studies of astronomers like Tycho Brahe had a decisive impact on setting up the scientific revolution. Astronomy and astrology were not fully separated by that time, but Brahe, based on his observations and experience already thought that astrologists were just charlatans and he maintains that the planets and stars have null influence over the human affairs. If that’s not a Data Scientist, who is?&lt;&#x2F;p&gt;
&lt;p&gt;So the “big thing” we are living now is not that we suddenly realize data is important, we have already known that for centuries, the difference is that now we have tons of available data from scientific disciplines like Biology and Astronomy, just to name two, and from daily interactions with streaming platforms, social networks, cell phones, and sensors all around us. Computers have made this possible by increasing our capacity to storage, process and transmits information by several order of magnitude, and perhaps equally important computers has also changed the way we ask questions and provide answers. There is a whole array of new methods to analyze and generate data, that are impractical without computers. Indeed, the modern practice and development of Bayesian methods have been profoundly influenced by the computers and computational methods up to the point that modern Bayesian statistics IS computational statistics. The only reason we are talking now about probabilistic programming, Machine Learning and Data Science is because we have cheap and fast computers.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;can-you-tell-us-in-brief-how-pymc3-and-arviz-help-with-bayesian-analysis&quot;&gt;Can you tell us in brief how PyMC3 and ArviZ help with Bayesian Analysis?&lt;&#x2F;h4&gt;
&lt;p&gt;PyMC3 is a probabilistic programming language offering two main components: a very clear syntax to define probabilistic models and a powerful set of methods to solve those models, mainly Markov Chain Monte Carlo and Variational Inference. Ideally the methods to solve probabilistic models should be Universal in the sense that they should be able to solve any valid probabilistic model. Unfortunately, even when current methods are very powerful they do not always work as we like, some models are still very difficult or slow to solve. Thus an important step in Bayesian Analysis is to check that inference was done properly. And this is one the motivations for creating ArviZ, a Python package for exploratory analysis of Bayesian models. ArviZ Includes functions for posterior analysis, sample diagnostics, model checking, and comparison. ArviZ works hand-in-hand with PyMC3, and other probabilistic programming language, like PyStan, emcee, Pyro, etc. Where the aim of the probabilistic programming languages is to make it easy to build and solve Bayesian models, the aim of the ArviZ library is to make it easy to process and analyze the results from the Bayesian models.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;can-you-explain-some-of-the-main-concepts-of-bayesian-analysis&quot;&gt;Can you explain some of the main concepts of Bayesian Analysis?&lt;&#x2F;h4&gt;
&lt;p&gt;Bayesian analysis can be summarized in just two concepts. Use probability distributions to represents the uncertainty in your model parameters. Then use Bayes theorem to update those probabilities given the data you have. All the rest derives from these two main concepts. Other concepts that are important to the practice of Bayesian Analysis are shared with other modeling approaches, like evaluating if models make sense by comparing their output against the data and the available domain-knowledge.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;why-do-you-like-working-with-data&quot;&gt;Why do you like working with data?&lt;&#x2F;h4&gt;
&lt;p&gt;I am not sure I “like” working with data, working with data is hard, data collection, data wrangling, cleaning and processing is generally time consuming. Data &lt;em&gt;per se&lt;&#x2F;em&gt; is not important what really matters is understanding phenomena, solving problems and designing better tools to solve problems. What happens is that data is essential to all these tasks. To answer any question in a scientific way you will need data at some point, for some problems you can progress a lot with just theory, but eventually you will need some data. The only scientific discipline that can avoid using data is pure mathematics. And for that reason many people do not think that mathematics is a scientific discipline, or if so they classify it as a logical science and not a factual one.&lt;&#x2F;p&gt;
&lt;p&gt;Everyone is talking about the data deluge and thus is easy to miss that data is produced by someone and that producing data is not always easy or cheap. Even when we have access to pre-existing data it may need further processing or it may not be suitable to answer our questions and thus we may need to generate data from scratch. In general, answering specific questions requires generating specific data under specific conditions. Just a few years ago many computational biologists and bioinformaticians believed that by extracting biological information from scientific journals and databases we will be able to build very reliable models of the cell. It turns out that while this is a good idea, is not that easy as its sounds and not applicable to every question. Papers are behind paywalls, written in formats not that easy to analyze programatically, experiments are performed under so many different conditions that integrating the information coherently is closer to a bad breakup than a romantic dinner, some experimental results are too noisy or the experimental design is flawed, observations can be contradictory, information in databases need to be further curated, etc.&lt;&#x2F;p&gt;
&lt;p&gt;To many people Data Science have put “data” in the spotlight, but science has always been data-driven. Charles Darwin was responsible from one of the most elegant scientific theories, and one of the most misrepresented ones. He spent years and years collecting data, not for the sake of having data but to try to make sense of the diversity and complexity of living organisms. Nowadays evolutionary biologists still spend a lot of time producing and gathering data from carefully designed observations, experiments and simulations in order to refine evolutionary ideas.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-are-the-advantages-and-disadvantages-of-using-python-over-other-languages-for-data-analysis&quot;&gt;What are the advantages and disadvantages of using Python over other languages for data analysis?&lt;&#x2F;h4&gt;
&lt;p&gt;One of the reasons I use Python is that it is a general purpose language, and while I spend a lot of time on data-analysis related stuff I also use Python to solve other types of problems. I learned to program during my PhD without formal training but with the help of great books like Think Python by Allen Downey and A Primer on Scientific Programming with Python by Hans Petter Langtangen, and also helped in many different ways by a large, welcoming and enthusiastic Python community.&lt;&#x2F;p&gt;
&lt;p&gt;At the time of my PhD most of my “coding” was about automating boring stuff and gluing specific scientific packages in order to perform molecular simulations and very very simple data-analysis problems. I used to do that using a collections of poorly documented (and probably poorly written) bash scripts. With the time this approach turns to be too restrictive, so I tried to learn Fortran and C, but I found them overcomplicated for most of the tasks I wanted to solve at the moment, and only very useful for a subsets of them… until I find Python! As someone said Python is not the best programming language for almost any task but is good enough for most of them as I would discover with the pass of time and with every new project that involved Python. One super tedious task for me at that moment was updating plots. I used a software with a GUI (and open source clone of a reeeeeally expensive proprietary scientific plotting software). Updating plots after re-running a simulation or noticing a mistake or getting feedback from my advisors or peers was a lot of work. Somehow, I did not remember the exact moment I found matplotlib, that was a deal-breaker for me and one of the reasons to learn even more Python.&lt;&#x2F;p&gt;
&lt;p&gt;Another epiphany was when I re-wrote a small piece of software a colleague kindly passed to me. Like me, my colleague was a non-computer-scientist. This code was a collection of bash scripts and a Fortran main program. I started with the bash scripts, instead of running several bash scripts I unified all of them into a collection of coherent Python functions. This already make my workflow easier and I was already super-happy, then I decide to change the Fortran code, at first this was mainly an exercise to challenge myself to learn more NumPy and Scipy. After many attempts to get this right (I never truly learned Fortran) I got a working Python version of the code, this code was not only much more shorter, easier to read and more modular, but to my surprise it was also 10x faster! Most of the speed-up come by replacing a lot of Fortran code with a SciPy call and a couple of NumPy array operations. And this was an important lesson to me. Do not re-invent the wheel, there are many specialized, well-tested, efficient routines out there, use them! Because while Python is &lt;em&gt;slow&lt;&#x2F;em&gt; not being proficient programmer in a &lt;em&gt;fast&lt;&#x2F;em&gt; language like Fortran or C can be even slower!&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-aspects-of-doing-bayesian-analysis-with-python-do-you-feel-are-tricky-to-get-past&quot;&gt;What aspects of doing Bayesian Analysis with Python do you feel are tricky to get past?&lt;&#x2F;h4&gt;
&lt;p&gt;For newcomers getting a fully functional Python environment can sometimes be tricky. Anaconda (a scientific Python distribution) and conda (a package manager) have helped a lot to get things installed properly, specially for Windows users.&lt;&#x2F;p&gt;
&lt;p&gt;When I show PyMC3 code to people most of them seem surprised by how much you can do with a few lines of codes. I even get responses like “that’s not programming” which I totally agree is just using a programming language to give instructions to a computer and get things done ;-) The challenge when using PyMC3 is then not so much on the programming-side but on the mental-modeling side, at first most people has problems figuring out how to express they problems in terms of a probabilistic model. This is a matter of practice and the creative part of the job. In the book I tried to show many examples of different models to help ease this transition to thinking probabilistically. This is something that needs practice, knowing that most pop-songs are built from the same chord progression of 3 to 4 chords that’s not automatically makes you a pop-star.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;your-take-on-the-data-analysis-environment-with-regards-to-innovations-in-it-the-knowledge-and-skills-gap-and-software-development-how-do-you-think-the-tech-landscape-is-changing&quot;&gt;Your take on the data analysis environment with regards to innovations in it, the knowledge and skills gap, and software development. How do you think the tech landscape is changing?&lt;&#x2F;h4&gt;
&lt;p&gt;My impression is that we now have something that was completely unimagined just a couple of decades ago: the popularization of very powerful computer methods. One of the side effects of the computer revolution is that any person with a modest understanding of a programming language like Python now has access to a plethora of powerful computational methods for data analysis, simulations, and other complex tasks. I am totally in favor of this, is one of my motivation to work on Open Source Software projects and to give free courses at the University. But I also recognize that this should be an invitation to us, as a community, to be extra careful about these methods not only to be able to apply them correctly from a technical point of view and to avoid making false claims but also from an ethical and democratic perspective. Otherwise we face the risk of giving too much control over important decisions to an increasingly reduced group of rich and powerful people and corporations, something that I am afraid is already happening and with disastrous consequences for those of us that not are part of the super-rich club. To turn this popularization of methods into a true democratization we need not only to make the methods accessible we also need to make other resources widely available. If the majority of the data generating processes, the data itself and the most powerful hardware is controlled by a small group then, we are not aiming for a true democracy we are just spending a lot of resources into training a high skilled work-force to serve the interest of a few and that is just a technocratic version of an oligarchy.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>A Pythonist finds a new home at Clojure land</title>
        <published>2017-04-14T00:00:00+00:00</published>
        <updated>2017-04-14T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/a-pythonist-finds-a-new-home-at-clojure-land/"/>
        <id>https://blog.lambdaclass.com/posts/a-pythonist-finds-a-new-home-at-clojure-land/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/a-pythonist-finds-a-new-home-at-clojure-land/">&lt;p&gt;Welcome back to another interview of &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;notamonadtutorial.com&#x2F;&quot;&gt;Not a Monad Tutorial&lt;&#x2F;a&gt;. In this opportunity I decided to interview Facundo Olano, a friend, a teammate, and a developer with a &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;facundoolano&quot;&gt;diverse experience&lt;&#x2F;a&gt;. We talked about Python, Node.js, Clojure, Common Lisp and software development in general. Something worth mentioning is that this is not the first time Python and Clojure get mentioned together at Not a Monad Tutorial. &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;notamonadtutorial.com&#x2F;indie-languages-interview-pixie-and-timothy-baldridge-cadbc36418dc&quot;&gt;Timothy Baldridge implemented Pixie&lt;&#x2F;a&gt;, a Lisp language inspired by Clojure, in Python.&lt;&#x2F;p&gt;
&lt;p&gt;Vote and discuss at &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;lobste.rs&#x2F;s&#x2F;nz28ef&#x2F;pythonist_finds_new_home_at_clojure_land&quot;&gt;lobsters&lt;&#x2F;a&gt;, &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;programming&#x2F;comments&#x2F;65ct5j&#x2F;a_pythonist_finds_a_new_home_at_clojure_land&#x2F;&quot;&gt;reddit&lt;&#x2F;a&gt;, &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=14114624&quot;&gt;hn&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-4XmtTGqxc82DyQwcpmr9pw.jpeg&quot; alt=&quot;&quot; &#x2F;&gt;A wallpaper I created for my OpenBSD laptop. Lisp, BSD, Erlang, Rust. We live in the best of all possible worlds.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;You are quite in love with Python. Why is that?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Heh, love is a big word, isn’t it? But, yes, I guess for a while I had pretty strong feelings for Python. I still have, to a degree. If you’re going with the love metaphor let’s say I had a series of shitty girlfriends that didn’t treat me all that well and I didn’t even noticed it, then I meet this great woman, this caring and interesting woman that listens to what I have to say and doesn’t, um, force me to wrap everything in class.&lt;&#x2F;p&gt;
&lt;p&gt;Seriously speaking, I learnt to program in college, arguably at an old age, and there they taught me Pascal (because some folks are convinced that’s still the best way to teach good programming manners), then a fair amount of C++, and lots of Java. Everybody was in love with Java over there and they kind of gave you the impression that that was it: this is as good as programming gets, this is what will get you a job and it’s so much better than C++, which I already knew wasn’t pleasant to work with. So I got a job programming Java and I loved it, I read all the books, &lt;em&gt;Refactoring&lt;&#x2F;em&gt; and the Design Patterns stuff. But then I had to quit because I was getting behind in College, I got some free time back and I was curious about Python because some former coworkers and other students talked heavens about it.&lt;&#x2F;p&gt;
&lt;p&gt;I got this book &lt;em&gt;Learning Python&lt;&#x2F;em&gt; and went through it top to bottom one summer. I guess I felt scammed, in a way: how come nobody told me about this? I felt I had been wasting my time writing XMLs and type hierarchies, while there was a simpler way to do about everything: dynamic typing gave me polymorphism for free, the data structures were built-in and had literals, string manipulation was just amazingly easy, you could have standalone functions and pass them like values, a lot of the Java design patterns were reduced to one-liners… I guess one of the take-aways of the experience was that sometimes your peers know better than your teachers (or your bosses).&lt;&#x2F;p&gt;
&lt;p&gt;But besides it feeling better than Java, what’s still unique for me about Python is the set of principles that are best expressed in the &lt;em&gt;Zen of Python&lt;&#x2F;em&gt;. It felt like every bit of the language followed those principles and it encouraged you to do the same with your own code; when in doubt about how to tackle something, the Zen of Python would tell you the right way to go. I still follow most of those ideas when I program, regardless of the language.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Before learning Clojure, your&lt;&#x2F;strong&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;facundoolano.wordpress.com&#x2F;2012&#x2F;01&#x2F;31&#x2F;first-impressions-on-common-lisp&#x2F;&quot;&gt;&lt;strong&gt;first experience with a Lisp&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;strong&gt;was with Common Lisp. From what I have talked with you about learning Common Lisp I could sum up that it was a bittersweet experience. Why didn’t you like Common Lisp?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I got interested in Lisp after reading Paul Graham essays. Then there was that bit of Eric Raymond about the religious experience of &lt;em&gt;getting&lt;&#x2F;em&gt; Lisp. After what I went through with Java and Python I made a point about always looking for chances to learn new languages.&lt;&#x2F;p&gt;
&lt;p&gt;But it just didn’t feel right, in a lot of ways it was the opposite of what I loved about Python: the code was very difficult to read (not because parens or prefix notation, just because it was filled with symbols), the operator set was huge, with really weird names and not dynamic at all, I remember it having like six equality operators for different types. Add to that it’s an old language with a small community and zero chances of getting a job using it, it made no sense to invest much time in it, since it wasn’t fun either. But fortunately there are many Lisps and I already knew right then I’d give a chance to Clojure eventually.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Why was the experience with&lt;&#x2F;strong&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;facundoolano.wordpress.com&#x2F;2016&#x2F;03&#x2F;20&#x2F;first-impressions-on-clojure&#x2F;&quot;&gt;&lt;strong&gt;Clojure different&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;strong&gt;? As&lt;&#x2F;strong&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;programming&#x2F;comments&#x2F;65ct5j&#x2F;a_pythonist_finds_a_new_home_at_clojure_land&#x2F;dg97mao&#x2F;&quot;&gt;&lt;strong&gt;stesch said in reddit&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;strong&gt;, Clojure land is in the Java sea. Those are strange waters for a pythonist. What did you like about it?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;For starters, it addresses everything that put me off about Common Lisp. It’s more readable. The operator set is big, but very consistent and polymorphic: all core functions work as expected with every data type. It has a strong focus on immutability and functional programming, which CL hadn’t. But it’s also a very pragmatic language: it doesn’t ask you to learn category theory or to know what a functor is in order to get why you would benefit from it. That’s the approach to functional programming that I like. I’m not saying theory isn’t important, just that I’m the kind of programmer whose interest you won’t catch with theory detached from practice. Also, the community is very active and welcoming, and the fact that it’s a JVM language makes it get a lot of attention, considering it’s a Lisp dialect.&lt;&#x2F;p&gt;
&lt;p&gt;Another thing that made me feel at home about Clojure is that it has a strong philosophy and you can tell its design has been driven by it. The philosophy is not the same as the one in Python, and now I understand that that doesn’t really matter. I want consistently opinionated languages rather than bags of features you can bend to program in ten different ways; &lt;em&gt;what&lt;&#x2F;em&gt; the philosophy is is secondary to the fact that &lt;em&gt;there is&lt;&#x2F;em&gt; a philosophy.&lt;&#x2F;p&gt;
&lt;p&gt;The talks by Rich Hickey are enlightening, and every time I watch one I feel like I improved my understanding of the language, even if the talk isn’t about Clojure itself. Kind of like a Zen of Clojure.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What do you think about the JVM and its community?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I’ve been working to suppress the strong feelings I used to have against Java. I still dislike it as a language and the way of programming it encourages, though. I revisited it a couple of years ago to write some Android apps and nope, still not my cup of tea. Everything just feels convoluted and over engineered, I’d constantly think how much simpler this is in Python or Perl or Ruby or JavaScript. It’s a very programmer-centric view, I’m aware, mostly based in what I enjoy in the day to day, which doesn’t necessarily make sense from a business perspective. There’s a reason why big companies go to Java; I recognize there’s a lot of top of the class software written in it, and it’s fast. I don’t have the background to make a serious assessment of the JVM but I’m pretty sure it’s an amazing piece of software.&lt;&#x2F;p&gt;
&lt;p&gt;The good thing is the JVM can now host other languages, and something as weird as a functional Lisp dialect is fairly close to being popular and you can even get a job with it. That’s a lot to say.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What do you miss from Python?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Sometimes I say, half-joking, that programming is a branch of literature. In that sense I value elegance and succinctness, I think there can be beauty in code, but I also know that beauty is completely subjective and I can’t argue about one style being better than another. I’m not talking about readability, that’s important and it’s more or less measureable; I’m talking about aesthetics. I think Python had that kind of beauty for me, which is harder to get in Clojure. Clojure can be more expressive and it’s more powerful but can easily get ugly if you don’t have a lot of discipline. Again: all subjective stuff.&lt;&#x2F;p&gt;
&lt;p&gt;Truth be told, I don’t think I miss Python all that much, at least not while I’m doing Clojure. JavaScript is a different story, JavaScript is a mess. But still, if you bend it in the right directions, it can be a fairly decent functional language. I noticed that Python can’t, there’s stuff that just doesn’t work that way (lambdas come to mind), and that probably would annoy me nowadays. So I guess I’m not married to any language anymore. That’s a good thing, right?&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Your most known projects in Github are written in JavaScript. Do you like coding in JavaScript?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;JavaScript is Frankenstein. As Douglas Crockford showed in &lt;em&gt;The Good Parts&lt;&#x2F;em&gt; years ago, there’s a lot of awful bits and you &lt;em&gt;have&lt;&#x2F;em&gt; to subset the language. That’s gotten worse, because they keep adding stuff to it (some of it really cool, some of it to make it look like Java), and they can’t remove the old stuff, so it has become one of those things you have to agree upfront on which parts you’re going to use and which parts are banned, kind of like C++.&lt;&#x2F;p&gt;
&lt;p&gt;But, as said, if you pick the right subset it can be good. &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;eslint.org&#x2F;&quot;&gt;eslint&lt;&#x2F;a&gt; helps. If you ban &lt;em&gt;this&lt;&#x2F;em&gt; and &lt;em&gt;new&lt;&#x2F;em&gt; and treat objects like maps, most problems go away. If you’re bold you can even pick a set of eslint rules to force immutability. And then there’s &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;ramdajs.com&quot;&gt;Ramda&lt;&#x2F;a&gt;. That’s the secret sauce; it makes data manipulation a joy, in some spots I even like its functions better than their Clojure counterparts. The async stuff is weird. I still can’t make my mind if Promises are better than callbacks, but I got used to them. It’s a lousy way of hiding concurrency, though.&lt;&#x2F;p&gt;
&lt;p&gt;I have a fair amount of Node.js projects in GitHub, yes. That’s the killer thing about Node.js: NPM, its ecosystem, this philosophy of small unix-y modules. You have an idea, you write up a file and you’re two commands away from publishing it and getting feedback. No other language I’ve tried reduces the boilerplate to share your work that much. That’s a real boost for Open Source and Collaboration. I recognize it has some bad side effects (mixed module quality, left-pad, etc.), but those are much less than the advantages. I remember Python dependency and publishing story being way more cumbersome.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;In the last few months you started using Emacs. What do you think about it?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I’ve been putting off a blog post about that. I know I’m glad that I decided not to learn Emacs at the same time that I was learning Clojure. That could have caused me to drop both things. I think there’s this idea that you can’t learn a Lisp without Emacs, and that may have been true before, but now that there’s &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;shaunlebron.github.io&#x2F;parinfer&#x2F;&quot;&gt;parinfer&lt;&#x2F;a&gt; you can safely hack Lisp on most modern editors. Hardcore lispers may not notice how amazing of a contribution to the community this is, it makes it dramatically easier to get started with Lisp and reachable to people that wouldn’t even consider using something like Emacs.&lt;&#x2F;p&gt;
&lt;p&gt;I pleasantly used Clojure with Sublime and parinfer for almost a year. Then I started reading &lt;em&gt;Coders at work&lt;&#x2F;em&gt; and saw all these amazing hackers mentioning Emacs again and again. It felt like I was missing out on something, so I decided I should give it a try, as a weekend project.&lt;&#x2F;p&gt;
&lt;p&gt;And it was a hell of weekend. The first lesson I learned was that I was a shitty typist, but that got better as the days went by. Fortunately it was a quiet week at work because I could barely get anything done for a while. One interesting note is that I went through this process with JavaScript, so I could make Emacs my daily editor at work. It wasn’t until I felt comfortable with the editor that I tried it with Clojure. And then I realised my Clojure experience wasn’t complete before. It probably goes the other way around: you get the best out of Emacs when you’re doing Lisp.&lt;&#x2F;p&gt;
&lt;p&gt;I’m not sure I’d recommend it to every programmer, though, specially if they work on a single language that already has a killer editor. Learning Emacs is a really fun and enriching experience, but you have to be prepared to spend a lot of time tuning the editor at first and acknowledge the fact that &lt;em&gt;your Emacs config will be the project of your life&lt;&#x2F;em&gt; , as I read somewhere.&lt;&#x2F;p&gt;
&lt;p&gt;I know I love those times when you realise you are doing something repeatedly, that could be done by a command, and you write it (or, better, you find that someone else wrote it already). That’s when it pays off.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Is there any particular Clojure library that you would specially recommend?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;jonase&#x2F;kibit&quot;&gt;kibit&lt;&#x2F;a&gt; I find amazing because it’s not only a useful linter (like &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;jonase&#x2F;eastwood&#x2F;&quot;&gt;eastwood&lt;&#x2F;a&gt; also is), but it teaches you the standard library as you go, which can be a little bit overwhelming when you are starting out. &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;bhauman&#x2F;lein-figwheel&quot;&gt;Figwheel&lt;&#x2F;a&gt; is another obvious one that made a big difference for me when I started to play with ClojureScript.&lt;&#x2F;p&gt;
&lt;p&gt;The &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;macchiato-framework.github.io&#x2F;&quot;&gt;Macchiato framework&lt;&#x2F;a&gt; is doing a great job of bringing Node.js to ClojureScript.**** I noticed some people don’t take Node.js very seriously, but being Clojure a language that makes such a strong point of leveraging the host platform, the world of possibilities available in NPM can’t be disregarded. There’s another often overlooked fact: you’re much more likely to find a functional programming enthusiast nowadays doing Node.js than in the Java world, so shortening that gap can only bring good to the community.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;candid82&#x2F;joker&quot;&gt;Joker&lt;&#x2F;a&gt; is another great one. It’s a Clojure interpreter written in Go, but what I’ve found incredibly useful is how it works as a linter, which you can easily hook to an editor. It really improved my workflow, early catching typos and bugs while I program.&lt;&#x2F;p&gt;
&lt;p&gt;Finally, in the testing related work I’ve been doing recently I’ve found &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;jakemcc&#x2F;lein-test-refresh&quot;&gt;lein-test-refresh&lt;&#x2F;a&gt; and &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;weavejester&#x2F;eftest&quot;&gt;eftest&lt;&#x2F;a&gt; to be useful and insightful about how clojure.test and leiningen internals work.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;On your github profile you have many pretty well known open source projects. What motivates you to invest time in them?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I just love programming. I have lots of hobbies, but definitely programming is one of the things that I enjoy the most, what gives me the most pleasure. It’s like an itch: I get this idea or I encounter a need that isn’t addressed by an existing library or maybe I’m just playing to learn a new technology. I can’t help it but sitting down and building something, until is see something working on the screen and the itch goes away. I learned not to be lazy, polishing it a bit and uploading it to GitHub.&lt;&#x2F;p&gt;
&lt;p&gt;Open source is ideal, because you get to work on your own time, you do the stuff you’re interested in and drop the project whenever it bores you. I wish someone would pay me to do that. With a real job it’s harder: sometimes it gets boring, sometimes there’s nothing to do or you depend on someone else to move forward. Most often than not you can’t share your work.&lt;&#x2F;p&gt;
&lt;p&gt;And I always liked this process of conceiving a project, executing it and sharing it with others. Not just in software; the same goes for my fiction writing or when I recorded music as a teenager. When I was in high school I didn’t know how to program but I was obsessed with making games, I spent most of my afternoons fiddling with these game maker programs, RPG Maker and such, sharing my creations with friends. Unfortunately internet access was limited at home and they didn’t teach programming in my school, so it wasn’t until much later that I was able to do serious stuff on my own.&lt;&#x2F;p&gt;
&lt;p&gt;During college I did little projects and games but the languages I knew and skills I had weren’t enough to get me very far at the beginning. There was no GitHub, so it was harder to share and find interesting projects to work on. Later I had to juggle between a full-time job and finishing college. It wasn’t until these last couple of years that I got the freedom to work on whatever I want. And I know in a couple of years I’ll have kids and other stuff going on in my life, so I’m trying to enjoy this programming spring as much as I can.&lt;&#x2F;p&gt;
&lt;p&gt;And then there’s marketing factor. I’m not great at some types of job interviews and my resume may not tell you that much on its own, but I have a portfolio of open source projects that shows I’m a serious coder, a published Android game that proves I can take a personal project to production and a blog that tells you that I reason about my craft and I’m constantly trying to improve it. If you care enough to read it.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What are you working on lately?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I work on a Node.js shop, but the team is full of functional enthusiasts. We can’t convince our boss to let us write a production microservice in Clojure or Elixir, or a user interface in Elm. But the boss doesn’t care that much about our integration tests (as long as there &lt;em&gt;are&lt;&#x2F;em&gt; tests). So when someone complained for the zillionth time about how painful it is to write our API integration tests in JavaScript, I proposed migrating them to Clojure. To my surprise they agreed. So I hacked together this little library to easily do all that we were already doing in our Node.js API tests. And I liked how it turned out, so I’ve &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;facundoolano&#x2F;restpect&quot;&gt;published it in GitHub&lt;&#x2F;a&gt;. Nothing too fancy but it was a good excuse to escape from JavaScript, and it got three of my coworkers learning Clojure, which is great news.&lt;&#x2F;p&gt;
&lt;p&gt;Other than that, I keep slowly growing my &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;facundoolano&#x2F;advenjure&quot;&gt;advenjure engine&lt;&#x2F;a&gt;; just &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;facundoolano.github.io&#x2F;house-taken&quot;&gt;published a full game&lt;&#x2F;a&gt; with it, based on a story by Julio Cortázar. Also been doing some &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;cljsbin-bkhgroqzwe.now.sh&#x2F;&quot;&gt;experiments with Macchiato&lt;&#x2F;a&gt;, to write Clojure web apps that run on Node.js. I have this Machine Learning book I’m about to start, see where that takes me. Node.js microservices still pay my bills. For now, I guess. At some point I hope to be able to get paid for writing Clojure.&lt;&#x2F;p&gt;
</content>
        
    </entry>
</feed>
