<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title>LambdaClass Blog - Machine Learning</title>
    <subtitle>Deep technical insights on cryptography, distributed systems, zero-knowledge proofs, and cutting-edge software engineering from the LambdaClass team.</subtitle>
    <link rel="self" type="application/atom+xml" href="https://blog.lambdaclass.com/tags/machine-learning/atom.xml"/>
    <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2021-03-19T00:00:00+00:00</updated>
    <id>https://blog.lambdaclass.com/tags/machine-learning/atom.xml</id>
    <entry xml:lang="en">
        <title>We wrote a book! “Data Science in Julia for Hackers” beta is now live and free to read</title>
        <published>2021-03-19T00:00:00+00:00</published>
        <updated>2021-03-19T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/how-we-wrote-a-hands-on-bayesian-data-science-book-in-6-months/"/>
        <id>https://blog.lambdaclass.com/posts/how-we-wrote-a-hands-on-bayesian-data-science-book-in-6-months/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/how-we-wrote-a-hands-on-bayesian-data-science-book-in-6-months/">&lt;h4 id=&quot;learn-about-data-science-and-julia-while-solving-real-life-problems&quot;&gt;Learn about data science and Julia while solving real-life problems&lt;&#x2F;h4&gt;
&lt;p&gt;&lt;strong&gt;Read our book “Data Science in Julia for Hackers” at:&lt;&#x2F;strong&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;datasciencejuliahackers.com&#x2F;&quot;&gt;&lt;strong&gt;https:&#x2F;&#x2F;datasciencejuliahackers.com&#x2F;&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-t93INVDo-XNSm7iObeXODQ.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;We put together this post to share the release of our first book on data science methods, which focuses on solving real-life problems. This release is actually a beta version, as we are looking to receive constructive criticism and feedback, in order to improve the book until the first revised version is ready.&lt;&#x2F;p&gt;
&lt;p&gt;We come from different backgrounds. Federico Carrone is a developer with over 15 years of experience and founder of a startup that is running since 2014, who is currently studying towards a degree in Mathematics. Herman Obst is an Industrial Engineer who is just learning to program as is our Physicist, Mariano Nicolini. Martina Cantaro coordinated the writing process and our technical consultants, Manuel Puebla and Lucas Fernández Piana, are making sure our definitions are simple to understand yet accurate.&lt;&#x2F;p&gt;
&lt;p&gt;We do not come from academia, nor are we experts in statistics, which may make some people wonder whether we have enough authority to concern ourselves with such complex issues. But we have one thing in common: above all, we are doers. Collectively, we have experience in setting ourselves big goals and achieving them through, learning, hacking, tinkering and thinking. Data science is a toolkit that has enabled us to solve different real-life problems and we want to share what we have learned in the process.&lt;&#x2F;p&gt;
&lt;p&gt;Speaking of real-life problems, few disciplines have as much impact when it comes to solving them as data science. Currently, our society is constantly generating massive amounts of information encoding complex behaviors and relationships from a wide array of fields. And people are developing the tools to use that information to our benefit.&lt;&#x2F;p&gt;
&lt;p&gt;That was why we were so struck by the fact that almost all the books on data science and statistics had a very theoretical approach, focusing on understanding the mathematics of the algorithms and never talking about their applications to situations we might encounter in work or life in general.&lt;&#x2F;p&gt;
&lt;p&gt;Because of this (and because of our love for making and generating things) we decided to embark on the adventure of writing a book. A book whose first and foremost premise was to propose diverse and interesting problems, and solve them using the ingenuity and tools of data science. And theory does not play a minor role, not at all, but it is developed only to the extent that the resolution of the problem requires it. In this way, a real connection between theory and reality is achieved.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;what-we-want-you-to-learn&quot;&gt;What we want you to learn&lt;&#x2F;h3&gt;
&lt;p&gt;One of the ideas we are most interested in conveying is that of taking action. Nowadays there is a dominant way of thinking, widespread in the academic world, which maintains that before being able to carry any meaningful work we must first acquire a broad theoretical knowledge of the subject. We think this can be counterproductive, as it makes people afraid of taking risks and daring to immerse themselves in practice.&lt;&#x2F;p&gt;
&lt;p&gt;We decided to disprove this way of thinking by making a book about Bayesian statistics, machine learning and artificial intelligence, without (at first) knowing much about any of these fields.&lt;&#x2F;p&gt;
&lt;p&gt;That was our goal. We figured out the rest as we went along.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;what-we-learned&quot;&gt;What we learned&lt;&#x2F;h3&gt;
&lt;p&gt;With our goal always in mind, we started searching and solving a wide variety of problems that could be interesting to tackle using Bayesian inference, which at the beginning was the only topic we planned to talk about. That way we got used to the Bayesian mindset and the different probabilistic programming tools in Julia, our language of choice.&lt;&#x2F;p&gt;
&lt;p&gt;But as we profressed, we changed the focus of the book from something like “Bayesian methods from a practical perspective” to include data science topics in general, from time series prediction to the powerful Scientific Machine Learning ecosystem. Finally, although we wanted to focus on these -not so widespread- methods, we thought it pertinent to add a section on more classical methods, such as deep learning and machine learning — the latter currently in production.&lt;&#x2F;p&gt;
&lt;p&gt;As the dificulty of the scenarios we created began to increase (we often found that a problem was way more complicated than we initially thought), it became clear that we had to incorporate a little more solid knowledge about Bayesianism. That’s where reading &lt;em&gt;Bayesian Methods for Hacker&lt;&#x2F;em&gt; s and &lt;em&gt;Statistical Rethinking&lt;&#x2F;em&gt; gave us a much better understanding and tools to deal with the complexity.&lt;&#x2F;p&gt;
&lt;p&gt;Our writing process also got better over time. Although we already had some experience writing blog posts, writing a book was a brand new challenge for everyone, especially since we are not native English speakers.&lt;&#x2F;p&gt;
&lt;p&gt;At the beginning, our explanations of models and the theory behind them were somewhat lacking. Several pages were discarded, and the rest were re-written several times until we found them passable. It was a process that involved some deal of frustration, but as we iterated over them, the quality of the pages increased substantially. Finally, we found a comfort zone in terms of diagraming, coding and writing the chapters.&lt;&#x2F;p&gt;
&lt;p&gt;The road was winding and some keys to keep the progress up were to not let ourselves be overwhelmed by the enormous task, to divide the work, to go chapter by chapter and, above all, to always keep moving forward. One strategy we used was to complete the writing of the chapters until we felt they were 80% complete. That way, the progress curve always kept a good positive slope, since (by Pareto law) that last 20% would take 80% of the time to complete. Only when we had completed 80% of the book, we went back chapter by chapter to finish polishing it.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;where-you-can-read-it&quot;&gt;Where you can read it&lt;&#x2F;h3&gt;
&lt;p&gt;And that’s it! As of now, the book is up for everyone to read at:&lt;&#x2F;p&gt;
&lt;h4 id=&quot;https-datasciencejuliahackers-com&quot;&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;datasciencejuliahackers.com&#x2F;&quot;&gt;https:&#x2F;&#x2F;datasciencejuliahackers.com&#x2F;&lt;&#x2F;a&gt;&lt;&#x2F;h4&gt;
&lt;p&gt;We hope it will be useful to as many people as possible and we hope to receive lots of feedback and constructive criticism, so we can keep improving edition after edition.&lt;&#x2F;p&gt;
&lt;p&gt;Enjoy!&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Scientific Machine Learning with Julia: the SciML ecosystem</title>
        <published>2020-11-13T00:00:00+00:00</published>
        <updated>2020-11-13T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/scientific-machine-learning-with-julia-the-sciml-ecosystem/"/>
        <id>https://blog.lambdaclass.com/posts/scientific-machine-learning-with-julia-the-sciml-ecosystem/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/scientific-machine-learning-with-julia-the-sciml-ecosystem/">&lt;h4 id=&quot;interview-with-chris-rackauckas&quot;&gt;Interview with Chris Rackauckas&lt;&#x2F;h4&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-zBLCNU10DE1qv5PG4wdwbg.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;We live in a complex world. For those scientists who dare to immerse themselves in that complexity and generate a deeper understanding of it, it is very common to have to deal with differential equation models that are not possible to solve without the use of a computer.&lt;&#x2F;p&gt;
&lt;p&gt;A lot of time is usually be spent in coding the particular differential equation for each problem. Julia SciML works to create and maintain tools that improve this process— from the creation of a framework that allows to automate the pipeline to create and solve problem-specific differential equations with a high level syntax, to introducing machine learning methods to infer unknown components of the model, and many other functionalities.&lt;&#x2F;p&gt;
&lt;p&gt;We interviewed the creator of SciML, Chris Rackauckas, to get to know a little more about his work.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-bCCWEZqP_ORcTiLPPV13rw.png&quot; alt=&quot;&quot; &#x2F;&gt;Source: DifferentialEquations.jl documentation&lt;&#x2F;p&gt;
&lt;h4 id=&quot;please-tell-us-a-bit-about-yourself-what-is-your-background-what-is-your-current-position&quot;&gt;Please tell us a bit about yourself. What is your background? what is your current position?&lt;&#x2F;h4&gt;
&lt;p&gt;I am an applied mathematics instructor at MIT, the Director of Scientific Research at Pumas-AI, and a senior research analyst at the University of Maryland, School of Pharmacy. My background is numerical differential equations and systems biology, where my PhD was in new methods for efficient solving of stochastic differential equations to model the control of randomness in the developing zebrafish hindbrain.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-is-sciml-why-was-it-born-and-what-s-its-purpose&quot;&gt;What is SciML? Why was it born and what’s its purpose?&lt;&#x2F;h4&gt;
&lt;p&gt;Before the “SciML” organization, there was just DifferentialEquations.jl and JuliaDiffEq, but it grew beyond just a single project. There were methods for symbolically manipulating equations, sparse automatic differentiation, automated model discovery, neural PDE solvers, and even packages in Python and R for using these tools. So the name didn’t fit and we did a reorganization around the central principle: scientific machine learning. Scientific machine learning is a burgeoning field that mixes scientific computing, like differential equation modeling, with machine learning. That is the essence of the organization: many tools for scientific simulation with differential equation solvers, chemical reaction network tools and N-body simulators, but all of them can compose with machine learning.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-YtKzMw7VOvNbOCsOkXwU0A.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;scientific-computing-and-machine-learning-are-often-perceived-as-very-different-areas-what-would-you-say-are-the-strengths-and-weaknesses-of-each-one-and-how-does-sciml-take-advantage-of-them&quot;&gt;Scientific Computing and Machine Learning are often perceived as very different areas. What would you say are the strengths and weaknesses of each one and how does SciML take advantage of them?&lt;&#x2F;h4&gt;
&lt;p&gt;Scientific computing generally requires a lot of prior knowledge about the system. You need to be able to create a “mechanistic model”, which requires knowing the physical laws, the chemicals which react, or other way to mathematically encode each interaction of the system. If you know this, great! Then you have a very predictive model. You might know all of the chemicals which interact but not know the reaction rates, and then 12 data points can turn this into quite a predictive model. So these models are interpretable (since it’s all about the mechanism), data efficient, etc. They are great at extrapolating too: the theory of gravity gives pretty good predictions for what happens on Earth as it does for the solar system as it does for galaxies.&lt;&#x2F;p&gt;
&lt;p&gt;Data-driven modeling, like machine learning, takes a completely opposite approach of being “data first”. You have a non-mechanistic model, and you “train” the model based on the data. This requires a lot of data, but you can do this even when you have no idea what the mechanism is. What’s the mechanism for what movie someone will want to watch next on Netflix given the previous movies they’ve seen? Einstein didn’t have a theory for that! But with big data, you can generate such a model.&lt;&#x2F;p&gt;
&lt;p&gt;Scientific machine learning is about pairing together these two paradigms. Incorporating mechanism into machine learning makes it more interpretable, more data efficient, and better able to predict beyond the training data, all without requiring that you know all of the mechanisms. We’re using this in cases like pharmacometrics, where in the first clinical trial we may not know everything about how the drug works, but we can start with a pretty good guess by using mechanistic models derived for similar drugs, and use the incoming data to train models which transforms the prior model towards the data.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-ihyMT0ujkdDopf3M8eiXUw.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-are-neural-odes-when-is-it-appropiate-to-work-with-one-do-you-fear-that-accuracy-or-interpretability-is-lost-by-introducing-a-neural-network-as-part-of-the-equation-aren-t-there-other-learning-methodologies-suited-for-such-a-thing&quot;&gt;What are Neural ODEs? When is it appropiate to work with one? Do you fear that accuracy or interpretability is lost by introducing a Neural Network as part of the equation? Aren’t there other learning methodologies suited for such a thing?&lt;&#x2F;h4&gt;
&lt;p&gt;Neural Ordinary Differential Equations or Neural ODEs are ordinary differential equations defined by a neural network. Indeed the result is less interpretable than having a mechanistic physical model, but it allows for the model to be learned directly from data. The neural network makes it not just estimating parameters, but estimating functions. As a middle ground, we created the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2001.04385&quot;&gt;universal differential equation&lt;&#x2F;a&gt; which is a partially mechanistic model where the neural networks fill in areas of the model which are unknown or have a lot of uncertainty. In this sense, there is more of a continuum between the data-driven and mechanistic models.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;currently-there-exist-many-differential-equations-solvers-why-do-you-think-this-is-the-case-is-there-a-way-to-choose-the-best-one-for-each-situation&quot;&gt;Currently, there exist many differential equations solvers, why do you think this is the case? Is there a way to choose the best one for each situation?&lt;&#x2F;h4&gt;
&lt;p&gt;We created an automated algorithm chooser in order to mitigate this issue. If you do ‘solve(prob)’ (i.e. don’t specify a solver algorithm), it will choose one for you. Then you can give it hints to go down different branches. As time goes on I think we will keep refining that algorithm and pushing more people towards that.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-are-the-key-reasons-the-sciml-differential-equations-solver-is-so-fast-how-does-it-differ-from-others-how-influential-was-writing-it-in-julia&quot;&gt;What are the key reasons the SciML Differential Equations solver is so fast? How does it differ from others? How influential was writing it in Julia?&lt;&#x2F;h4&gt;
&lt;p&gt;Every differential equation solver specializes on some aspect of the differential equation, giving them different performance aspects. For example, BDF integrators, “the standard” for stiff equations, use values from past steps. This can speed things up if the equation is not too stiff, but if it’s too stiff then you cannot use a high order (known as the Dahlquist barrier) and it slows down. So it’s problem dependent as to how well it can mitigate numerical issues, which means for some problems it’s fast and in others it breaks down. Then, if you have discontinuities which are frequent, like dosing in pharmacometrics simulations, this also requires order reduction and thus makes this particular method slower. DifferentialEquations.jl has about 300 methods when you consider all of the tableaus across not just ODEs but also SDEs, DAEs, and DDEs, and it’s this collection that allows it to be efficient.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;regarding-the-importance-of-being-able-to-quantify-the-uncertainty-of-the-numerical-resolution-when-solving-differential-equations-how-does-sciml-address-this-problem&quot;&gt;Regarding the importance of being able to quantify the uncertainty of the numerical resolution when solving differential equations, how does SciML address this problem?&lt;&#x2F;h4&gt;
&lt;p&gt;DifferentialEquations.jl comes with a module DiffEqUncertainty.jl that gives sampling-based estimates of numerical uncertainty by causing jitter on the order of the error estimates calculated on each step. Normally these error estimates are only used for adapting dt, but this gives a way to get essentially a free estimate of what other possible paths look like. Andrew Stuart’s group at CalTech then has a full publication that describes that this method indeed matches the error distribution of the full solve. So if you run this a hundred times you’ll get a sense of what all of the possible trajectories could’ve been given the error tolerance that you allowed.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-are-multiscalearrays-in-what-ways-do-these-data-structures-help-us-in-simulating-complex-scientific-models&quot;&gt;What are MultiScaleArrays? In what ways do these data structures help us in simulating complex scientific models?&lt;&#x2F;h4&gt;
&lt;p&gt;The differential equation solvers, and actually all of the SciML ecosystem, work on abstract interfaces which allow for the concrete implementation of a type to be radically different from the standard implementation. MultiScaleArrays is a nice example of this where an entire multi-scale model is represented as both a graph structure and an array simultaneously. This lets the user write a model like “for every cell in the lung, do the chemical reactions of a lung cell” to define a model, but have the stiff high-performance ODE solver automatically know how to interact with this object. It’s not even an array: it’s an array of arrays of arrays etc., which acts like an array. In this form it’s very efficient to allows cells to divide and die, and the ODE solver will adapt the size of the solution vector automatically as this changes.&lt;&#x2F;p&gt;
&lt;p&gt;While this was made for the specific case of multi-scale biological modeling in mind, other users have since come up with other great examples. CuArrays are CUDA-accelerated arrays that live on the GPU that can be dropped in as a replacement to the standard array, or ComponentArrays.jl defines an array type similar to MultiScaleArrays which is backed by a real vector, so it’s faster for standard computations but slower for size changes. A lot of new features can thus be directly added and optimized in the ODE solver just by changing the input types!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-crRcFtHznAsYXDCb1uh4oQ.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;are-the-processes-of-solving-differential-equations-and-training-a-neural-networks-similar-how-do-you-put-together-both-frameworks&quot;&gt;Are the processes of solving differential equations and training a Neural Networks similar? How do you put together both frameworks?&lt;&#x2F;h4&gt;
&lt;p&gt;Training a neural network is solving an ODE defined by the gradient of the loss function until zero. Solving that ODE with Euler’s method is gradient descent. So you could use an ODE solver as the algorithm for training a neural ODE, and there is a use case that we’re looking into for that. Differential equations are more ubiquitous than I think most people realize.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;is-gpu-computing-integrated-in-the-sciml-ecosystem-how-important-is-having-this-feature-to-a-scientific-computing-framework-nowadays&quot;&gt;Is GPU computing integrated in the SciML ecosystem? How important is having this feature to a scientific computing framework nowadays?&lt;&#x2F;h4&gt;
&lt;p&gt;Yes, there’s two major ways. If you have “big kernels”, like PDE solving or neural networks integrated into models, you can do those calculations on the GPU. This is what’s known as “within-method parallelism”. One of the more recent techniques that we have is “between-method parallelism”, where we can automatically generate CUDA kernels from your model and parallelize that between trajectories of the solution. This uses some fancy code generation tricks thanks to tools like KernelAbstractions.jl, and allows “small problems” to have an effective way to use GPUs as well.&lt;&#x2F;p&gt;
&lt;p&gt;How important is it? Somewhat. There are problems which are extremely GPU-parallelizable, like neural ODEs and PDEs, and there are problems which are not, like lots of semi-mechanistic universal differential equation models. Whether a GPU is useful is very dependent on what and how you’re trying to model.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;in-which-cases-is-it-worth-to-add-a-bayesian-analysis-to-the-parameter-estimation-for-example-with-the-use-of-diffeqbayes-jl-what-are-its-advantages-over-more-classical-optimization-algorithms&quot;&gt;In which cases is it worth to add a Bayesian analysis to the parameter estimation, for example with the use of DiffEqBayes.jl? What are its advantages over more classical optimization algorithms?&lt;&#x2F;h4&gt;
&lt;p&gt;Bayesian analysis gives you a posterior distribution which has a sense of uncertainty quantification, i.e. it doesn’t just give you the “best parameter” but also a distribution which you can use to understand the error bars on your parameter estimate. In many cases this is a fundamentally interesting quantity. For example, in pharmacology we often want to know the probability that the drug concentration is in the safe zone. To evaluate this, we need a probabilistic fit of the model since only by including the uncertainty of our parameters can we get an accurate guess of the probabilities of the dynamics.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-c8-WwVO2Mlef4QqXP7SvSA.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;are-there-any-relevant-books-or-papers-you-would-like-to-recommend-for-digging-deeper-in-these-topics&quot;&gt;Are there any relevant books or papers you would like to recommend for digging deeper in these topics?&lt;&#x2F;h4&gt;
&lt;p&gt;Books schmooks. You’ll want to go directly to the sources. The only books I really recommend these days are Ernst Hairer’s “Solving Ordinary Differential Equations” I and II tomes: those are a work of art. Also Kloeden’s book on numerical methods for stochastic differential equations. Other than that, dive right into the scientific literature.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-is-next-for-sciml-are-you-currently-working-on-some-other-features-to-add-in-the-near-future&quot;&gt;What is next for SciML? Are you currently working on some other features to add in the near future?&lt;&#x2F;h4&gt;
&lt;p&gt;There’s tons we’re doing! I think a lot of what’s next is the integration of symbolic computing into all of our tools. ModelingToolkit.jl is the centerpiece of that push, and while I gave a talk at JuliaCon 2020 showcasing how it can be used as an automated code optimization tool (and gave a PyData 2020 talk on how you can GPU-accelerate ODE solves in R using it!), it’s so much more than that. It’s sometimes hard to numerically do things correctly, like ensuring positivity in an ODE solution can be difficult. But if you log transformed your model, then by definition your solution will always be positive. Right now this is up to the user, but what if we could automatically change the equations you wrote so that, not only are they more efficient, but they are also mathematically easier to solve and estimate? That’s the scope of ModelingToolkit, and if that interests you then you might want to stay tuned to that and its sister product NeuralSim which is about automated surrogate acceleration for the ModelingToolkit modeling language.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Julia GPU</title>
        <published>2020-10-20T00:00:00+00:00</published>
        <updated>2020-10-20T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/julia-gpu/"/>
        <id>https://blog.lambdaclass.com/posts/julia-gpu/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/julia-gpu/">&lt;h3 id=&quot;how-the-julia-language-is-making-it-easy-for-programmers-to-use-gpu-capabilities-with-juliagpu&quot;&gt;How the Julia language is making it easy for programmers to use GPU capabilities with JuliaGPU&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-KJX3T1Y9T1Cj0aV3m-A22w.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;We are living in a time where more and more data is being created every day as well as new techniques and complex algorithms that try to extract the most out of it. As such, CPU capabilities are approaching a bottleneck in their computing power. GPU computing opened its way into a new paradigm for high-performance and parallel computation a long time ago, but it was not until recently that it become massively used for data science.&lt;br &#x2F;&gt;
In this interview, &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;maleadt&quot;&gt;Tim Besard&lt;&#x2F;a&gt;, one of the main contributors to the JuliaGPU project, digs into some of the details about GPU computing and the features that make Julia a language suited for such tasks, not only from a performance perspective but also from a user one.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h4 id=&quot;please-tell-us-a-bit-about-yourself-what-is-your-background-what-is-your-current-position&quot;&gt;Please tell us a bit about yourself. What is your background? what is your current position?&lt;&#x2F;h4&gt;
&lt;p&gt;I’ve always been interested in systems programming, and after obtaining my CS degree I got the opportunity to start a PhD at Ghent University, Belgium, right when Julia was first released around 2012. The language seemed intriguing, and since I wanted to gain some experience with LLVM, I decided to port some image processing research code from MATLAB and C++ to Julia. The goal was to match performance of the C++ version, but some of its kernels were implemented in CUDA C… So obviously Julia needed a GPU back-end!&lt;&#x2F;p&gt;
&lt;p&gt;That was easier said than done, of course, and much of my PhD was about implementing that back-end and (re)structuring the existing Julia compiler to facilitate these additional back-ends. Nowadays I’m at Julia Computing, where I still work on everything GPU-related.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-is-juliagpu-what-is-the-goal-of-the-project&quot;&gt;What is JuliaGPU? What is the goal of the project?&lt;&#x2F;h4&gt;
&lt;p&gt;JuliaGPU is the name we use to group GPU-related resources in Julia: There’s a &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;JuliaGPU&quot;&gt;GitHub organization&lt;&#x2F;a&gt; where most packages are hosted, a &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;juliagpu.org&#x2F;&quot;&gt;website&lt;&#x2F;a&gt; to point the way for new users, we have &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;JuliaGPU&#x2F;gitlab-ci&quot;&gt;CI infrastructure&lt;&#x2F;a&gt; for JuliaGPU projects, there’s a Slack channel and Discourse category, etc.&lt;&#x2F;p&gt;
&lt;p&gt;The goal of all this is to make it easier to use GPUs for all kinds of users. Current technologies often impose significant barriers to entry: CUDA is fairly tricky to install, C and C++ are not familiar to many users, etc. With the software we develop as part of the JuliaGPU organization, we aim to make it easy to use GPUs, without hindering the ability to optimize or use low-level features that the hardware has to offer.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-is-gpu-computing-how-important-is-it-nowadays&quot;&gt;What is GPU computing? How important is it nowadays?&lt;&#x2F;h4&gt;
&lt;p&gt;GPU computing means using the GPU, a device originally designed for graphics processing, to perform general-purpose computations. It has grown more important now that CPU performance is not improving as steadily as it used to. Instead, specialized devices like GPUs or FPGAs are increasingly used to improve the performance of certain computations. In the case of GPUs, the architecture is a great fit to perform highly-parallel applications. Machine learning networks are a good example of such parallel applications, and their popularity is one of the reasons GPUs have become so important.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;do-you-think-julia-is-an-appropriate-language-to-efficiently-use-gpu-capabilities-why&quot;&gt;Do you think Julia is an appropriate language to efficiently use GPU capabilities? Why?&lt;&#x2F;h4&gt;
&lt;p&gt;Julia’s main advantage is that the language was designed to be compiled. Even though the syntax is high-level, the generated machine code is&lt;br &#x2F;&gt;
compact and has great performance characteristics (for more details, see &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;janvitek.org&#x2F;pubs&#x2F;oopsla18b.pdf&quot;&gt;this paper&lt;&#x2F;a&gt;). This is crucial for GPU execution, where we are required to run native binaries and cannot easily (or efficiently) interpret code as is often required by other language’s semantics.&lt;&#x2F;p&gt;
&lt;p&gt;Because we’re able to directly compile Julia for GPUs, we can use almost all of the language’s features to build powerful abstractions. For example, you can define your own types, use those in GPU arrays, compose that with existing abstractions like lazy “Transpose” wrappers, access those on the GPU while benefiting from automatic bounds-checking (if needed), etc.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;from-a-python-programmer-perspective-how-does-cuda-jl-compare-to-pycuda-are-their-functionalities-equivalent&quot;&gt;From a Python programmer perspective, how does CUDA.jl compare to PyCUDA? Are their functionalities equivalent?&lt;&#x2F;h4&gt;
&lt;p&gt;PyCUDA gives the programmer access to the CUDA APIs, with high-level Python functions that are much easier to use. CUDA.jl provides the same, but in Julia. The &lt;code&gt;hello world&lt;&#x2F;code&gt; from PyCUDA’s home page looks almost identical in Julia:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;using CUDA&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;function multiply_them(dest, a, b)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; i = threadIdx().x&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; dest[i] = a[i] * b[i]&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; return&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;end&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;a = CuArray(randn(Float32, 400))&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;b = CuArray(randn(Float32, 400))&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;dest = similar(a)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;@cuda threads=400 multiply_them(dest, a, b)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;println(dest-a.*b)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;There’s one very big difference: “multiply_them” here is a function written in Julia, whereas PyCUDA uses a kernel written in CUDA C. The reason is straightforward: Python is not simple to compile. Of course, projects like Numba prove that it is very much possible to do so, but in the end those are separate compilers that try to match the reference Python compilers as closely as possible. With CUDA.jl, we integrate with that reference compiler, so it’s much easier to guarantee consistent semantics and follow suit when the language changes (for more details,&lt;br &#x2F;&gt;
refer to &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1712.03112&quot;&gt;this paper&lt;&#x2F;a&gt;).&lt;&#x2F;p&gt;
&lt;h4 id=&quot;are-the-packages-in-the-juliagpu-organization-targeted-to-experienced-programmers-only&quot;&gt;Are the packages in the JuliaGPU organization targeted to experienced programmers only?&lt;&#x2F;h4&gt;
&lt;p&gt;Not at all. CUDA.jl targets different kinds of (GPU) programmers. If you are confident writing your own kernels, you can do so, while using all of the low-level features CUDA GPUs have to offer. But if you are new to the world of GPU programming, you can use high-level array operations that use existing kernels in CUDA.jl. For example, the above element-wise multiplication could just as well be written as:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;using CUDA&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;a = CuArray(randn(Float32, 400))&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;b = CuArray(randn(Float32, 400))&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;dest = a .* b&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;&lt;h4 id=&quot;is-it-necessary-to-know-how-to-code-in-cuda-jl-to-take-full-advantage-of-gpu-computing-in-julia&quot;&gt;Is it necessary to know how to code in CUDA.jl to take full advantage of GPU computing in Julia?&lt;&#x2F;h4&gt;
&lt;p&gt;Not for most users. Julia has a powerful language of generic array operations (“map”, “reduce”, “broadcast”, “accumulate”, etc) which can be applied to all kinds of arrays, including GPU arrays. That means you can often re-use your codebase developed for the CPU with CUDA.jl (&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;abs&#x2F;pii&#x2F;S0965997818310123&quot;&gt;this paper&lt;&#x2F;a&gt; shows some powerful examples). Doing so often requires minimal changes: changing the array type, making sure you use array operations instead of for loops, etc.&lt;&#x2F;p&gt;
&lt;p&gt;It’s possible you need to go beyond this style of programming, e.g., because your application doesn’t map cleanly onto array operations, to use specific GPU features, etc. In that case, some basic knowledge about CUDA and the GPU programming model is sufficient to write kernels in CUDA.jl.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;how-is-the-experience-of-coding-a-kernel-in-cuda-jl-in-comparison-to-cuda-c-and-how-transferable-is-the-knowledge-to-one-another&quot;&gt;How is the experience of coding a kernel in CUDA.jl in comparison to CUDA C and how transferable is the knowledge to one another?&lt;&#x2F;h4&gt;
&lt;p&gt;It’s very similar, and that’s by design: We try to keep the kernel abstractions in CUDA.jl close to their CUDA C counterparts such that the programming environment is familiar to existing GPU programmers. Of course, by using a high-level source language there’s many quality-of-life improvements. You can allocated shared memory, for example, statically and dynamically as in CUDA C, but instead of a raw pointers we use an N-dimensional array object you can easily index. An example from the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;developer.nvidia.com&#x2F;blog&#x2F;using-shared-memory-cuda-cc&#x2F;&quot;&gt;NVIDIA developer blog&lt;&#x2F;a&gt;:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;__global__ void staticReverse(int *d, int n)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;{&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; __shared__ int s[64];&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; int t = threadIdx.x;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; int tr = n-t-1;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; s[t] = d[t];&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; __syncthreads();&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; d[t] = s[tr];&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;}&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The CUDA.jl equivalent of this kernel looks very familiar, but uses array objects instead of raw pointers:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;function staticReverse(d)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; s = @cuStaticSharedMem(Int, 64)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; t = threadIdx().x&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; tr = length(d)-t+1&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; s[t] = d[t]&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; sync_threads()&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; d[t] = s[tr]&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; return&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;end&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Using array objects has many advantages, e.g. multi-dimensional is greatly simplified and we can just do “d[i,j]”. But it’s also safer, because these accesses are bounds checked:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;julia&amp;gt; a = CuArray(1:64)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;64-element CuArray{Int64,1}:&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 1&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 2&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 3&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; ⋮&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 62&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 63&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 64&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;julia&amp;gt; @cuda threads=65 staticReverse(a)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;ERROR: a exception was thrown during kernel execution.&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;Stacktrace:&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; [1] throw_boundserror at abstractarray.jl:541&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Bounds checking isn’t free, of course, and once we’re certain our code is correct we can add an “@inbounds” annotation to our kernel and get the high-performance code we expect:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;julia&amp;gt; @device_code_ptx @cuda threads=64 staticReverse(a)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;.visible .entry staticReverse(.param .align 8 .b8 d[16]) {&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; .reg .b32 %r&amp;lt;2&amp;gt;;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; .reg .b64 %rd&amp;lt;15&amp;gt;;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; .shared .align 32 .b8 s[512];&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;mov.b64 %rd1, d;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; ld.param.u64 %rd2, [%rd1];&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; ld.param.u64 %rd3, [%rd1+8];&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; mov.u32 %r1, %tid.x;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; cvt.u64.u32 %rd4, %r1;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; mul.wide.u32 %rd5, %r1, 8;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; add.s64 %rd6, %rd5, -8;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; add.s64 %rd7, %rd3, %rd6;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; ld.global.u64 %rd8, [%rd7+8];&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; mov.u64 %rd9, s;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; add.s64 %rd10, %rd9, %rd6;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; st.shared.u64 [%rd10+8], %rd8;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; bar.sync 0;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; sub.s64 %rd11, %rd2, %rd4;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; shl.b64 %rd12, %rd11, 3;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; add.s64 %rd13, %rd9, %rd12;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; ld.shared.u64 %rd14, [%rd13+-8];&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; st.global.u64 [%rd7+8], %rd14;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; ret;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;}&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;julia&amp;gt; a&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;64-element CuArray{Int64,1}:&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 64&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 63&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 62&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; ⋮&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 3&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 2&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 1&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Tools like “@device_code_ptx” make it easy for an experienced developer to inspect generated code and ensure the compiler does what he wants.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;why-does-having-a-compiler-have-such-an-impact-in-libraries-like-cuda-jl-how-was-the-process-of-integrating-it-to-the-julia-compiler&quot;&gt;Why does having a compiler have such an impact in libraries like CUDA.jl? (How was the process of integrating it to the Julia compiler?)&lt;&#x2F;h4&gt;
&lt;p&gt;Because we have a compiler at our disposal, we can rely on higher-order functions and other generic abstractions that specialize based on the arguments that users provide. That greatly simplifies our library, but also gives the user very powerful tools. As an example, we have carefully implemented a &lt;code&gt;mapreduce&lt;&#x2F;code&gt; function that uses shared memory, warp intrinsics, etc to perform a high-performance reduction. The implementation is generic though, and will automatically re-specialize (even at run time) based on the arguments to the function:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;julia&amp;gt; mapreduce(identity, +, CuArray([1,2,3]))&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;6&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;julia&amp;gt; mapreduce(sin, *, CuArray([1.1,2.2,3.3]))&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;-0.11366175839582586&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;With this powerful &lt;code&gt;mapreduce&lt;&#x2F;code&gt; abstraction, implemented by a experienced GPU programmer, other developers can create derived abstractions without such experience. For example, let’s implement a &lt;code&gt;count&lt;&#x2F;code&gt; function that evaluates for how many items a predicate holds true:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;count(predicate, array) = mapreduce(predicate, +, array)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;julia&amp;gt; a = CUDA.rand(Int8, 4)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;4-element CuArray{Int8,1}:&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 51&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 3&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 70&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; 100&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;julia&amp;gt; count(iseven, a)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;2&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Even though our &lt;code&gt;mapreduce&lt;&#x2F;code&gt; implementation has not been specifically implemented for the &lt;code&gt;Int8&lt;&#x2F;code&gt; type or the &lt;code&gt;iseven&lt;&#x2F;code&gt; predicate, the Julia compiler automatically specializes the implementation, resulting in kernel optimized for this specific invocation.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;what-were-the-biggest-challenges-when-developing-packages-for-juliagpu-particularly-writing-a-low-level-package-such-as-cuda-jl-in-a-high-level-programming-language-such-as-julia&quot;&gt;What were the biggest challenges when developing packages for JuliaGPU, particularly writing a low level package such as CUDA.jl in a high level programming language such as Julia?&lt;&#x2F;h4&gt;
&lt;p&gt;Much of the initial work focused on developing tools that make it possible to write low-level code in Julia. For example, we developed the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;maleadt&#x2F;LLVM.jl&quot;&gt;LLVM.jl&lt;&#x2F;a&gt; package that gives us access to the LLVM APIs. Recently, our focus has shifted towards generalizing this functionality so that other GPU back-ends, like &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;JuliaGPU&#x2F;AMDGPU.jl&quot;&gt;AMDGPU.jl&lt;&#x2F;a&gt; or &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;JuliaGPU&#x2F;oneAPI.jl&quot;&gt;oneAPI.jl&lt;&#x2F;a&gt; can benefit from developments to CUDA.jl. Vendor-neutral array operations, for examples, are now implemented in &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;JuliaGPU&#x2F;GPUArrays.jl&quot;&gt;GPUArrays.jl&lt;&#x2F;a&gt; whereas shared compiler functionality now lives in &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;JuliaGPU&#x2F;GPUCompiler.jl&quot;&gt;GPUCompiler.jl&lt;&#x2F;a&gt;. That should make it possible to work on several GPU back-ends, even though most of them are maintained by only a single developer.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;regarding-the-latest-release-announced-in-the-juliagpu-blog-about-multi-device-programming-what-are-the-difficulties-that-this-new-functionality-solves-is-this-relevant-in-the-industry-where-big-computational-resources-are-needed&quot;&gt;Regarding the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;juliagpu.org&#x2F;2020-07-18-cuda_1.3&#x2F;&quot;&gt;latest release&lt;&#x2F;a&gt; announced in the JuliaGPU blog about multi-device programming, what are the difficulties that this new functionality solves? Is this relevant in the industry where big computational resources are needed?&lt;&#x2F;h4&gt;
&lt;p&gt;In industry or large research labs, MPI is often used to distribute work across multiple nodes or GPUs. Julia’s MPI.jl supports that use case, and integrates with CUDA.jl where necessary. The multi-device functionality added to CUDA 1.3 additionally makes it possible to use multiple GPUs within a single process. It maps nicely on Julia’s task-based concurrency, and makes it easy to distribute work within a single node:&lt;&#x2F;p&gt;
&lt;pre class=&quot;giallo&quot; style=&quot;color: #E1E4E8; background-color: #24292E;&quot;&gt;&lt;code data-lang=&quot;plain&quot;&gt;&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;Threads.@threads for dev in devices()&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; device!(dev)&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt; # do some work here&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;span class=&quot;giallo-l&quot;&gt;&lt;span&gt;end&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;&lt;h4 id=&quot;what-are-the-plans-for-the-near-future&quot;&gt;&lt;strong&gt;What are the plans for the near future?&lt;&#x2F;strong&gt;&lt;&#x2F;h4&gt;
&lt;p&gt;There aren’t any specific roadmaps, but one upcoming major feature is proper support for reduced-precision inputs, like 16-bits floating point. We already support Float16 arrays where CUBLAS or CUDNN does, but the next version of Julia will make it possible to write kernels that operate on these values.&lt;&#x2F;p&gt;
&lt;p&gt;Other than that, features come as they do :-) Be sure to subscribe to the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;juliagpu.org&#x2F;post&#x2F;&quot;&gt;JuliaGPU blog&lt;&#x2F;a&gt; where we publish a short post for every major release of Julia’s GPU back-ends.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;You can find Tim at @&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;maleadt&quot;&gt;maleadt&lt;&#x2F;a&gt; on Twitter!&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Interview with Will Kurt on his latest book: Bayesian Statistics The Fun Way</title>
        <published>2019-06-04T00:00:00+00:00</published>
        <updated>2019-06-04T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/interview-with-will-kurt-on-his-latest-book-bayesian-statistics-the-fun-way/"/>
        <id>https://blog.lambdaclass.com/posts/interview-with-will-kurt-on-his-latest-book-bayesian-statistics-the-fun-way/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/interview-with-will-kurt-on-his-latest-book-bayesian-statistics-the-fun-way/">&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-LDJcJQMeyOPU9lqAs98JBQ.jpeg&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Like most devs, I have a diverse set of interests: functional programming, operating systems, type systems, distributed systems, and data science. That is why I was excited when I learned that &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;willkurt&quot;&gt;Will Kurt&lt;&#x2F;a&gt;, the author of &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.manning.com&#x2F;books&#x2F;get-programming-with-haskell&quot;&gt;&lt;em&gt;Get Programming with Haskell,&lt;&#x2F;em&gt;&lt;&#x2F;a&gt;__ wrote a a bayesian statistics book that is being published by No Starch Press. There aren’t many people that write books on different topics. I was sure that Will had something interesting to share in this new book. I wasn’t disappointed. The book is an excellent introduction, specially for those of us that have a rough time with advanced math but that want to advance in the data science field. I recommend reading the book after reading Think Stats, but before reading Bayesian Methods for Hackers, Bayesian Analysis with Python and Doing Bayesian Data Analysis.&lt;&#x2F;p&gt;
&lt;p&gt;If you like the interview I recommend that you also read the interviews we did with &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;notamonadtutorial.com&#x2F;inteview-with-thomas-wiecki-about-probabilistic-programming-and-pymc-66a12b6f3f2e&quot;&gt;Thomas Wiecki&lt;&#x2F;a&gt; and &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;notamonadtutorial.com&#x2F;interview-with-osvaldo-martin-about-bayesian-analysis-with-python-a696b2bce3ba&quot;&gt;Osvaldo Martin&lt;&#x2F;a&gt; about Bayesian analysis and probabilistic programming.&lt;&#x2F;p&gt;
&lt;p&gt;Finally I wanted to thank two members of my team (Pablo Amoroso and Juan Bono) for helping me with the interview.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;&lt;strong&gt;1. Why a new statistics book?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Nearly all of the many excellent books on Bayesian statistics out now assume you are either familiar with statistics already or have a pretty solid foundation in programming. Because of this the current state of Bayesian statistics in often as an advanced alternative to classical (i.e. frequentist) statistics. So even though Bayesian statistics is gaining a lot of popularity, it’s mostly amount people who already have a quantitative background.&lt;&#x2F;p&gt;
&lt;p&gt;When someone wants to simply “learn statistics” they usually pick up an introduction based on frequentist statistics and end up half understanding a bunch of tests and rules, and feel very confused by the subject. I wanted to write a book on Bayesian statistics that really anyone could pick up and use to gain real intuitions for how to think statistically and solve real problems using statistics. For me there’s no reason why Bayesian statistics can’t be a beginners first introduction to statistics.&lt;&#x2F;p&gt;
&lt;p&gt;I would love it if, one day, when people said “statistics” it implied Bayesian statistics and frequentist statistics was just an academic niche. To get there we need more books that introduce statistics to a wide audience using Bayesian methods and assume this may be the readers first exposure to stats. I toyed with the idea of just calling this book “Statistics the Fun Way”, but I know I would probably get angry emails from people buying the book help with stats 101 and getting very confused! Hopefully this book will be a small step in getting “stat 101” to be taught from the Bayesian perspective, and statistics can make sense from the beginning.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;2. Who is your intended audience for the book? Could anyone without a math background pick it up?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;My goal with Bayesian Statistics the Fun Way was to create a book that basically anyone with a high school math background could pick up and read. Even if you only vaguely remember algebra, the book moves at a pace that should be easy to follow. Bayesian statistics does require just a little calculus and is a lot easier with a bit of code, so I’ve included two appendices that cover enough R to work as an advanced calculator and enough background in the ideas of calculus that when the book needs talk about integrals you can understand. But I promise that there is no solving of any calculus problems required.&lt;&#x2F;p&gt;
&lt;p&gt;While I worked hard to limit the mathematical prerequisites for the book, as you read through the book you should start picking up on mathematical ways of thinking. If you really understand the math your using, you can make better use of it. So I don’t try to shy away from any of the real math, but rather work up to it slowly so that all the math seems obvious as you develop your understanding. Like many people, I used to believe that math was confusing and difficult to work with. In time I really saw that when math is done right, it should be almost obvious. Confusion in mathematics is usually just the result of moving too quickly, or leaving out important steps in the reasoning.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;3. Why should software developers learn probability and statistics?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I really believe everyone should learn some probability and statistics because it really does help to reason about the uncertain world which is our everyday life. For software developers in particular there are few common places that its useful to understand statistics. It’s pretty likely that at some point in your career in software, you’ll need to write code that makes some decision based on some uncertain measurement. Maybe it’s measuring the conversion rate on a web page, generating some random reward in a game, assigning users to groups randomly or even reading information from an uncertain sensor. In all these cases really understanding probability will be very helpful. In the software part of my career I’ve also found that probability can help a lot in troubleshooting bugs that are difficult to reproduce or to trace back to a complex problem. If a bug appears to be caused by insufficient memory, does adding more memory decrease the probability of the bug in a meaningful way? If there are two explanations for a complex bug, which should be investigated first? In all these cases probability can help. And of course with the rise of Machine Learning and Data Science, engineers are more and more likely to be working on software problems that involve working directly with probabilities.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;4. Could you give a brief summary of the difference between the frequentist and bayesian approaches to probability?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Frequentists interpret probability as a statement about how frequently an event should occur in repeated trials. So if we toss a coin twice we should expect to get 1 head because the frequency of heads is 1&#x2F;2. Bayesians interpret probability as a statement of our knowledge, basically as a continuous version of logic. The probability of getting heads in a coin toss is 0.5 because I don’t believe getting heads is any more likely than getting tails. For coin tosses both schools of thought work pretty well. But when you talk about things like the probability that your favorite football team will win the world cup, talking about degrees of belief makes a lot more sense. This additionally means that Bayesian statistics does not make statements about the world but about our understanding of the world. And since we each understand the world a bit differently, Bayesian statistics allows us to incorporate that difference into our analysis. Bayesian analysis is, in many ways, the science of changing your mind.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;5. Why did you choose to focus on the bayesian approach?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;There are plenty of really great philosophical reasons to focus on Bayesian statistics but for me there is a very practical reason: everything makes sense. From a small set of relatively intuitive rules you can build out the solutions to any problem you encounter. This gives Bayesian statistics a lot of power and flexibility, and also makes it much easier to learn. I think this is something programmers will really like about Bayesian reasoning. You aren’t applying ad hoc tests to a problem, but reasoning about your problem and coming up with a solution that makes sense. Bayesian statistics is really reasoning. You agree to the statistical analysis only when it genuinely makes sense and convinces you, not because some seemingly arbitrary test result achieves some equally arbitrary value. Bayesian statistics also allows us to disagree quantitatively. It’s quite common in everyday life that two people will see the same evidence and come to different conclusions. Bayesian statistics allows us to model this disagreement in a formal way so that we can see what evidence it would take to change our beliefs. You shouldn’t believe the results of a paper because of a p-value, you should believe them because the truly convince you.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;6. How Bayesian Statistics Is Related To Machine Learning&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;One way I’ve been thinking about the relationship between Bayesian Statistics and Machine Learning (especially neural networks) in the way that each deal with the fact that calculus can get really, really hard. Machine Learning is essentially understanding and solving really tricky derivatives. You come up with a function and a loss for it, then compute (automatically) the derivative and try to follow it until you get optimal parameters. People often snarkily remark that backpropagation is “just the chain rule”, but nearly all the really hard work in deep learning is applying that successfully.&lt;&#x2F;p&gt;
&lt;p&gt;Bayesian statistics is the other part of calculus, solving really tricky integrals. The Stan developer Michael Betancourt made a great comment that basically all Bayesian analysis is really computing expectations, which is solving integrals. Bayesian analysis leaves you with a posterior distribution but you can’t use a distribution for anything unless you integrate over it to get a concrete answer. Thankfully no one makes snarky comments about integrals because everyone knows that it can be really tricky in the simplest case. This xkcd makes that point nicely:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-vska22BJzFePmtcrzokZ0A.png&quot; alt=&quot;&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;So in this strange way the current state Machine Learning and Bayesian Statistics are what happens when you push basic calculus ideas to the limits of what we can compute.&lt;&#x2F;p&gt;
&lt;p&gt;This relationship also outlines the key differences. When you think about derivatives you’re looking for a specific point related to a function. If you know location and time, the derivative is speed and can tell you when you went the fastest. Moving the needle in ML is getting a single metric better than anyone else. Integration is about summarizing an entire process. Again if you know location and time, the integral is distance and tells you how far you’ve traveled. Bayesian statistics is about summarizing all of your knowledge about a problem, but this allows us to not just give single predictions but also say how confident we are in a wide range of predictions. Advancement in Bayesian statistics is about understanding more complex systems of information.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;7. If your readers wanted to dig deeper into the subject of the book, where would you point them to (books, courses, blog posts, etc)?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The biggest inspiration for this book was E.T. Jaynes’ “Probability Theory: the Logic of Science”. My secret hope is that “Bayesian Statistics the Fun Way” can be a version of that book accessible to everyone. Jaynes’ book is really quite challenging to work through and is presents a pretty radical version of Bayesian statistics. Aubrey Clayton has done an amazing service by putting together a &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=rfKS69cIwHc&quot;&gt;series of lectures&lt;&#x2F;a&gt; on the key chapters of this book.&lt;&#x2F;p&gt;
&lt;p&gt;And of course if you liked reading the book you’d probably enjoy my &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.countbayesie.com&#x2F;&quot;&gt;blog&lt;&#x2F;a&gt;. I haven’t been posting much recently since I’ve been writing a “Bayesian Statistics the Fun Way” and before that “Get Programming with Haskell” but I’ve got a ton of posts in my head that I really want to get down on paper soon. Generally the blog, despite the name, is not strictly Bayesian. Typically if I have some statistics&#x2F;probability topic that I’m thinking about, it will get fleshed out into a blog post.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;8. In your experience, what is a concept from probability&#x2F;statistics that non experts find difficult to understand?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Honestly, the hardest part is interpreting probabilities. People really lost faith in a lot of Bayesian analysts like Nate Silver (and many others) when they were predicting 80% or so chance that Clinton would win the 2016 election and she didn’t. People felt like they had been tricked and everyone was wrong, but 80% chance really isn’t that high. If my doctor tells me I have an 80% chance to live I’m going to be really nervous.&lt;&#x2F;p&gt;
&lt;p&gt;A common approach to this problem is to point to probabilities themselves and say that they are a poor way to express uncertainty. The fix then is that you should be using odds or likelihood ratios or some decibel-like system similar to Jaynes’s idea of evidence. But after really thinking about probability for along time I haven’t found that there’s a universally good way to express uncertainty.&lt;&#x2F;p&gt;
&lt;p&gt;The heart of the problem is that, deep down, we really want to believe that the world is certain. Even among experienced probabilists there’s this persistent nagging feeling that maybe if you do the right analysis, learn the right prior, add another layer into your hierarchical model you can get it right and remove or at least dramatically reduce uncertainty. Part of what draws me to probability is the weird mixture of trying to make sense of the world and the mediation on the fact that even when trying your hardest, the world will surprise you.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;9. What are your thoughts on p-values as a measure of statistical significance? Could you give us a brief description of p-hacking?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;There’s two things wrong with p-values. First of all, p-values are not the way sane people answer questions. Imagine how this conversation would sound at work:&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;Manager: “Did you fix that bug assigned to you?”&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;You: “Well I’m pretty sure I didn’t not fix it…”&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Manager: “If you fixed it, just mark it fixed.”&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;You: “Oh no, I really can’t say that I fixed it…”&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Manager: “So you want to mark it ‘will not fix’?”&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;You: “No, no, I’m pretty sure that’s not the case”&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;p-values confuse people because they are, quite literally, confusing. Bayesian statistics gives you a posterior probability, which is exactly the positive answer to the question being posed that you want. In the previous dialog the Bayesian says “I’m pretty sure it’s fixed”, if the manager wants you to be more sure, you collect more data and then you can say “I’m basically certain it’s fixed”.&lt;&#x2F;p&gt;
&lt;p&gt;The second problem is the culture of arbitrarily picking 0.05 as some magic value that has meaning. Related to the previous question about understanding probabilities, a 5% chance of something occuring does not make it very rare. Rolling a 20 sided die and getting a 20 has a 5% chance, and anyone who knows of Dungeons and Dragons (D&amp;amp;D) knows that this is far from impossible. Outside of role playing games, focusing on a die roll is not a great system of verifying true from false.&lt;&#x2F;p&gt;
&lt;p&gt;And that brings us to p-hacking. Imagine you’re playing D&amp;amp;D with some friends and you role twenty 20-sided dice all at one. You then point one that landed on 20 and proclaim “that was the die I meant to roll, the rest are all just test dice.” It’s still cheating even if you technically did roll a 20. That’s what p-hacking essentially is. You keep doing analysis until you find something that is ‘significant’, and then claim that’s what you were looking for the entire time.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;10. Any closing recommendations on what book to read next after reading your book?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Now that I’ve finished writing this book I finally have time to start catching up on other books that I didn’t have time to read while writing it! I’m really enjoying Osvaldo Martin’s “Bayesian Analysis with Python” (I know Not Monad Tutorial interviewed him not long ago). It’s a great book that approaches Bayesian analysis through PyMC3. I really think the world of probabilistic programming is very exciting and will be more and more an essential part of practical Bayesian statistics. Another book I really want to read is Richard McElreath’s “Statistical Rethinking”. It has a second edition coming out soon so I’m slightly hesitant to get copy before that. McElreath has put up a bunch of great supporting material on his &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;xcelab.net&#x2F;rm&#x2F;statistical-rethinking&#x2F;&quot;&gt;website&lt;&#x2F;a&gt;, so I might not be able to wait until the 2nd edition to get a copy. Both of these sources would be great next steps following “Bayesian Statistics the Fun Way”. Another good recommendations would be Kruschke’s “Doing Bayesian Data Analysis”.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Inteview with Thomas Wiecki about Probabilistic programming and PyMC</title>
        <published>2018-11-16T00:00:00+00:00</published>
        <updated>2018-11-16T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://blog.lambdaclass.com/posts/inteview-with-thomas-wiecki-about-probabilistic-programming-and-pymc/"/>
        <id>https://blog.lambdaclass.com/posts/inteview-with-thomas-wiecki-about-probabilistic-programming-and-pymc/</id>
        
        <content type="html" xml:base="https://blog.lambdaclass.com/posts/inteview-with-thomas-wiecki-about-probabilistic-programming-and-pymc/">&lt;h3 id=&quot;inteview-with-thomas-wiecki-about-pymc-and-probabilistic-programming&quot;&gt;Inteview with Thomas Wiecki about PyMC and probabilistic programming&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;max&#x2F;2000&#x2F;1-Ke59y1Iyox6MUJ1HpEkLyg.jpeg&quot; alt=&quot;&quot; &#x2F;&gt;“A colleague of von Neumann and Ulam, Nicholas Metropolis, suggested using the name &lt;strong&gt;Monte Carlo&lt;&#x2F;strong&gt; , which refers to the Monte Carlo Casino in Monaco where Ulam’s uncle would borrow money from relatives to gamble”&lt;&#x2F;p&gt;
&lt;p&gt;After studying and working with distributed systems my interests drifted into data science, artificial intelligence, machine learning and now statistics. After a while I found I really liked applying what I have learnt into finance. That is how I learnt about probabilistic programming and &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;docs.pymc.io&#x2F;&quot;&gt;PyMC&lt;&#x2F;a&gt; while reading Thomas Wiecki posts at &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;blog.quantopian.com&#x2F;&quot;&gt;Quantopian blog&lt;&#x2F;a&gt;. That’s why we decided to interview Thomas. I hope you like this interview as much as we did.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;&lt;strong&gt;What is probabilistic programming?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Probabilistic Programming is a paradigm that allows the expression of Bayesian statistical models in computer code. Imagine you run an A&#x2F;B test and want to know which version is better. With a few lines of code you could build a model with 2 convergence rate parameters that are linked to the data you observed this far. So far that’s only model specification. The real power in probabilistic programming comes from the inference algorithms that have become so powerful that they usually work very well no matter what model you throw at them. So all you have to do is build the model, hit the inference button and analyze your outputs. In this example, the outputs will be the estimates of the convergence rates for both conditions as well as the uncertainty in those estimates. From there it is trivial to extract statements such as “with x% probability, version A has a higher convergence rate than version B”.&lt;&#x2F;p&gt;
&lt;p&gt;This is a really simple example but these models can get staggeringly complex, depending on the problem you are trying to solve.&lt;&#x2F;p&gt;
&lt;p&gt;In general, whenever you have a problem where uncertainty plays a big role, where there is structure to be exploited (e.g. hierarchical), or you have prior knowledge you want to include in the model, probabilistic programming is the tool of choice.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What is PyMC?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;PyMC3 is such a probabilistic programming framework. It is different from most previous frameworks in that it does not require you to write models in a domain specific language but in plain Python. It features state-of-the-art inference algorithms and diagnostics, flexible support for Gaussian Processes, model comparison metrics, and has a very active community.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Why was PyMC created? What is the difference with other projects like Edward and Stan?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;PyMC3 is a result of the desire to implement next-generation Hamiltonian Monte Carlo (HMC) samplers which are vastly superior to previous MCMC algorithms. Contrary to these previous algorithms, HMC requires gradients to be computed. Theano was the first library that allowed to build a compute graph in Python from which it is easy to automatically compute gradients. John Salvatier went through various designs until he came up with the core design that would constitute PyMC3. While HMC is the core motivation, Theano provides many other benefits to PyMC3, like high performance due to graph optimizations and compilation to CPU and GPU, while keeping the model definition and code-base pure Python.&lt;&#x2F;p&gt;
&lt;p&gt;The biggest difference to Stan is that this one is written in C++ with a custom DSL to define models. This is great as it allows interfaces from various languages but it comes at the cost of a more complex code-base, and having to learn a DSL rather than being able to use Python. Having said that, PyMC3 is hugely inspired by Stan in many ways.&lt;&#x2F;p&gt;
&lt;p&gt;Edward is a more recent PPL built on TensorFlow so in that way it is quite similar to PyMC3 in that you can construct models in pure Python. Its focus is more on variational inference (which can also be expressed in the same PPL), scalability and deep generative models. I don’t think it is actively developed anymore so I think some interested should take a look at TensorFlow Probability instead.&lt;&#x2F;p&gt;
&lt;p&gt;In general, I would say that if you are a ML researcher developing new deep networks or variational inference algorithms, use TensorFlow Probability; if you are an R user with a statistical background, use Stan; if you are a Data Scientist most comfortable in Python, use PyMC3.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Could you please tell us about real world examples where PyMC is being used?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;PyMC3 is widely used in academia, there are currently close to 200 papers using PyMC3 in various fields, including astronomy, chemistry, ecology, psychology, neuroscience, computer security, and many more. It is also used to solve various business problems by large and small companies. One common use case I have heard is for A&#x2F;B testing, which makes sense as uncertainty plays a big role. Another problem well solved by PyMC3 is supply chain optimization.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;How does PyMC differ from other probabilistic programming languages (eg Figaro, Church, Anglican)?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;These more academic PPLs really push the envelope of what is possible to do in this framework. They are Turing complete and thus there is little that can not be done. Often these high standards on theoretical guarantees and pureness of the PPL come at the cost of usability and performance. PyMC3 on the other hand is focusing on solving 80% of the problems encountered in reality as succinctly and performant as possible.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;How far is support for Deep Learning methods integrated into PyMC?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I wrote a &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;twiecki.github.io&#x2F;blog&#x2F;2016&#x2F;06&#x2F;01&#x2F;bayesian-deep-learning&#x2F;&quot;&gt;couple&lt;&#x2F;a&gt; &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;twiecki.github.io&#x2F;blog&#x2F;2016&#x2F;07&#x2F;05&#x2F;bayesian-deep-learning&#x2F;&quot;&gt;of&lt;&#x2F;a&gt; &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;twiecki.github.io&#x2F;blog&#x2F;2017&#x2F;03&#x2F;14&#x2F;random-walk-deep-net&#x2F;&quot;&gt;blog&lt;&#x2F;a&gt; &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;twiecki.github.io&#x2F;blog&#x2F;2018&#x2F;08&#x2F;13&#x2F;hierarchical_bayesian_neural_network&#x2F;&quot;&gt;posts&lt;&#x2F;a&gt; exploring these topics. As deep learning was Theano’s original purpose we can tap into a lot of that functionality and extend deep nets in interesting ways. I have not seen it been much explored elsewhere, however. PyMC4 will be based on TensorFlow Probability (TFP) which definitely has a strong focus on deep generative models so this type of model will be much easier to build and TFP’s powerful inference algorithms will also allow it to scale.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What are the tradeoffs of using Variational Inference vs standard Markov chain Monte Carlo with regards to finance?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Variational inference is generally much faster at the cost of a less accurate approximation of the posterior. In finance you are often operating under razor-thin margins so everything counts. My recommendation is to thus use MCMC.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Is there support for modelling Generalized Extreme Value distributions in PyMC3?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I haven’t come across that one yet but it looks like it should be fairly easy to add. We certainly have the Gumbell and Weibull distribution which are special cases of it.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;How is model criticism implemented?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;There is pymc3.sample_posterior_predictive() which allows you to generate new data from your model which you can then compare to your original data to test if the model can capture the important properties in your model. See &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;docs.pymc.io&#x2F;notebooks&#x2F;posterior_predictive.html&quot;&gt;https:&#x2F;&#x2F;docs.pymc.io&#x2F;notebooks&#x2F;posterior_predictive.html&lt;&#x2F;a&gt; for more information.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;How do you use PyMC3 at Quantopian?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;We use it in various places, but most critical for portfolio weighting. At Quantopian our challenge is to evaluate return streams of trading algorithms over limited time periods to decide if they have an edge in the market or just got lucky over a certain time-period. Thus, correctly quantifying uncertainty is critical. The return streams themselves have many challenging characteristics on top of that which are important to consider when trying to select them. Some key characteristics are that over time, they often change volatility; the “edge” they have can also vary over time; and they can be correlated with other strategies you are considering.&lt;&#x2F;p&gt;
&lt;p&gt;Adrian Seyboldt built a fairly sophisticated model which takes all these properties (and more) into account and ends up having tens of thousands of parameters. The incredible thing about PyMC3 and HMC is that this hugely complex model can be fit in well under an hour. But the really business critical advantage is that once this model is fitted, correctly attributing all the uncertainty in these various characteristics, we can put everything into an optimizer to give us the optimal portfolio. This way, we solve the algorithm selection &lt;em&gt;and&lt;&#x2F;em&gt; portfolio weighting problem in one go. Before, there was a lot of discretionary leeway in what constitutes enough evidence that an algorithm should be turned on or off leading to suboptimal decisions.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Has PyMC been ever used to price financial derivatives?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Not to my knowledge but I would not be surprised if they had been used for that. People come up to me constantly at conferences and tell me about the cool domain problems they solved with PyMC3 at their company. I love hearing about this because it is hard to assess how many and for what purpose people use your software.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;How big a problem is autocorrelation in sampling financial (tail risk, pricing) distributions?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;It is definitely an important source of risk that is often ignored when applying frequentist statistics to finance, as the normality assumption is baked into most tests. Using probabilistic programming we can model changes in volatility like the &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;docs.pymc.io&#x2F;notebooks&#x2F;stochastic_volatility.html&quot;&gt;stochastic volatility model&lt;&#x2F;a&gt; does. Alternatively one can also use a Student-T distribution for the likelihood which allows for heavier tails.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What could be improved in PyMC?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I think the documentation and website needs more work to make it easier to find things and more beginner friendly. We also recently spun out the plotting code into a separate project called &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arviz-devs.github.io&#x2F;arviz&#x2F;&quot;&gt;ArviZ&lt;&#x2F;a&gt;. In the upcoming release, we will slowly transition to using that library.&lt;&#x2F;p&gt;
&lt;p&gt;Our next major project will be PyMC4 which will be based on TensorFlow Probability which provides a great core architecture and allows us to put more focus on usability and we have some interesting ideas for improved model creation API. In the meantime, maintenance of Theano is going to be taken over by the PyMC development team as the original authors are moving on.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Is the project looking for contributors?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Yes, we constantly have new contributors show up on &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;pymc-devs&#x2F;pymc3&quot;&gt;GitHub&lt;&#x2F;a&gt; and &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;discourse.pymc.io&quot;&gt;discourse&lt;&#x2F;a&gt; and keep growing our list of core developers. We also have a summit coming up where all developers will be meeting in London to hack on PyMC4.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What books or MOOCs would you recommend for a software dev that wants to learn more about probability and statistics?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;camdavidsonpilon.github.io&#x2F;Probabilistic-Programming-and-Bayesian-Methods-for-Hackers&#x2F;&quot;&gt;Probabilistic Programming for Hackers&lt;&#x2F;a&gt; is a great read. For a more formal introduction I like &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;www.indiana.edu&#x2F;~kruschke&#x2F;DoingBayesianDataAnalysis&#x2F;&quot;&gt;Kruschke’s puppy book&lt;&#x2F;a&gt; (which was &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;JWarmenhoven&#x2F;DBDA-python&quot;&gt;ported to PyMC3&lt;&#x2F;a&gt;) as well as Osvaldo Martin’s (who is a PyMC core developer) book on &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.packtpub.com&#x2F;big-data-and-business-intelligence&#x2F;bayesian-analysis-python-second-edition&quot;&gt;Bayesian Analysis with Python&lt;&#x2F;a&gt;. Also if you find that screencasts are a good way to learn — Peadar Coyle (who is a PyMC core developer) put together a course called &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.probabilisticprogrammingprimer.com&#x2F;&quot;&gt;Probabilistic Programming Primer&lt;&#x2F;a&gt;, he also looks at other PPLs including Pyro (from Uber based on Pytorch) and Rainier (a Scala based PPL). Finally, &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;xcelab.net&#x2F;rm&#x2F;statistical-rethinking&#x2F;&quot;&gt;Statistical Rethinking&lt;&#x2F;a&gt; (ported to &lt;a rel=&quot;noopener external&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;pymc-devs&#x2F;resources&#x2F;tree&#x2F;master&#x2F;Rethinking&quot;&gt;PyMC3&lt;&#x2F;a&gt;) is a fantastic resource as well.&lt;&#x2F;p&gt;
</content>
        
    </entry>
</feed>
