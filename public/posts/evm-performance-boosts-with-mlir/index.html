<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EVM performance boosts with MLIR - LambdaClass Blog</title>
    <meta name="description" content="Deep technical insights on cryptography, distributed systems, zero-knowledge proofs, and cutting-edge software engineering from the LambdaClass team.">

    <!-- Feeds -->
    <link rel="alternate" type="application/rss+xml" title="RSS" href="https://blog.lambdaclass.com/rss.xml">
    <link rel="alternate" type="application/atom+xml" title="Atom" href="https://blog.lambdaclass.com/atom.xml">

    <!-- Styles -->
    <link rel="stylesheet" href="https://blog.lambdaclass.com/style.css">

    <!-- Preload fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">

    <!-- Math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body, {delimiters: [{left: '$$', right: '$$', display: true}, {left: '$', right: '$', display: false}]});"></script>
</head>
<body>
    <div class="site-wrapper">
        <header class="site-header">
            <nav class="nav-container">
                <a href="https://blog.lambdaclass.com" class="site-logo">
                    <span class="logo-text">LambdaClass</span>
                </a>
                <div class="nav-links">
                    <a href="https://blog.lambdaclass.com" >Home</a>
                    <a href="https://blog.lambdaclass.com/tags" >Topics</a>
                    <a href="https://github.com/lambdaclass" target="_blank" rel="noopener">GitHub</a>
                    <a href="https://x.com/class_lambda" target="_blank" rel="noopener">X</a>
                    <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                        <svg class="sun-icon" xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"></circle><line x1="12" y1="1" x2="12" y2="3"></line><line x1="12" y1="21" x2="12" y2="23"></line><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line><line x1="1" y1="12" x2="3" y2="12"></line><line x1="21" y1="12" x2="23" y2="12"></line><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line></svg>
                        <svg class="moon-icon" xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path></svg>
                    </button>
                </div>
            </nav>
        </header>

        <main class="site-main">
            
<article class="page-article">
    <header class="page-header">
        <h1 class="page-title">EVM performance boosts with MLIR</h1>
        
        <div class="page-meta">
            <time datetime="2024-06-14">June 14, 2024</time>
        </div>
        
    </header>

    <div class="page-content prose">
        <p>We implemented 75% of the functionality of the Ethereum Virtual Machine, in two weeks, with five new hires, compiling the VM opcode logic to native machine code with a state of the art compiler backend. Why did we do this? How?<br />
The TL;DR is: to get a performance boost (recent benchmark results show a throughput 300% to 600% times higher than <em>revm</em> , when running factorial and fibonacci programs), to increase implementation diversity, and to use it in our upcoming implementation of an Ethereum Execution client.</p>
<p>Seeing as many other VMs compile bytecode to native instructions, it struck us as odd that Ethereum Virtual Machine (EVM) implementations don’t do the same. Doing Cairo Native we <a href="/cairo-and-mlir/">learned a lot about MLIR/LLVM</a>, and so we started the EVM-MLIR project with the objective of having a faster alternative to <em>revm</em>.</p>
<p>We wanted to get a sense of feasibility as soon as possible, so we started by specifying the problem (and solution) well, laying out the project skeleton and utilities, and making sure the new team had a solid base to work on. With clear tasks ready to be assigned, we managed to implement 111 out of 149 opcodes from mainnet in two weeks!</p>
<h2 id="applying-mlir-to-the-evm">Applying MLIR to the EVM</h2>
<p>The EVM is a stack-based virtual machine whose compiled bytecode represents a sequence of instructions consisting of 1-byte opcodes with implicit parameters. Push operations also include up to 32 bytes of extra data (the number to push to the stack).</p>
<p>Its memory architecture consists of five components:</p>
<pre class="giallo" style="color: #E1E4E8; background-color: #24292E;"><code data-lang="plain"><span class="giallo-l"><span>    * Stack: stores up to 1024 256-bit wide integers. Each operation pops operands from it, and/or pushes results to it. If a program runs out of stack it terminates.</span></span>
<span class="giallo-l"><span>    * Memory: byte array, which allows random addressing by byte. Used for storing and accessing volatile data in an ordered manner.</span></span>
<span class="giallo-l"><span>    * Calldata: a read-only byte array similar to the _Memory_ sent as input on each transaction. Some operands allow copying data from the calldata to the stack or memory.</span></span>
<span class="giallo-l"><span>    * Storage: dictionary with 256-bit keys and values. Changes are persisted, unless the transaction is reverted.</span></span>
<span class="giallo-l"><span>    * Transient storage: similar to _Storage_ , but changes are discarded at the end of a transaction.</span></span></code></pre>
<p>We can see that the execution model of the EVM is exceedingly simple, on purpose.</p>
<p>A naive interpreter loop on the instruction sequence is simple to implement but difficult to optimize. There are many approaches to implementing bytecode interpreters (it’s a fun and educating project!) but removing interpreter overhead by directly translating each opcode to machine instructions is very efficient. The only difficulty is needing a compiler backend and a way to link and invoke the generated code.</p>
<p>We decided to take advantage of our recent experience with MLIR and write a library to translate each operation to a sequence of MLIR blocks containing the MLIR operations that implement each opcode’s behaviour, string them up by connect each one to the next. Finally this representation can be translated to LLVM IR and be put through LLVM’s optimizer passes.</p>
<p>Not only did we have to translate each opcode’s logic in terms of MLIR operations, we also needed to translate the memory architecture:</p>
<pre class="giallo" style="color: #E1E4E8; background-color: #24292E;"><code data-lang="plain"><span class="giallo-l"><span>    * Stack: we pre-allocate the max stack size (1024 elements) before starting the aforementioned sequence. Current and base pointers are used to maintain the stack and check for overflows or underflows.</span></span>
<span class="giallo-l"><span>    * Memory: we handle the memory allocation in Rust, extended as needed by FFI callbacks.</span></span>
<span class="giallo-l"><span>    * Calldata: we store it on Rust&#39;s side, and give it as input to the EVM.</span></span>
<span class="giallo-l"><span>    * Storage/Transient storage: will be handled via syscalls, with an API similar to _revm_.</span></span></code></pre><h3 id="benchmarks">Benchmarks</h3>
<h4 id="factorial">Factorial</h4>
<p>This program computed the Nth factorial number, with N passed via calldata. We chose 1000 as N and ran the program on a loop 100,000 times.</p>
<h5 id="macbook-air-m1-16-gb-ram">MacBook Air M1 (16 GB RAM)</h5>
<p>| Mean [s] | Min [s] | Max [s] | Relative<br />
—|—|—|—|—<br />
EVM-MLIR | 1.062 ± 0.004 | 1.057 | 1.070 | 1.00<br />
revm | 6.747 ± 0.190 | 6.497 | 7.002 | 6.36 ± 0.18</p>
<h5 id="amd-ryzen-9-5950x-16-core-processor-128-gb-ram">AMD Ryzen 9 5950X 16-Core Processor (128 GB RAM)</h5>
<p>| Mean [s] | Min [s] | Max [s] | Relative<br />
—|—|—|—|—<br />
EVM-MLIR | 1.363 ± 0.151 | 1.268 | 1.691 | 1.00<br />
revm | 5.081 ± 0.685 | 4.839 | 7.025 | 3.73 ± 0.65</p>
<h4 id="fibonacci">Fibonacci</h4>
<p>This program computed the Nth fibonacci number, with N passed via calldata. Again, we chose 1000 as N and ran the program on a loop 100,000 times.</p>
<h5 id="macbook-air-m1-16-gb-ram-1">MacBook Air M1 (16 GB RAM)</h5>
<p>| Mean [s] | Min [s] | Max [s] | Relative<br />
—|—|—|—|—<br />
EVM-MLIR | 1.010 ± 0.016 | 0.990 | 1.040 | 1.00<br />
revm | 6.192 ± 0.119 | 6.094 | 6.374 | 6.13 ± 0.15</p>
<h5 id="amd-ryzen-9-5950x-16-core-processor-128-gb-ram-1">AMD Ryzen 9 5950X 16-Core Processor (128 GB RAM)</h5>
<p>| Mean [s] | Min [s] | Max [s] | Relative<br />
—|—|—|—|—<br />
EVM-MLIR | 1.496 ± 0.236 | 1.243 | 1.756 | 1.00<br />
revm | 4.586 ± 0.066 | 4.537 | 4.727 | 3.07 ± 0.49</p>
<p>Code for these benchmarks can be seen in our repo: <a rel="noopener external" target="_blank" href="https://github.com/lambdaclass/evm_mlir">lambdaclass/evm_mlir</a>, along with documentation on how to reproduce them. We’re currently running them on our CI to detect performance regressions, and we’ll be adding more complex programs in the near future.</p>
<h3 id="next-steps">Next steps</h3>
<p>We now leave a skeleton crew to finish the remaining functionality and to continue optimizations, and focus on our new Execution Client – nicknamed <em>ethrex</em> after ETHereum Rust EXecution.</p>
<p>As said, our objective for our new Execution Client is giving the Ethereum ecosystem an alternative Rust Execution client with simple, straightforward code in the coming two months. After the MLIR EVM is ready, we intend to integrate it to <em>ethrex</em> , as part of a dog-fooding effort.</p>

    </div>
</article>

        </main>

        <footer class="site-footer">
            <div class="footer-container">
                <div class="footer-content">
                    <p class="footer-copyright">&copy; 2026 LambdaClass. All rights reserved.</p>
                    <div class="footer-links">
                        <a href="https://github.com/lambdaclass" target="_blank" rel="noopener">GitHub</a>
                        <a href="https://x.com/class_lambda" target="_blank" rel="noopener">X</a>
                        <a href="https://blog.lambdaclass.com/rss.xml">RSS</a>
                    </div>
                </div>
            </div>
        </footer>
    </div>

    <script>
        // Theme toggle functionality
        const themeToggle = document.getElementById('theme-toggle');
        const html = document.documentElement;

        // Check for saved preference or system preference
        const savedTheme = localStorage.getItem('theme');
        const systemPrefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;

        if (savedTheme) {
            html.setAttribute('data-theme', savedTheme);
        } else if (systemPrefersDark) {
            html.setAttribute('data-theme', 'dark');
        }

        themeToggle.addEventListener('click', () => {
            const currentTheme = html.getAttribute('data-theme');
            const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
            html.setAttribute('data-theme', newTheme);
            localStorage.setItem('theme', newTheme);
        });
    </script>
</body>
</html>
