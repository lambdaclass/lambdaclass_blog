<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interview with Dask’s creator: Scale your Python from one computer to a thousand - LambdaClass Blog</title>
    <meta name="description" content="My love for building distributed systems with Erlang, databases and fetching huge volumes of data still lives on. But nowadays I want to…">

    <!-- Feeds -->
    <link rel="alternate" type="application/rss+xml" title="RSS" href="https://blog.lambdaclass.com/rss.xml">
    <link rel="alternate" type="application/atom+xml" title="Atom" href="https://blog.lambdaclass.com/atom.xml">

    <!-- Styles -->
    <link rel="stylesheet" href="https://blog.lambdaclass.com/style.css">

    <!-- Preload fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">

    <!-- Math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body, {delimiters: [{left: '$$', right: '$$', display: true}, {left: '$', right: '$', display: false}]});"></script>
</head>
<body>
    <div class="site-wrapper">
        <header class="site-header">
            <nav class="nav-container">
                <a href="https://blog.lambdaclass.com" class="site-logo">
                    <span class="logo-text">LambdaClass</span>
                </a>
                <div class="nav-links">
                    <a href="https://blog.lambdaclass.com" >Home</a>
                    <a href="https://blog.lambdaclass.com/tags" >Topics</a>
                    <a href="https://github.com/lambdaclass" target="_blank" rel="noopener">GitHub</a>
                    <a href="https://x.com/class_lambda" target="_blank" rel="noopener">X</a>
                    <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                        <svg class="sun-icon" xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"></circle><line x1="12" y1="1" x2="12" y2="3"></line><line x1="12" y1="21" x2="12" y2="23"></line><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line><line x1="1" y1="12" x2="3" y2="12"></line><line x1="21" y1="12" x2="23" y2="12"></line><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line></svg>
                        <svg class="moon-icon" xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path></svg>
                    </button>
                </div>
            </nav>
        </header>

        <main class="site-main">
            
<article class="page-article">
    <header class="page-header">
        <h1 class="page-title">Interview with Dask’s creator: Scale your Python from one computer to a thousand</h1>
        
        <div class="page-meta">
            <time datetime="2019-09-03">September 03, 2019</time>
        </div>
        
    </header>

    <div class="page-content prose">
        <p>My love for building distributed systems with Erlang, databases and fetching huge volumes of data still lives on. But nowadays I want to have better theoretical and practical tools to understand the data. That is why I have been seriously studying probability, statistics and getting better at Python, numpy, pandas, scikit-learn, scipy and R. If you have read my earlier interviews you are probably aware of this.</p>
<p>That is why I decided to interview Dask’s creator Matthew Rocklin. Dask is a great bridge between the two areas that we specialize at my company <a rel="noopener external" target="_blank" href="https://lambdaclass.com/">LambdaClass</a>: distributed systems and data science. Dask is a great tool to parallelize python libraries. When you have some spare time I highly recommend that you check its code. Meanwhile I leave you with Matthew’s answers.</p>
<hr />
<p><strong>What is Dask? Why did you create it?</strong></p>
<p>Dask is a Python library designed to parallelize other common Python libraries, like NumPy, Pandas, Scikit-Learn and others. It helps people use Python on either a single multi-core machine, or a large distributed cluster.</p>
<p>People tend to use it either as a “Big Pandas” or “Big NumPy”, or as a lower level library to build their own parallel systems.</p>
<p>Originally we created Dask to parallelize Numpy and Pandas. We quickly found that the internals of Dask were useful for many more things, so we quickly pivoted to exposing the internals as a generic parallel system.</p>
<p><strong>Dask dataframes are a full replacement of pandas dataframes?</strong></p>
<p>No, the Pandas API is <strong>huge</strong> , so a full replacement is nearly impossible.</p>
<p>That being said, Dask Dataframe does implement the vast majority of popularly used Pandas functionality. Common staples like elementwise, reductions, groupbys, joins, rolling, timeseries, and more operations are all there. Additionally, because Dask dataframes are just a bunch of Pandas dataframes spread around a cluster it’s often pretty easy to convert custom code from Pandas to Dask easily.</p>
<p>It’s also worth noting that Dask != Dask Dataframes. Dataframes only account<br />
for about a third of Dask use out there. Dask goes way beyond just<br />
parallelizing Pandas.</p>
<p><strong>Is there any downside of using Dask dataframes instead of pandas dataframes?</strong></p>
<p>Oh definitely. If Pandas is solving your problem today, please don’t switch to Dask.</p>
<p>As with any distributed system, Dask adds a lot of complexity like network<br />
overheads, function serialization, and longer tracebacks in errors. We do a<br />
lot of work to keep our overhead small, both by keeping Dask lightweight and<br />
taking care of Python usability, but still, if you don’t need to switch, then<br />
don’t.</p>
<p><strong>How is it different form other distributed computation solutions (eg Hadoop MapReduce, Spark, Storm, Luigi, Airflow)?</strong></p>
<p>Dask is a bit lower level and more generic than those systems, and so can be used to build up similar solutions using existing Python libraries.</p>
<p>For example:</p>
<ul>
<li>When we combine Dask with Pandas we get <a rel="noopener external" target="_blank" href="https://docs.dask.org/en/latest/dataframe.html">Dask Dataframes</a>, which are comparable with Spark DataFrames</li>
<li>When we combine Dask with Scikit-Learn we get <a rel="noopener external" target="_blank" href="https://ml.dask.org">Dask-ML</a></li>
<li>When we combine Dask with Python’s <a rel="noopener external" target="_blank" href="https://docs.dask.org/en/latest/futures.html">futures or async/await</a> APIs we get a real-time framework, somewhat similar to Storm</li>
<li>When we combine Dask with <em>cron</em> like logic, we get an ETL framework like Airflow or Luigi. In fact, some of the Airflow developers split off and made <a rel="noopener external" target="_blank" href="https://www.prefect.io/">Prefect</a> a successor to Airflow which delegates the execution and data movement to Dask</li>
</ul>
<p>Additionally, Dask can be combined with other libraries to get novel systems<br />
that aren’t in your list. For example:</p>
<ul>
<li>When we combine Dask with Numpy we get a scalable multi-dimensional <a rel="noopener external" target="_blank" href="https://docs.dask.org/en/latest/array.html">Dask Arrays</a>.</li>
<li>When we combine Dask with GPU-accelerated Pandas or Numpy like libraries like <a rel="noopener external" target="_blank" href="https://rapids.ai">RAPIDS</a> we get distributed GPU-accelerated dataframes and arrays.</li>
</ul>
<p>Internally, Dask has the scalability of a system like MapReduce or Spark, with<br />
the flexibility of a system like Luigi or Airflow. This combination is nice both when you’re building new systems, and means that Dask gets used in a ton of novel work.</p>
<p><strong>How does data locality affect the performance of Dask? Does it assume all data is local to workers?</strong></p>
<p>By data locality you might mean two things (both of which Dask handles well):</p>
<p>1. Where does the data live in some storage system, like S3 or HDFS?</p>
<p>Dask is more than happy to query a data-local storage system like HDFS,<br />
find out where all the data lives, and target computations appropriately.</p>
<p>However, this kind of workload is becoming increasingly rare. More often<br />
people are using storage systems that prefer global accessibility over data<br />
locality, so this matters less and less these days in practice.</p>
<p>2. Once data is in memory, can Dask avoid moving it around?</p>
<p>Dask thinks a lot about where to run computations, and avoiding needless<br />
data communication is a big part of this decision. Sometimes we do need to<br />
move data around, but yes, Dask certainly avoids this when possible.</p>
<p>Moreover, because Dask gets used with a <strong>wide</strong> variety of workloads, our<br />
scheduling heuristics have had to evolve quite a bit over the years. It’s very<br />
rare for us to find problems today on which Dask’s data locality heuristics<br />
don’t respond optimally.</p>
<p><strong>What is the biggest Dask cluster you have seen in production?</strong></p>
<p>One thousand Windows machines.</p>
<p>Dask gets used on some of the world’s largest super-computers (I was<br />
logged into <a rel="noopener external" target="_blank" href="https://www.olcf.ornl.gov/summit">Summit</a>, the worlds largest super computer, just a few hours ago), and is deployed routinely on all major clouds.</p>
<p>However, Dask also scales down nicely. You can also just <em>import dask</em> and run it on a thread pool in a single python process or Jupyter notebook. As we like to say, <em>“The median cluster size is one”</em>. Dask is pure-Python, and super-lightweight if it needs to be. You can just <code>pip install dask</code> and it ships with the popular Anaconda distribution, which is deployed on millions of machines around the world.</p>
<p><strong>The Dask scheduler and Dask worker architecture, implementation and protocol was inspired by any other project?</strong></p>
<p>The central scheduler + distributed worker architecture is pretty common today. It’s a pragmatic choice for systems that want to scale between 1–1000 nodes.</p>
<p>So sure, Dask was inspired by other projects. All of them :). Notably, Dask tries hard not to reinvent too much. We rely a ton on other infrastructure within the Python ecosystem. We use Tornado and asyncio for concurrency and peer-to-peer networking, Numpy, Pandas, and Scikit-learn for computation, and other Python APIs like concurrent.futures and joblib for user APIs.</p>
<p>Dask is really just a smashing together of Python’s networking stack with its<br />
data science stack. Most of the work was already done by the time we got here.</p>
<p><strong>Which do are for you the most interesting frameworks, tools or libraries implemented on top of Dask and why?</strong></p>
<p>I’ll list a few interesting frameworks, but there are a ton out there these days:</p>
<ul>
<li><a rel="noopener external" target="_blank" href="https://xarray.pydata.org">Xarray</a> is a library commonly used to study Earth system data, like the climate, meteorology, oceanography, satellite imagery, and more. It’s really gratifying to see people use Dask to finally be able to analyze these huge climate science simulations, and help us better understand the planet.</li>
<li><a rel="noopener external" target="_blank" href="https://prefect.io">Prefect</a> provides a bunch of niceties on top of Dask for common Data Engineering or ETL workloads, similar to Airflow/Luigi. We got these feature requests constantly when we were starting out but declared them out of scope. It was great to have another project come by, take that feature set, and implement it way better than we ever could.</li>
<li><a rel="noopener external" target="_blank" href="https://epistasislab.github.io/tpot">TPot</a> is a library for automatic machine learning. You give it a dataset, and it tries out a bunch of models and pre-processors to find a good model. TPot existed well before Dask, and it has really gnarly parallelism internally, which makes it hard for non-experts to accelerate. Fortunately the TPot and Dask developers were able to get this going in a weekend, and now you can scale out this search with Dask on whatever parallel hardware you have.</li>
<li><a rel="noopener external" target="_blank" href="https://rapids.ai">RAPIDS</a> is a GPU-accelerated data science stack by NVIDIA. They were building out their own fast GPU implementation of Pandas and Numpy and wanted something to solve the multi-node problem for them. Dask was able to step in, handle all of the distributed communication, scheduling, and load balancing, and then step aside while NVIDIA’s fast GPU algorithms took over. (disclaimer, this is my current employer).</li>
</ul>
<p><strong>Could you please tell us about the work you are doing at NVIDIA to offload Dask computations to the GPU?</strong></p>
<p>Yeah, RAPIDS is really exciting. It turns out that GPUs are good for things other than graphics and deep learning. They’re surprisingly effective at accelerating more traditional computing in data science (and actual science). Operations like dataframe joins, CSV parsing, FFTs, text processing, and more can often be accelerated 10x-200x. Historically you had to know C and CUDA to use these libraries though, which made them accessible only to somewhat experience software developers.</p>
<p>The RAPIDS project within NVIDIA is wrapping up all of these algorithms in Python, and exposing APIs to data science users that look like drop-in replacements for Numpy/Pandas/Scikit-Learn.</p>
<p>They use Dask to provide multi-GPU parallelism (some people have many GPUs in a single machine) and multi-node parallelism across a cluster. Dask’s<br />
flexibility, and the fact that it’s pretty unopinionated about what you run as<br />
computation make it the perfect fit. It’s also one of the only task schedulers<br />
out there that run in a non-JVM language, which helps if you use natively<br />
compiled code, like CUDA.</p>
<p><strong>Do you have any book, MOOC or resource that you would recommend to those of us that want to learn more about the implementation of schedulers, concurrency models and distributed systems?</strong></p>
<p>Ha! Sadly no.</p>
<p>Centrally managed distributed schedulers are, unfortunately, not a common topic of research these days. From an academic/intellectual level it’s a fairly<br />
simple problem. Most of the difficult parts are in the details of engineering,<br />
which are unfortunately not that interesting to anyone who isn’t building a<br />
distributed scheduler.</p>

    </div>
</article>

        </main>

        <footer class="site-footer">
            <div class="footer-container">
                <div class="footer-content">
                    <p class="footer-copyright">&copy; 2026 LambdaClass. All rights reserved.</p>
                    <div class="footer-links">
                        <a href="https://github.com/lambdaclass" target="_blank" rel="noopener">GitHub</a>
                        <a href="https://x.com/class_lambda" target="_blank" rel="noopener">X</a>
                        <a href="https://blog.lambdaclass.com/rss.xml">RSS</a>
                    </div>
                </div>
            </div>
        </footer>
    </div>

    <script>
        // Theme toggle functionality
        const themeToggle = document.getElementById('theme-toggle');
        const html = document.documentElement;

        // Check for saved preference or system preference
        const savedTheme = localStorage.getItem('theme');
        const systemPrefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;

        if (savedTheme) {
            html.setAttribute('data-theme', savedTheme);
        } else if (systemPrefersDark) {
            html.setAttribute('data-theme', 'dark');
        }

        themeToggle.addEventListener('click', () => {
            const currentTheme = html.getAttribute('data-theme');
            const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
            html.setAttribute('data-theme', newTheme);
            localStorage.setItem('theme', newTheme);
        });
    </script>
</body>
</html>
